

\section{El algoritmo de Metropolis}



\section{El algoritmo de Metropolis-Hastings}

Este algoritmo se basa en proponer un nuevo punto de acuerdo a una función de
densidad de probabilidad arbitraria y aceptar este valor propuesto con una
probabilidad que depende del punto actual, el nuevo punto y la densidad de la cual
fue propuesto el nuevo punto.\\\\
Suponga que deseamos simular de la posterior multivariada $p(\alpha  \mid  x)$. Sea
$q(\alpha, \alpha')$ una función de densidad de probabilidad arbitraria que
describe la probabilidad de aceptación de $\alpha'$ dado que la posición actual es
$\alpha$. La densidad q puede ser escogida. El algoritmo de Metropolis-Hastings
está dado por:

\begin{itemize}
\item Sea el valor actual $\alpha_i$, generar un valor candidato $\alpha'$ donde
$\alpha'$ se obtiene como una observación de la densidad $q(\alpha_i, \alpha')$.
\item Calcule
\[T(\alpha_i, \alpha') =
\begin{cases}
min [ \frac{p(\alpha' \mid  x)q(\alpha', \alpha_i)}{p(\alpha_i \mid  x)q(\alpha_i, \alpha')}]
& \text{si} p(\alpha_i \mid  x)q(\alpha_i, \alpha') > 0,\\ 1 & \text{si}
p(\alpha_i \mid x)q(\alpha_i, \alpha') = 0
\end{cases}
\]
\item La probabilidad de aceptar el candidato es $T(\alpha_i, \alpha')$.
Fijar $\alpha_{i+1}=\alpha'$. De otra forma, rechazar el candidato y fijar
$\alpha_{i+1}=\alpha_i$.
\item Repita el paso anterior para obtener la secuencia $\alpha_0,\alpha_1,...,$
donde $\alpha_0$ denota un valor arbitrario de arranque.
\item Descarte los primeros $m$ valores obtenidos. Entonces $\alpha_{m+1}, \alpha{m+2}, . .
.$ es una secuencia (correlacionada) de la distribución posterior que se requería.
\end{itemize}
En principio, puede ser usada cualquier densidad $q$, pero si ésta es escogida
ingenuamente, la eficiencia de la cadena puede ser muy pobre. Nótese que los
valores de salida pueden ser los mismos que loas valores iniciales.\\\\
Siguiendo con el segundo ejemplo del apartado de Gibbs, en donde contábamos con 10
datos que tenían una distribución normal con media 2 y varianza 1, se ha escogido
usar como $q$ (distribuciones propuestas), normales centradas en el actual
parámetro. Dadas las distribuciones propuestas, algunos valores de la varianza
pueden ser negativos; este no es un problema porque la posterior toma el valor cero,
por tanto este valor será aceptado con un probabilidad de cero. En el libro de
Robert y Casella hay muchos ejemplos sobre las densidades $q$. En la figura 6, se
observa una lenta y convergencia.

La relación más importante entre el muestreados de Gibbs y el algorítmo de
Metropolis-Hastings, está dada como un teorema en el libro de Robert y Casella (pg
296).

\begin{Res}
El muestreador de Gibbs es equivalente al algorítmo de Metropolis-Hastings, con la
probabilidad de aceptación igual a uno para todos los puntos propuestos.
\end{Res}
Lo anterior implica que la convergencia para ambos métodos no es la misma.\\
Para cerrar la sección de cadenas de Markov vía Monte Carlo, es importante
hacernos la siguiente pregunta: ¿Son independientes las muestras simuladas?. En
principio no se puede hablar de independencia, pues es claro que la observación
$\{i+1\}$ depende de la observación $\{i\}$. Dado que las observaciones resultantes
se encuentran en estricto orden de medición, podríamos utilizar algunos criterios
como ACF y PACF, para averiguar sobre la correlación entre observaciones.\\

La figura 7 meustra el gráfico de autocorrelación parcial de los datos para los
dos métodos, en general no hay una estructura definida de autocorrelación parcial.
La figura 8 muestra que para el caso del algoritmo Metropolis-Hastings, si existe una
fuerte autocorrelación entre las primeras 100 observaciones, mientras que para el
muestreador de Gibbs tal estructura no está definida. Este podría ser otro
criterio de selección de la observación m-ésima.

\section{Algoritmos híbridos}

MEtropolis withing Gibbs

\section{Diagnóstico de convergencia}

\section{Cadenas de Markov reversibles}


\section{Códigos en \textbf{\texttt{R}}} En esta sección se implementan
cada uno de los algorítmos utilizados en los
ejemplos desarrollados.\\

\textsc{Algoritmo de METROPOLIS HASTING}\\

\texttt{met.hast.1 <- function(datos, a, b, iter, ini, v.mean, v.var) \{\\
mu0<- ini[1]; var0<- ini[2]\\
resul <- matrix(ncol=2,nrow=iter)\\
resul[1,1] <- mu0; resul[1,2] <- var0\\
for (i in 2:iter) \{\\
mu.prop <- rnorm(1, mu0, sqrt(v.mean)) \# Propuesta para la media\\
var.prop <- rnorm(1, var0, sqrt(v.var))\# Propuesta para la varianza\\
if (var.prop <= 0) \{\\
\# Vigila varianzas negativas \\
T.val <- 0 \# Nunca acepta \}\\
else \{\\
T1 <- prod(dnorm(datos,mu.prop,sqrt(var.prop)))\\
* dgamma(b/var.prop,a) * b* ( (1/var.prop)\^ 2 )\\
* dnorm(mu0, mu.prop,sqrt(v.mean)) * dnorm(var0,var.prop,sqrt(v.var))\\
T2 <- prod(dnorm(datos,mu0,sqrt(var0))) * dgamma(b/var0,a) * b\\
* ( (1/var0)\^2 ) * dnorm(mu.prop, mu0, sqrt(v.mean))\\
* dnorm(var.prop, var0,sqrt(v.var))\\
T.val <- min(1, T1/T2 ) \}\\
u <- runif(1) if (u <= T.val) \{\\
resul[i,1] <- mu.prop; resul[i,2] <- var.prop \}\\
else \{\\
resul[i,1] <- mu0; resul[i,2] <- var0 \}\\
mu0<- resul[i,1]; var0<- resul[i,2]; \}\\
final <- resul final \}\\
mc2 <- met.hast.1(datos,10,10,1000,c(5,5),0.15,0.08)}\\\\

\textsc{Independencia entre selecciones}\\\\

\texttt{mc1[,1]->Mu\_Gibbs; mc1[,2]->Var\_Gibbs\\
mc2[,1]->Mu\_MH; mc2[,2]->Var\_MH\\
par(mfrow=c(2,2))\\
pacf(Mu\_Gibbs,1000)\\
pacf(Mu\_MH,1000, ylim=c(-0.1,0.2))\\
pacf(Var\_Gibbs,1000)\\
pacf(Var\_MH,1000, ylim=c(-0.1,0.2))\\
par(mfrow=c(2,2))\\
acf(Mu\_Gibbs,1000,ylim=c(-0.1,0.2))\\
acf(Mu\_MH,1000 )\\
acf(Var\_Gibbs,1000,ylim=c(-0.1,0.2))\\
acf(Var\_MH,1000) }\\\\

\section{Metodología}

En los próximos apartados el lector podrá identificar los pasos que se deberán seguir para la consecución de los objetivos señalados al principio de esta propuesta doctoral.

\subsection{Identificación}

En primer lugar, cada modelo propuesto debe ser totalmente identificable en el sentido de \citet[p. 60]{Bickel}. Lo anterior implica que para cada escenario planteado, las matrices de información auxiliar deben estar correctamente estructuradas tanto en los componentes fijos, como en los componentes aleatorios. Una vez, asegurada esta propiedad, se utilizará el enfoque bayesiano de proponer distribuciones previa conjugadas siempre que sea posible. Dado que este acercamiento a la modelación conjunta requiere un arduo trasfondo computacional, cuando las distribuciones posterior no parezcan tener una forma conocida o cerrada, se utilizará el enfoque propuesto mediante la implementación del algoritmo híbrido.

\subsection{Computación}

En total armonía con lo anterior, los parámetros del modelo (efectos fijos, efectos aleatorios y efectos de varianza) estarán dados por un vector por bloques. Para la estimación de estas cantidades, es necesario utilizar el enfoque propuesto mediante la implementación de sendas cadenas simuladas desde las distribuciones posterior y con la técnica de Gibbs, en caso que sean conocidas; o mediante la utilización de distribuciones de salto para la implementación de un algoritmo de tipo Metrópolis. De esta manera, se debe utilizar en cada iteración un algoritmo híbrido que permita la actualización de las cadenas paso a paso. En términos pragmáticos, el autor de esta propuesta doctoral utilizará el software estadístico \textsf{R} \citep{R} para la implementación de tales algoritmos en cada uno de los escenarios propuestos.

\subsection{Estimación}

Aunque no será el quid de la investigación, y tampoco se abordará a profundidad las reglas de decisión derivadas de la teoría de decisión \citep{Berger}, es importante resaltar que en este trabajo doctoral, se utilizará el criterio de mínima pérdida cuadrática para la realización de cualquier tipo de inferencia ya sea de tipo estimativo o predictivo. Con base en lo anteriormente expuesto, se tiene que, siempre y cuando sea posible realizar la integración, las estimaciones puntuales estarán dadas por la esperanza del parámetro basada en la distribución posterior inducida por el análisis respectivo. Para los parámetros cuya distribución posterior no tiene una forma conocida o cerrada, se utilizarán métodos numéricos que deban ser llevados a cabo hasta obtener convergencia. Estos métodos convergen a la moda, el valor que hace máxima la distribución posterior, y este será el criterio de estimación en estos casos. A continuación se hace un repaso del tratamiento involucrado en la construcción de las cadenas que se generan a partir de los algoritmos utilizados en la estimación de los parámetros.


