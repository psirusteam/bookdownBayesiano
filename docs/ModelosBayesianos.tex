% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
  spanish,
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Modelos Bayesianos con R y STAN},
  pdfauthor={Andrés Gutiérrez - Hanwen Zhang},
  pdflang={es},
  colorlinks=true,
  linkcolor=blue,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=Blue,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{setspace}
\def\bPi{\boldsymbol \Pi }
\def\bGamma{\boldsymbol \Gamma}
\def\bgamma{\boldsymbol \gamma}
\def\beps{\boldsymbol \varepsilon}
\def\bbeta{\boldsymbol \beta}
\def\bLambda{\boldsymbol \Lambda}
\def\blambda{\boldsymbol \lambda}
\def\bBeta{\boldsymbol \Beta}
\def\bEta{\boldsymbol \eta}
\def\balpha{\boldsymbol \alpha}
\def\btheta{\boldsymbol \theta}
\def\bmu{\boldsymbol \mu}
\def\bSigma{\boldsymbol \Sigma}
\def\bphi{\boldsymbol \phi}
\def\bpi{\boldsymbol \pi}
\def\bxi{\boldsymbol \xi}
\ifxetex
  % Load polyglossia as late as possible: uses bidi with RTL langages (e.g. Hebrew, Arabic)
  \usepackage{polyglossia}
  \setmainlanguage[]{spanish}
\else
  \usepackage[main=spanish]{babel}
% get rid of language-specific shorthands (see #6817):
\let\LanguageShortHands\languageshorthands
\def\languageshorthands#1{}
\fi
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{Modelos Bayesianos con R y STAN}
\author{Andrés Gutiérrez - Hanwen Zhang}
\date{2021-05-30}

\usepackage{amsthm}
\newtheorem{theorem}{Teorema}[chapter]
\newtheorem{lemma}{Lema}[chapter]
\newtheorem{corollary}{Corolario}[chapter]
\newtheorem{proposition}{Resultado}[chapter]
\newtheorem{conjecture}{Conjectura}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{Definición}[chapter]
\theoremstyle{definition}
\newtheorem{example}{Ejemplo}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{Ejercicio}[chapter]
\theoremstyle{definition}
\newtheorem{hypothesis}{Hipótesis}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Comentario}
\newtheorem*{solution}{Solución}
\begin{document}
\maketitle

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{prefacio}{%
\chapter*{Prefacio}\label{prefacio}}
\addcontentsline{toc}{chapter}{Prefacio}

\hypertarget{antes-de-comenzar}{%
\chapter*{Antes de comenzar}\label{antes-de-comenzar}}
\addcontentsline{toc}{chapter}{Antes de comenzar}

\hypertarget{cuestionamientos-sobre-el-enfoque-bayesiano}{%
\section*{Cuestionamientos sobre el enfoque bayesiano}\label{cuestionamientos-sobre-el-enfoque-bayesiano}}
\addcontentsline{toc}{section}{Cuestionamientos sobre el enfoque bayesiano}

\citet{GelmanObjections} presenta algunos de los cuestionamientos que algunos estadísticos anti-bayesianos han argumentado en contra de este paradigma que, sin lugar a dudas, ha proporcionado una valiosa herramienta de modelación en la ciencia contemporanea. Revisemos algunos de estos argumentos:

\begin{quote}
La inferencia bayesiana es una teoría matemática coherente pero no brinda la suficiente confianza en usos científicos. Las distribuciones \emph{previas} subjetivas no inspiran confianza porque ni siquiera existe algún principio objetivo para elegir una distribución previa no informativa. ¿De dónde vienen las distribuciones previas? No confío en ellas y no veo ninguna razón para recomendarlas a otra gente, apenas me siento cómodo acerca de su coherencia filosófica.
\end{quote}

Este argumento es débil puesto que la teoría bayesiana es una teoría cinetífica apoyada en los axiomas matemáticos de la teoría de la medida y de probabilidad. De la mismaforma, nótese que tampoco existe un principio objetivo para escoger una verosimilitud. ¿De dónde vienen las regresiones logísticas? ¿quién dijo que los datos eran normales? Como toda ciencia, la estadística se basa en procedimientos subjetivos que inducen resultados que se pueden probar de una manera objetiva. Al decidir usar una determinada distribución previa, el investigador está haciendo uso de su conocimiento objetivo sobre el fenómeno de interés. Esto no dista mucho de la planificación de un estudio por muestreo o de un experimento, en donde se hace uso de la información auxiliar disponible para definir la mejor versión del estudio. Además, como se verá más adelante, sí existen principios objetivos que permiten decidir acerca de la elección de una distribución previa; por ejemplo, la invarianza de la distribución previa frente a transformaciones de los parámetros.

\begin{quote}
La teoría bayesiana requiere un pensamiento mucho más profundo sobre la situación y recomendarle a los investigadores comunes el uso del teorema de Bayes es como darle al hijo del vecino la llave de un \emph{F-16}. De veras que, yo comenzaría con algo de métodos probados y confiables, y entonces generalizaría la situación utilizando los principios estadísticos y la teoría del minimax, que no dependen de ninguna creencia subjetiva. Especialmente cuando las distribuciones previas que veo en la práctica toman formas conjugadas. ¡Qué coincidencia!
\end{quote}

Como científicos e investigadores debemos tratar con el conocimiento objetivo y dejar a un lado las creencias subjetivas. Es por eso que las distribuciones previas que se manejan en la inferencia bayesiana son objetivas de la misma forma que lo son los métodos frecuentistas al asignar un modelo probabilístico a la verosimilitud de los datos. El resultado final sólo depende del modelo asumido y de los datos recolectados. A pesar de que algunos resultados de la inferencia bayesiana coinciden con el acercamiento frecuentista, esto no sucede en todos los casos. Si la distribución es conjugada, simplemente quiere decir que es posible utilizar un generador de números aleatorios conocido; sin embargo, en pleno siglo XXI, esto ya no constituye un problema.

\begin{quote}
Dejando de lado las preocupaciones matemáticas, me gustan las estimaciones insesgadas, los intervalos de confianza con un nivel real de cobertura. Pienso que la manera correcta de inferir es acercarse al parámetro tanto como sea posible y desarrollar métodos robustos que trabajen con supuestos mínimos. El acercamiento bayesiano intenta aproximar el insesgamiento, mientras asume supuestos más y más fuertes. En los viejos tiempos, los métodos Bayesianos por lo menos tenían la virtud de estar matemáticamente limpios. Hoy en día, cualquier inferencia se realiza mediante el uso de las cadenas de Markov con métodos de Monte Carlo (MCMC). Lo anterior significa que, no sólo no se pueden evaluar las características estadísticas del método, sino que tampoco se puede asegurar su convergencia.
\end{quote}

Los métodos bayesianos parecen moverse rápidamente hacia la computación elaborada. Para bien o para mal, la computación se está convirtiendo en una plataforma central para el desarrollo científico y estadístico. Por otro lado, estos mismos adelantos de computación científica permiten evaluar las características de los modelos bayesianos y la convergencia de las cadenas de la distribución posterior. Haciendo uso de la rigurosidad científica, el investigador debe conocer a profundidad el espíritu de los métodos MCMC y verificar que la distribución posterior conjunta sobre un vector de parámetros no sea impropia, y por supuesto verificar que las cadenas tienen propiedades estacionarias.

\begin{quote}
La gente tiende a creer los resultados que apoyan sus preconceptos y descreen los resultados que los sorprenden, ésta es una forma errada y sesgada de pensar. Pues bien, los métodos bayesianos animan este modo indisciplinado de pensamiento. Estoy seguro que muchos estadísticos bayesianos están actuando de buena fe; sin embargo, al mismo tiempo, también están proporcionando estímulo a investigadores descuidados y poco éticos por todas partes, porque el investigador queda estancado al momento de escoger una distribución previa.
\end{quote}

Si hay una seria diferenciación entre las creencias subjetivas y los resultados posteriores, debería ser un indicador de revaluar el modelo usado. Además, ante el desconocimiento del fenómeno, el investigador bayesiano puede utilizar una distribución previa débil y añadir más información si se necesita. Las verificaciones predictivas (previas y posteriores) son una parte esencial del método bayesiano que obliga a repensar las creencias del investigador con respecto al parámetro de interés. Este ejercicio redunda en el replanteamineto de la distribución previa mediante el estudio de las distribuciones predictivas, decantándose al final por el mejor modelo.

\begin{quote}
Los cálculos de la teoría de la decisión guían a la idea de que el muestreo probabilístico y la asignación aleatoria de tratamientos son ineficaces, de que los mejores diseños y muestras son los determinísticos. No tengo ningún conflicto con estos cálculos matemáticos; el conflicto es más profundo, en los fundamentos filosóficos, en la idea de que el objetivo de la estadística consiste en tomar una decisión óptima. Un estimador bayesiano es un estimador estadístico que reduce al mínimo el riesgo promedio. Sin embargo, cuando hacemos estadística, no estamos intentando \emph{reducir al mínimo el riesgo promedio}, estamos intentando hacer estimación y juzgamiento de hipótesis.
\end{quote}

Un estimador bayesiano es un estimador estadístico que minimiza el riesgo promedio. Uno de los primeros tópicos que se presentan en este libro es el de la teoría de la decisión y funciones de perdida, como herramientas fundamentales del aprendizaje estadístico \citep{hastie}. Además, como se verá más adelante, la asignación de las unidades experimentales al tratamiento o la inclusión de las unidades muestrales en un estudio probabilístico debe y puede ser tenido en cuenta en los modelos bayesianos, mediante la inclusión en el modelo de las variables que intervinieron en la selección de las unidades. De la misma forma, el juzgamiento de hipótesis es una práctica que se extiende en la modelación bayesiana.

\begin{quote}
No puedo estar al tanto de lo que están haciendo todos esos Bayesianos hoy en día. Desafortunadamente, toda clase de personas están siendo seducidas por las promesas de la inferencia automática con la \emph{magia del MCMC}. Desearía que todos paráramos de una vez y por todas y empezáramos, de nuevo, a hacer estadística de la forma en que debe ser hecha: volviendo a los viejos tiempos en que un \(p\)-valor era utilizado para algo, cuando un intervalo de confianza tenía significado, y el sesgo estadístico era algo que se quería eliminar y no algo que se debiera abrazar.
\end{quote}

Los métodos Bayesianos algunas veces son presentados como un motor de inferencia automática. Sin embargo, la inferencia bayesiana tiene tres etapas: formulación del modelo, ajuste del modelo a los datos, evaluación del ajuste. Así que el procedimiento no es mágico ni automático. Además, una de las ventajas de la estadística bayesiana es que deja de lado las sofisticaciones de la inferencia clásica en donde, por ejemplo, la simple interpretación de un intervalo de confianza se hace muy complicada a la luz del razonamiento lógico. De la misma forma los valores \(p\) constituyen un paradigma cada vez más revalorado en la investigación social.

\hypertarget{acerca-de-la-notaciuxf3n}{%
\section*{Acerca de la notación}\label{acerca-de-la-notaciuxf3n}}
\addcontentsline{toc}{section}{Acerca de la notación}

Antes de empezar las próximas secciones, es necesario revisar la
notación que se seguirá de ahora en adelante. Del teorema de Bayes
resultan tres grandes definiciones que constituyen la base de la
estadística Bayesiana y que a lo largo de este texto se mencionarán
diferenciándolas por medio de la notación. El símbolo más importante de
la estadística matemática es \(p\), el cual indica que existe una
distribución de probabilidad para los datos, para el vector de
parámetros, condicional o no. De hecho todos las definiciones y
resultados anteriores han estado supeditadas al uso de esta monótona
notación. En el ámbito de la notación de investigación internacional es
común diferenciar las distribuciones con el fin de hacer más ameno el
estudio del enfoque Bayesiano. En este texto se seguirá esta distinción.
Un ejemplo claro en donde \(p\) representa cuatro funciones distintas en
una sola ecuación es el siguiente:

\[p(\theta \mid y)=p(y \mid \theta)\frac{p(\theta)}{p(y)}\]

\citet{Gelman95} explica por qué la notación simple, con el uso (a
veces abuso) de la letra \(p\) es más rigurosa de lo que, a simple vista,
pueda parecer y comenta que,

\begin{quote}
En realidad no me gusta la notación que la mayoría de los estadísticos usen \(f\) para las distribuciones de muestreo; \(\pi\), para las distribuciones previas y \(L\), para las verosimilitudes. Este estilo de notación se desvía de lo que realmente es importante. La notación no debería depender del orden en que las distribuciones son especificadas. Todas ellas son distribuciones de probabilidad, eso es lo realmente importante.
\end{quote}

Esto tiene sentido, aún más cuando se estudian las propiedades
estadísticas de los estimadores desde el punto de vista de la teoría de
la medida. Siendo así, el símbolo \(p\) se refiere a una notación para una
medida de probabilidad, quizás inducida por un elemento aleatorio. De
hecho, en la ecuación que determina la regla de Bayes, cada una de las
\(p\) son medidas de probabilidad que no comparten el mismo espacio de
medida (ni la misma \(\sigma\)-álgebra, ni el mismo espacio muestral).

De hecho, todo queda claro al realizar un diagrama que permita ver el
espacio de salida y el espacio de llegada de los elementos aleatorios
que inducen (si es el caso), cada una de las distribuciones de
probabilidad. Por otra parte, Bob Carpenter concluye que:

\begin{quote}
Una vez resuelto el problema de identificación de los espacios, la notación estadística depende en gran manera del contexto y aunque la regla de Bayes no necesite de mucha explicación, es necesario conocerlo todo acerca del contexto para poder interpretar las funciones que la conforman\ldots{} El problema se hace mucho más agudo para los estadísticos novatos, pero eso se resuelve con la práctica. Una vez que uno sabe lo que está haciendo, se vuelve obvia la referencia de la distribución \(p\).
\end{quote}

Por lo anterior, es natural que algunos de los textos clásicos de
estadística matemática, los autores asumen que el lector sigue la idea
de la referencia de la distribución \(p\) en cuestión.

\hypertarget{tuxf3picos-buxe1sicos}{%
\chapter{Tópicos básicos}\label{tuxf3picos-buxe1sicos}}

\hypertarget{teoruxeda-de-la-decisiuxf3n}{%
\section{Teoría de la decisión}\label{teoruxeda-de-la-decisiuxf3n}}

El problema estadístico de estimar un parámetro se puede ver dentro del contexto de la teoría de decisión: la estimación que proveemos, sea en el ámbito de la estadística clásica o la estadística bayesiana, depende de los datos muestrales, \(\mathbf{X}\), de tal forma que si éstos cambian, la estimación también cambia. De esta manera, el proceso de estimación puede ser representado como una función que toma un conjunto de datos muestrales y los convierte en una estimación (\(A(\mathbf{X})\) o simplemente \(A\)) del parámetro de interés. En la teoría de decisión, la anterior función se conoce como una regla de decisión.

Así como en la vida cotidiana, por la incertidumbre del futuro (en el ámbito estadístico, por la incertidumbre acerca del parámetro), toda acción que se tome (toda estimación que se provea) puede traer consigo un grado de falla o riesgo. Y es necesario escoger la acción óptima que de alguna forma minimice ese riesgo. Formalizando esta idea intuitiva, se define la función de pérdida \(L\) que asocia a cada dupla conformada por la acción tomada y el parámetro de interés \(\theta\), \((A, \ \theta)\) con un número no negativo que cuantifica la pérdida que ocasiona la acción (o la estimación) \(A\) con respecto al parámetro \(\theta\).

Es claro que se desea escoger aquella acción que minimice de alguna forma la pérdida que ésta ocasiona, pero la función \(L\) no se puede minimizar directamente, puesto que:

\begin{itemize}
\item
  En el ámbito de la estadística clásica, el parámetro \(\theta\) se considera fijo, y los datos muestrales \(\mathbf{X}\) aleatorios. Como la función de pérdida \(L\) depende de \(\mathbf{X}\), entonces ésta también será una variable aleatoria, y no se puede minimizar directamente. Por lo tanto se define el riesgo o la pérdida promedio como la esperanza matemática de \(L\); denotando el riesgo como \(R\), éste está definido como \(R=E(L)\) (la esperanza se toma con respecto a la distribución probabilística de \(\mathbf{X}\)).
\item
  En el ámbito de la estadística bayesiana, \(\theta\) sigue siendo una cantidad fija, pero la incertidumbre que tiene el investigador sobre la localización del parámetro se puede modelar mediante funciones de probabilidad. La herramienta fundamental para conocer características de \(\theta\) es su función de densidad posterior \(p(\theta|\mathbf{X})\). En este caso, el riesgo \(R\) se define como
\end{itemize}

\begin{equation*}
R=E(L)=\int L(A, \theta)p(\theta|\mathbf{X})d\theta
\end{equation*}

En cualquiera de los dos casos anteriores, se busca la estimación que minimice el riesgo \(R\). Ilustramos los anteriores conceptos en los siguientes ejemplos tanto en la estadística clásica como en la estadística bayesiana.

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-1}{}{\label{exm:unnamed-chunk-1} }Sea \(X_i\) con \(i=1,\cdots, n\) una muestra aleatoria con media \(\theta\) y varianza \(\sigma^2\), ambas fijas, y suponga que se desea encontrar el mejor estimador de \(\theta\) bajo la función de pérdida cuadrática dada por

\begin{equation*}
L(A,\theta)=(A-\theta)^2
\end{equation*}

cuyo riesgo asociado está dado por \(R=E(A-\theta)^2\). En primer lugar, buscaremos dicho estimador dentro de todas las formas lineales de \(X_i\), es decir, los estimadores de la forma \(A=\sum_{i=1}^nc_iX_i\). Por tanto, el riesgo se puede expresar como
\begin{align*}
R=E(A-\theta)^2&=Var(A)+(E(A)-\theta)^2\\
&=\sum_{i=1}^nc_i^2\sigma^2+\theta^2(\sum_{i=1}^nc_i-1)^2
\end{align*}

Y al buscar los coeficientes \(c_i\) que minimizan la anterior expresión, encontramos que \(c_i=\theta^2/(\sigma^2+n\theta^2)\) para todo \(i\). Como estos coeficientes conducen a un estimador que depende del parámetro desconocido, concluimos que no hay ningún estimador que minimiza el riesgo.

Para encontrar una solución, es necesario restringir aún más el rango de estimadores; para eso, se impone la restricción de que \(\sum_{i=1}^n c_i=1\). De esta forma, el riesgo está dado por \(R=\sum c_i^2\sigma^2\). Dado que \(\sigma^2\) es fijo, al minimizar \(\sum c_i^2\) sujeto a la restricción, se tiene que la solución es \(c_i=1/n\) para todo \(i\), y así encontramos que el mejor estimador (en el sentido de minimizar el riesgo de la función de pérdida cuadrática) dentro de todas las formas lineales con \(\sum c_i=1\) es la media muestral \(\bar{X}\).
\end{example}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-2}{}{\label{exm:unnamed-chunk-2} }Suponga que se desea estimar un parámetro de interés \(\theta\) en el contexto de la estadística bayesiana y denotamos la función de densidad posterior de \(\theta\) como \(p(\theta|\mathbf{X})\), entonces si utilizamos la función de pérdida cuadrática, el riesgo asociado será

\begin{align*}
R&=E(L(A,\theta))=E (A-\theta)^2=Var(\theta)+(E(\theta)-A)^2
\end{align*}

que es minimizado si \(A=E(\theta)\). Es decir, la mejor acción para estimar \(\theta\) es utilizar su tomada con respecto a la distribución posterior \(p(\theta|\mathbf{X})\).
\end{example}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-3}{}{\label{exm:unnamed-chunk-3} }En el mismo contexto del ejemplo anterior, si cambiamos la función de pérdida a la siguiente
\begin{equation*}
L(A,\theta)=|A-\theta|=(A-\theta)I_{(A\geq\theta)}+(\theta-A)I_{(\theta>A)}
\end{equation*}

El riesgo estará dado por
\begin{align*}
R&=E(L(A,\theta))\\
&=\int L(A,\theta)p(\theta|\mathbf{X})d\theta\\
&=\int_{(A\geq\theta)}(A-\theta)p(\theta|\mathbf{X})d\theta+\int_{(\theta>A)}(\theta-A)p(\theta|\mathbf{X})d\theta
\end{align*}

Derivando el riesgo con respecto a la acción \(A\), se tiene que
\begin{equation*}
\frac{\partial R}{\partial A}=\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta-\int_{(\theta>A)}p(\theta|\mathbf{X})d\theta
\end{equation*}

Igualando a cero, tenemos que
\begin{equation*}
\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta=\int_{(\theta>A)}p(\theta|\mathbf{X})d\theta=0.5
\end{equation*}

Y concluimos que la acción \(A\) que induce menor riesgo corresponde al percentil 50\% o la mediana de la distribución posterior de \(\theta\).
\end{example}

De los anteriores ejemplos se observa que, bajo un mismo contexto, cuando se utilizan diferentes funciones de pérdida, también se obtienen distintas estimaciones, y distintas acciones que optimizan el riesgo.

\hypertarget{algunos-resultados-de-probabilidad}{%
\section{Algunos resultados de probabilidad}\label{algunos-resultados-de-probabilidad}}

Antes de entrar en el repaso de estos conceptos fundamentales, se definen los conceptos de \textbf{parámetro} y \textbf{espacio paramétrico} asociados a una distribución de probabilidad.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Un parámetro es aquella cantidad que define la forma funcional de una distribución de probabilidad; es decir, cuando el parámetro cambia de valor, la función de densidad y la función de distribución cambian. Las distribuciones de probabilidad pueden tener más de un parámetro. Cuando una distribución tiene solo un parámetro, éste se denota usualmente por \(\theta\), cuando se presenta más de un parámetro, la notación se cambia a \(\boldsymbol \theta\), representando el vector de parámetros.
\item
  El espacio paramétrico, \(\Theta\), es el conjunto que contiene todos los posibles valores que puede tomar el parámetro o el vector de parámetros. Para distribuciones con un solo parámetro, \(\Theta\) será un subconjunto de \(\mathbb{R}\), mientras que para distribuciones con dos o más parámetros, \(\Theta\) será un subconjunto de \(\mathbb{R}\times\mathbb{R}\).
\end{enumerate}

Para entender los fundamentos de la modelación bayesiana, es necesario
recordar algunas definiciones y resultados de la teoría de probabilidad
que ayudarán a hacer más expedito este periplo por la estadística
bayesiana. En términos de notación, se utilizará indistintamente la
expresión de integral, \(\int\), indicando la sumatoria, en el caso de las
variables aleatorias discretas o la integral de Riemann-Stieltjes en el
caso de las variables aleatorias continuas.

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-4}{}{\label{def:unnamed-chunk-4} }Sean \(\mathbf{X}=(X_1,\ldots,X_p)'\), \(\mathbf{Y}=(Y_1,\ldots,Y_q)'\) dos vectores aleatorios definidos sobre los espacios de muestreo \(\mathcal{X}\), \(\mathcal{Y}\), respectivamente. Suponga que la distribución conjunta de estos vectores aleatorios está dada por \(p(\mathbf{X},\mathbf{Y})\). La distribución marginal de \(\mathbf{X}\) está dada por
\begin{equation}
p(\mathbf{X})=\int p(\mathbf{X},\mathbf{Y})\ d\mathbf{Y}
\end{equation}
y la distribución condicional de \(\mathbf{X}\) dado \(\mathbf{Y}\) como
\begin{equation}
p(\mathbf{X} \mid \mathbf{Y})
=\frac{p(\mathbf{X},\mathbf{Y})}{p(\mathbf{Y})}
\end{equation}
\end{definition}

\begin{proposition}
\protect\hypertarget{prp:Res121}{}{\label{prp:Res121} }Suponga los vectores \(\mathbf{X}\), \(\mathbf{Y}\) y un tercer vector \(\mathbf{Z}=(Z_1,\ldots,Z_r)'\) definido sobre el espacio de muestreo \(\mathcal{Z}\). Entonces se tiene que
\begin{equation}
p(\mathbf{X} \mid \mathbf{Z})=\int p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})\ d\mathbf{Y}
\end{equation}
y
\begin{equation}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}
\end{equation}
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}En primer lugar, nótese que
\begin{align*}
\int p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})\ d\mathbf{Y}&=
\int \frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}\ d\mathbf{Y}\\
&=\frac{1}{p(\mathbf{Z})} \int p(\mathbf{X},\mathbf{Y},\mathbf{Z}) \ d\mathbf{Y}\\
&=\frac{1}{p(\mathbf{Z})} p(\mathbf{X},\mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})
\end{align*}

Por otro lado,

\begin{align*}
\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}=
\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})} \diagup
\frac{p(\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}
=\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}=p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})
\end{align*}
\end{proof}

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-6}{}{\label{def:unnamed-chunk-6} }Sean \(\mathbf{X}\), \(\mathbf{Y}\), \(\mathbf{Z}\) vectores aleatorios, se dice que \(\mathbf{X}\) es condicionalmente independiente de \(\mathbf{Y}\) con respecto a \(\mathbf{Z}\) si satisfacen la siguiente expresión
\begin{equation}
p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})
\end{equation}
\end{definition}

\begin{proposition}
\protect\hypertarget{prp:Res122}{}{\label{prp:Res122} }Si \(\mathbf{X}\) es condicionalmente independiente de \(\mathbf{Y}\) con respecto a \(\mathbf{Z}\), entonces se tiene que
\begin{equation}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})
\end{equation}
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}Como \(p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})=\dfrac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}\), entonces

\begin{align*}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}
=\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})p(\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}
=\frac{p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}=p(\mathbf{X} \mid \mathbf{Z})
\end{align*}
\end{proof}

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-8}{}{\label{prp:unnamed-chunk-8} }Si \(\mathbf{X}\) es independiente de \(\mathbf{Y}\), entonces \(\mathbf{X}\) es condicionalmente independiente de \(\mathbf{Y}\) dado cualquier otro vector \(\mathbf{Z}\).
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}Nótese que
\begin{equation*}
p(\mathbf{X},\mathbf{Y}\mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})
\end{equation*}

puesto que, utilizando la hipótesis de independencia, se tiene que
\begin{equation*}
p(\mathbf{X} \mid \mathbf{Y})=p(\mathbf{X})
\end{equation*}
\end{proof}

\hypertarget{teorema-de-bayes}{%
\section{Teorema de Bayes}\label{teorema-de-bayes}}

Desde la revolución estadística de Pearson y Fisher, la inferencia
estadística busca encontrar los valores que parametrizan a la
distribución desconocida de los datos. El primer enfoque, propuesto por
Pearson, afirmaba que si era posible observar a la variable de interés
en todos y cada uno de los individuos de una población, entonces era
posible calcular los parámetros de la distribución de la variable de
interés; por otro lado, si solo se tenía acceso a una muestra
representativa, entonces era posible calcular una estimación de tales
parámetros. Sin embargo, Fisher discrepó de tales argumentos, asumiendo
que las observaciones están sujetas a un error de medición y por lo
tanto, así se tuviese acceso a toda la población, sería imposible calcular
los parámetros de la distribución de la variable de interés.

Del planteamiento de Fisher resultaron una multitud de métodos
estadísticos para la estimación de los parámetros poblacionales. Es
decir, si la distribución de \(\mathbf{Y}\) está parametrizada por
\(\boldsymbol \theta=(\theta_1,\ldots,\theta_K)\), \(\boldsymbol \theta\in \Theta\) con \(\Theta\)
el espacio paramétrico inducido por el comportamiento de la variable de
interés, el objetivo de la teoría estadística inferencial es calcular
una estimación \(\hat{\boldsymbol \theta}\) del parámetro \(\boldsymbol \theta\), por medio de los
datos observados. En este enfoque, los parámetros se consideran
cantidades fijas y constantes. Sin embargo, en la última mitad del siglo
XX, algunos investigadores estadísticos comenzaron a reflexionar acerca
de la naturaleza de \(\boldsymbol \theta\) y enfocaron la inferencia estadística de
una manera distinta: \emph{asumiendo que la distribución de la variable de
interés está condicionada a valores específicos de los parámetros}. Es
decir, en términos de notación, si la variable de interés es
\(\mathbf{Y}\), su distribución condicionada a los parámetros toma la
siguiente forma \(p(\mathbf{Y} \mid \boldsymbol \theta)\). Esto implica claramente
que en este nuevo enfoque la naturaleza de los parámetros no es
constante.

En términos de inferencia para \(\boldsymbol \theta\), es necesario encontrar la
distribución de los parámetros condicionada a la observación de los
datos. Para este fin, es necesario definir la distribución conjunta de
la variable de interés con el vector de parámetros.
\begin{equation*}
p(\boldsymbol \theta,\mathbf{Y})=p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)
\end{equation*}

A la distribución \(p(\boldsymbol \theta)\) se le conoce con el nombre de
distribución \emph{previa} y en ella se enmarcan todas y cada una de las
creencias que se tienen acerca del comportamiento estocástico del vector
de parámetros antes de que ocurra la recolección de los datos; \(p(\mathbf{Y} \mid \boldsymbol \theta)\) es la distribución de muestreo,
verosimilitud o distribución de los datos. Por otro lado, la
distribución del vector de parámetros condicionada a los datos
observados está dada por

\begin{equation}
\label{eq:Bayes}
p(\boldsymbol \theta\mid \mathbf{Y})=\frac{p(\boldsymbol \theta,\mathbf{Y})}{p(\mathbf{Y})}=\frac{p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)}{p(\mathbf{Y})}
\end{equation}

A la distribución \(p(\boldsymbol \theta\mid \mathbf{Y})\) se le conoce con el
nombre de distribución \emph{posterior} y en ella se enmarcan las
creencias actualizadas acerca del comportamiento estocástico del vector
de parámetros teniendo en cuenta los datos observados \(\mathbf{Y}\).
Nótese que la expresión \eqref{eq:Bayes} se compone de una fracción cuyo
denominador no depende del vector de parámetros y considerando a los
datos observados como fijos, corresponde a una constante y puede ser
obviada. Por lo tanto, otra representación de la regla de Bayes está
dada por

\begin{align}
\label{eq:Bayes1}
p(\boldsymbol \theta\mid \mathbf{Y})\propto p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta)
\end{align}

\citet{Gelman03} menciona que esta expresión se conoce como la
distribución \emph{posterior no-normalizada} y encierra el núcleo
técnico de la inferencia bayesiana. La constante \(p(\mathbf{Y})\)
faltante en la expresión \eqref{eq:Bayes1} se da a continuación.

\begin{proposition}
\protect\hypertarget{prp:Res131}{}{\label{prp:Res131} }La expresión \(p(\mathbf{Y})\) corresponde a una constante \(k\) tal que
\begin{equation*}
k=p(\mathbf{Y})=E_{\boldsymbol \theta}[p(Y \mid \boldsymbol \theta)]
\end{equation*}
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}Nótese que
\begin{equation*}
k=p(\mathbf{Y})=\int p(\mathbf{Y},\boldsymbol \theta)\ d\boldsymbol \theta=\int p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)\ d\boldsymbol \theta.
\end{equation*}
entonces
\begin{align*}
k&=\int p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta)\ d\boldsymbol \theta\\
&=E_{\boldsymbol \theta}[p(Y \mid \boldsymbol \theta)]
\end{align*}
\end{proof}

Curiosamente, el reverendo Thomas Bayes nunca publicó este resultado,
sino que después de su fallecimiento, su amigo el filósofo Richard
Price, encontró los escritos dentro de sus pertenencias, y éstos fueron
publicados en el 1764 en
\emph{Philosophical Transactions of the Royal Society of London}. Aunque
el teorema de Bayes fue nombrado en honor de Thomas Bayes, es casi
seguro que él mismo no sospechaba del gran impacto de su resultado. De hecho, aproximadamente una década más tarde, Pierre-Simon Laplace también descrubrió el mismo principio, y dedicó gran parte de su vida extendiéndolo y formalizándolo. Más aún, él analizó grandes volumenes de datos relacionados a los nacimientos en diferentes paises para confirmar esta teoría, y sentó las bases de la estadística bayesiana.

A continuación se presenta un ejemplo simple de este sencillo pero
poderoso teorema.

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-11}{}{\label{exm:unnamed-chunk-11} }Suponga que una fábrica del sector industrial produce bolígrafos y que la producción está a cargo de tres máquinas. La primera máquina produce el 50\% del total de bolígrafos en el año, la segunda máquina produce el 30\% y la última maquina produce el restante 20\%. Por supuesto, esta producción esta sujeta al error y por tanto, basados en la experiencia, es posible reconocer que, de los artículos producidos por la primera máquina, el 5\% resultan defectuosos; de los artículos producidos por la segunda máquina, el 2\% resultan defectuosos y, de los artículos producidos por la última máquina, el 6\% resultan defectuosos.

Una pregunta natural que surge es acerca de la probabilidad de selección de un artículo defectuoso y para responder a esta pregunta con rigurosidad de probabilística es necesario enfocar la atención en los tópicos básicos que dejamos atrás. En primer lugar, el experimento en cuestión es la selección de un bolígrafo. Para este experimento, una terna \((\Omega, \mathfrak{F}, P)\) \footnote{\(\Omega\) denota el conjunto de todos lo posibles resultados del experimento, \(\mathfrak{F}\) denota una \(\sigma\)-álgebra y \(P\) hace referencia ana medida de probabilidad propiamente definida.}, llamada comúnmente espacio de medida o espacio de probabilidad, está dada por

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El espacio muestral: \(\Omega=\{\text{defectuoso}, \text{No defectouso}\}\)
\item
  La \(\sigma\)-álgebra: \(\mathfrak{F}=\{\Omega, \phi, \{\text{Defectuoso}\}, \{\text{No Defectuoso}\}\}\)
\item
  La función de probabilidad:
  \begin{align*}
    p: \mathfrak{F} &\longrightarrow [0,1]\\
    \Omega &\longrightarrow 1\\
    \phi &\longrightarrow 0\\
    \{Defectuoso\}&\longrightarrow P(D)\\
    \{No Defectuoso\}&\longrightarrow 1-P(D)
    \end{align*}
  en donde, acudiendo al teorema de probabilidad total, se define
  \begin{equation*}
    p(D)=p(D \mid M1)P(M1)+p(D \mid M2)P(M2)+p(D \mid M3)P(M3)
    \end{equation*}
\end{enumerate}

Sin embargo, también es posible plantearse otro tipo de preguntas que sirven para calibrar el proceso de producción de artículos defectuosos. Por ejemplo, cabe preguntarse acerca de la probabilidad de que, habiendo seleccionado un artículo defectuoso, éste provenga de la primera máquina\footnote{Por supuesto que la pregunta también es válida al indagar por la probabilidad de que habiendo seleccionado un artículo defectuoso, éste provenga de la segunda o tercera máquina.}. En esta ocasión, el experimento ha cambiado y ahora se trata de seleccionar un artículo defectuoso y para responder a tal cuestionamiento, se debe establecer rigurosamente el espacio de probabilidad que puede estar dado por

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El espacio muestral: \(\Omega=\{M1, M2, M3 \}\)
\item
  La \(\sigma\)-álgebra: \(\mathfrak{F}^+=\{\Omega, \phi, \{M1\}, \{M2,M3\}\}\)
\item
  La función de probabilidad:
  \begin{align*}
    p: \mathfrak{F}^+ &\longrightarrow [0,1]\\
    \Omega &\longrightarrow 1\\
    \phi &\longrightarrow 0\\
    \{M1\}&\longrightarrow p(M1 \mid D)\\
    \{M2,M3\}&\longrightarrow 1-p(M1 \mid D)
    \end{align*}
  en donde, acudiendo a la probabilidad condicional, se define
  \begin{equation*}
    p(M1 \mid D)=\frac{p(D \mid M1)P(M1)}{p(D \mid M1)P(M1)+p(D \mid M2)P(M2)+p(D \mid M3)P(M3)}
    \end{equation*}
\end{enumerate}

La anterior función de probabilidad se conoce con el nombre de regla de probabilidad de Bayes y, aparte de ser el baluarte de la mayoría de investigaciones estadísticas que se plantean hoy en día, ha sido la piedra de tropiezo de muchos investigadores radicales que trataron de estigmatizar este enfoque tildando a sus seguidores de mediocres matemáticos y pobres probabilistas afirmando que la regla de probabilidad de Bayes es sólo un artilugio diseñado para divertirse en el tablero.

Pues bien, la interpretación de la regla de bayes se puede realizar en el sentido de actualización de la estructura probabilística que gobierna el experimento. Y esta actualización tiene mucho sentido práctico cuando se cae en la cuenta de que la vida real está llena de calibradores y que las situaciones generadas son consecuencia de algún cambio estructural. De esta forma, el conocimiento de la probabilidad de que el artículo sea producido por la primera máquina se actualiza al conocer que este artículo particular es defectuoso y de esta manera calibra la estructura aleatoria que existe detrás del contexto de la fábrica de bolígrafos. Aparte de servir para resolver problemas como el anteriormente mencionado, la regla de bayes ha marcado el comienzo de un nuevo enfoque de análisis de datos, no solamente porque hace explícitas las relaciones causales entre los procesos aleatorios, sino también porque facilita la inferencia estadística y la interpretación de los resultados.
\end{example}

En el campo de la medicina, también se ha visto un gran número de la
aplicación del teorema de Bayes. A continuación se enuncia uno de ellos:

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-12}{}{\label{exm:unnamed-chunk-12} }El Grupo de Trabajo de Servicios Preventivos de los Estados Unidos (USPSTF) hizo unas nuevas y controversiales recomendaciones \href{https://www.uspreventiveservicestaskforce.org/uspstf/recommendation/breast-cancer-screening}{recomendaciones} sobre la detección del cáncer de mama dentro de los cuales no recomienda el examen de la mamografía en mujeres entre 40 y 49 años de edad, afirmando que la práctica bienal de este examen debe ser una decisión individual según el contexto particular de la paciente. Por otro lado, la USPSTF sí recomienda tal práctica de forma bienal en grupos de mujeres de entre 50 y 74 años de edad, puesto que no encontró suficiente evidencia de beneficio o daño adicional en realizar este examen en mujeres mayores a los 74 años. Además, también recomendó \emph{no} realizar auto exámanes de senos, contrario a las recomendaciones y consejos que da la mayoría de los profesionales y organizaciones de la salud, incluyendo la \emph{Amerian Cancer Society}. Como información adicional, se sabe que:

\begin{itemize}
\tightlist
\item
  Los expertos estiman que un 12.3\% de las mujeres desarrollan formas invasivas del cáncer de mama durante la vida.
\item
  La probabilidad de que una mujer desarrolle el cáncer de mama entre los 40 y los 49 años de edad es 1 en 69, y esta probabilidad aumenta a medida que envejezca, de tal forma que llega a ser de 1 en 38 en mujeres de entre 50 y 59 años.
\item
  El cáncer de mama es más difícil de detectar en mujeres jóvenes puesto que el tejido mamario es más denso y fibroso. Los expertos estiman que la tasa de un falso positivo es de 97.8 por cada 1000 mujeres de 40 y 49 años, y esta tasa disminuye a 86.6 por cada 1000 mujeres entre 50 y 59 años.
\item
  La tasa de un falso negativo es de 1 por cada 1000 mujeres de 40 y 49 años, y es de 1.1 por cada 1000 mujeres entre 50 y 59 años.
\end{itemize}

Resumiendo las anteriores afirmaciones, tenemos las siguientes probabilidades

\begin{longtable}[]{@{}lll@{}}
\toprule
Probabilidad & 40 - 49 & 50 - 59 años \\
\midrule
\endhead
Cáncer & 1/69=0.01449 & 1/38=0.02632 \\
No cáncer & 68/69=0.9855 & 37/38=0.97368 \\
Positivo \(\mid\) No cáncer & 0.0978 & 0.0866 \\
Negativo \(\mid\) No cáncer & 0.9022 & 0.9134 \\
Positivo \(\mid\) Cáncer & 0.999 & 0.9989 \\
Negativo \(\mid\) Cáncer & 0.001 & 0.0011 \\
\bottomrule
\end{longtable}

Utilizando la regla de Bayes, se puede calcular las siguientes probabilidades para mujeres de 40 y 49 años:
\begin{align*}
P(\text{Cáncer}|\text{Positivo})&=\frac{P(\text{Positivo}|\text{Cáncer})P(\text{Cáncer})}{P(\text{Positivo}|\text{Cáncer})P(\text{Cáncer})+P(\text{Positivo}|\text{No cáncer})P(\text{No cáncer})}\\
&=\frac{0.999*0.01449}{0.999*0.01449+0.0978*0.9855}\\
&=0.1305
\end{align*}

\begin{align*}
P(\text{Cáncer}|\text{Negativo})&=\frac{P(\text{Negativo}|\text{Cáncer})P(\text{Cáncer})}{P(\text{Negativo}|\text{Cáncer})P(\text{Cáncer})+P(\text{Negativo}|\text{No cáncer})P(\text{No cáncer})}\\
&=\frac{0.001*0.01449}{0.001*0.01449+0.9022*0.9855}\\
&=0.0000163
\end{align*}

Similarmente, se puede calcular estas dos probabilidades para las mujeres de 50 y 59 años.

\begin{longtable}[]{@{}lll@{}}
\toprule
Probabilidad & 40 - 49 años & 50 - 59 años \\
\midrule
\endhead
Cáncer \(\mid\) Positivo & 0.1305985 & 0.23769 \\
No cáncer \(\mid\) Positivo & 0.8694223 & 0.7623123 \\
Cáncer \(\mid\) Negativo & 0.0000163 & 0.0000326 \\
No cáncer \(\mid\) Negativo & 0.9999837 & 0.9999674 \\
\bottomrule
\end{longtable}

Los anteriores resultados muestran cómo cambia la probabilidad de tener cáncer al condicionar en los resultados de la pruebe. Entre estos valores se puede ver que, con un resultado positivo en el examen, la probabilidad de tener efectivamente el cáncer es aproximadamente diez puntos porcentuales más bajo en mujeres de edad de 40 y 49 años, de donde se puede sustentar la recomendación de no efectuar este examen en mujeres de este rango de edad.
\end{example}

\hypertarget{inferencia-bayesiana}{%
\chapter{Inferencia bayesiana}\label{inferencia-bayesiana}}

El enfoque bayesiano, además de especificar un modelo para los datos
observados \(\mathbf{Y}=(y_1,\ldots,y_n)\) dado un vector de parámetros
desconocidos \(\boldsymbol \theta=(\theta_1,\ldots,\theta_K)\), usualmente en forma
de densidad condicional \(p(\mathbf{Y} \mid \boldsymbol \theta)\), supone que
\(\boldsymbol \theta\) es aleatorio y que tiene un densidad \emph{previa}
\(p(\boldsymbol \theta\mid \boldsymbol \eta)\), donde \(\boldsymbol \eta\) es un vector de hiper-parámetros.
De esta forma, la inferencia concerniente a \(\boldsymbol \theta\) se basa en una
densidad \emph{posterior} \(p(\boldsymbol \theta\mid \mathbf{Y})\).

En términos de estimación, inferencia y predicción, el enfoque Bayesiano
supone dos momentos o etapas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Antes de la recolección de las datos, en donde el investigador propone,
  basado en su conocimiento, experiencia o fuentes externas, una
  distribución de probabilidad previa para el parámetro de interés.
  Con esta distribución es posible calcular estimaciones puntuales y por
  intervalo con el fin de confirmar que la distribución propuesta se
  ajusta al problema de estudio. En esta etapa, basados en la distribución
  previa, también es posible hacer predicciones de cantidades
  observables.
\item
  Después de la recolección de los datos. Siguiendo el teorema de Bayes,
  el investigador actualiza su conocimiento acerca del comportamiento
  probabilístico del parámetro de interés mediante la distribución
  posterior de este. Con esta distribución es posible calcular
  estimaciones puntuales y por intervalo justo como en el enfoque
  frecuentista. En esta etapa, basados en la distribución
  posterior, también es posible hacer predicciones de cantidades
  observables y pruebas de hipótesis acerca de la adecuación del mejor
  modelo a los datos observados.
\end{enumerate}

\hypertarget{inferencia-previa}{%
\subsubsection*{Inferencia previa}\label{inferencia-previa}}
\addcontentsline{toc}{subsubsection}{Inferencia previa}

Con las anteriores expresiones es posible calcular la probabilidad
previa de que \(\boldsymbol \theta\) esté en una determinada región \(G\) como
\begin{equation}
Pr(\boldsymbol \theta\in G)=\int_G p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}

En esta primera etapa también es posible calcular, con fines
confirmatorios \citep{Carlin96}, la estimación puntual para el vector
\(\boldsymbol \theta\) dada por alguna medida de tendencia central para la
distribución \(p(\boldsymbol \theta\mid \boldsymbol \eta)\). En particular, si se escoge la
media, entonces

\begin{equation}
(\#eq:est.prio)
\hat{\boldsymbol \theta}=E(\boldsymbol \theta)=\int \boldsymbol \theta\ p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}

También es posible calcular una región \(C\) de \(100\times(1-\alpha)%
\) de
credibilidad\footnote{La interpretación de las regiones de credibilidad
  bayesianas difiere de la interpretación de las regiones de confianza
  frecuentistas. La primera se refiere a la probabilidad de que el
  verdadero valor de \(\boldsymbol \theta\) esté en la región. La segunda se refiere a
  la región de la distribución muestral para \(\boldsymbol \theta\) tal que, dados los
  datos observados, se podría esperar que el \(100\times\alpha%
  \) de las
  futuras estimaciones de \(\boldsymbol \theta\) no pertenecieran a dicha región.} para
\(\boldsymbol \theta\) que en esta primera etapa es tal que \begin{equation}
1-\alpha \leq Pr(\boldsymbol \theta\in C)=\int_Cp(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}

\hypertarget{inferencia-posterior}{%
\subsubsection*{Inferencia posterior}\label{inferencia-posterior}}
\addcontentsline{toc}{subsubsection}{Inferencia posterior}

Una vez recolectados los datos, se actualizan las cálculos descritos en
la sección anterior. Podemos calcular la probabilidad posterior
de que \(\boldsymbol \theta\) esté en la región \(G\) dados los datos observados como
\begin{equation}
Pr(\boldsymbol \theta\in G  \mid \mathbf{Y})=\int_G p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}

También es posible calcular la estimación puntual para el vector
\(\boldsymbol \theta\) dados los datos observados. Ésta está dada por alguna medida
de tendencia central para la distribución \(p(\boldsymbol \theta\mid \mathbf{Y})\).
En particular, si se escoge la media, entonces \begin{equation}
\hat{\boldsymbol \theta}=E(\boldsymbol \theta\mid \mathbf{Y})=\int \boldsymbol \theta\ p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}

La región \(C\) de \(100\times(1-\alpha)%
\) de credibilidad es tal que
\begin{equation}
1-\alpha \leq Pr(\boldsymbol \theta\in C \mid \mathbf{Y})=\int_Cp(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}

También la distribución posterior del parámetro \(\boldsymbol \theta\) es útil para
el procedimiento de juzgamiento de hipótesis en el ámbito del análisis
bayesiano. Esto se lleva a cabo por medio del factor de Bayes que se
presentará más adelante.

\hypertarget{inferencia-predictiva}{%
\subsubsection*{Inferencia predictiva}\label{inferencia-predictiva}}
\addcontentsline{toc}{subsubsection}{Inferencia predictiva}

En términos de inferencia predictiva existen dos etapas que cubren las
\emph{actuales} suposiciones acerca del vector de parámetros \(\boldsymbol \theta\).
En una primera etapa - antes de la observación de los datos - la
suposición \emph{actual} de \(\boldsymbol \theta\) está dada por la densidad
previa \(p(\boldsymbol \theta\mid \boldsymbol \eta)\). En estos términos, utilizando el
Resultado \ref{prp:Res131}, la distribución predictiva previa de
\(\mathbf{Y}\) está dada por

\begin{equation}
p(\mathbf{y})=\int p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}

La segunda etapa - después de la recolección de los datos - actualiza
las suposiciones acerca de \(\boldsymbol \theta\) puesto que ahora éste sigue una
distribución posterior dada por \eqref{eq:Bayes}. Por lo tanto, la
distribución predictiva posterior de \(\mathbf{Y}\) está dada por

\begin{align}
\label{eq:predictpos}
p(\tilde{\mathbf{y}} \mid \mathbf{Y})&=\int p(\tilde{\mathbf{y}},\boldsymbol \theta\mid \mathbf{y})\ d\boldsymbol \theta\notag \\
&=\int p(\tilde{\mathbf{y}} \mid \boldsymbol \theta,\mathbf{Y})p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta\notag \\
&=\int p(\tilde{\mathbf{y}} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{align} donde \(p(\tilde{\mathbf{y}} \mid \boldsymbol \theta)\) es la
distribución de los datos evaluada en los nuevos valores
\(\tilde{\mathbf{y}}\). La segunda línea de la anterior igualdad se
obtiene utilizando el resultado \ref{prp:Res121} y la última línea se
obtiene del resultado \ref{prp:Res122} de la independencia condicional.

\hypertarget{la-distribuciuxf3n-previa}{%
\section{La distribución previa}\label{la-distribuciuxf3n-previa}}

La escogencia de una distribución previa es muy importante en el
análisis bayesiano, puesto que ésta afecta directamente en la
distribución posterior, tal como lo ilustra el teorema de Bayes. En
primer lugar, la distribución previa debe describir adecuadamente los
conocimientos previos sobre los parámetros objetivos de estimación. Por
ejemplo, si se cree que un parámetro toma valores cercanos a 10,
entonces la distribución escogida para representarla también debe tomar
valores cercanos a 10, como podría ser una distribución normal centrada en
ese valor. Por otro lado, dado que en la literatura existe un gran
número de distribuciones, algunas muy similares entre ellas, a la hora
de escoger una distribución previa también se debe tener en cuenta las
implicaciones a la hora de efectuar cálculos de la estimación puntual o
del intervalo de crediblidad, procurando en la mayoría de casos, obtener
una distribución posterior fácil de manejar. A continuación exponemos
algunos aspectos generales relacionados con las distribuciones previas.

\hypertarget{distribuciones-conjugadas}{%
\subsection{Distribuciones conjugadas}\label{distribuciones-conjugadas}}

Como se verá en los capítulos siguientes, muchos problemas de inferencia
bayesiana comparten la agradable cualidad de que la forma funcional de
la distribución previa para el parámetro de interés resulta ser
la misma de la distribución posterior. Por ejemplo:

\begin{itemize}
\item
  Cuando se tiene una muestra aleatoria de variables con distribución
  Bernoulli de parámetro \(\theta\), es factible pensar que una distribución
  previa apropiada para este parámetro es la distribución Beta;
  bajo este escenario, la distribución posterior también resulta
  ser Beta.
\item
  En el caso en que se quiera modelar el parámetro \(\theta\) concerniente a
  una variable aleatoria con distribución Poisson, es posible asignar como
  candidata para distribución previa a la distribución Gamma; en
  este caso la distribución posterior también resulta ser Gamma.
\end{itemize}

Las distribuciones conjugadas son deseadas en el análisis bayesiano pues
en primer lugar, la distribución posterior del parámetro \(\theta\) es
considerada como la actualización del conocimiento acerca de este
después de la recolección de los datos, entonces al tener la misma forma
funcional que la distribución previa, pueden ser comparadas y así
ver claramente cómo es la influencia de los datos observados sobre la
creencia inicial acerca de \(\theta\); en segundo lugar, el hecho de que la
distribución posterior sea de la misma forma funcional que la previa
permite que la actualización de información se pueda llevar a cabo
sistemáticamente, pues cada vez que se observan nuevos datos, la
anterior distribución posterior puede ser tomada como la distribución
previa y así producir una nueva distribución posterior.

A continuación exponemos la definición rigurosa de las distribuciones
conjungadas y algunos tópicos relacionados.

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-1}{}{\label{def:unnamed-chunk-1} }Sea \(\mathcal{F}=\{p(\mathbf{Y} \mid \boldsymbol \theta)\}\) una familia de distribuciones de probabilidad. Una familia de distribuciones \(\mathcal{P}\) se dice conjugada con respecto a \(\mathcal{F}\) si para toda distribución previa \(p(\boldsymbol \theta) \in \mathcal{P}\) y para toda distribución de muestreo o verosimilitud de las observaciones \(p(\mathbf{Y} \mid \boldsymbol \theta)\), \(p(\boldsymbol \theta\mid \mathbf{Y})\) también pertenece a la familia \(\mathcal{P}\).
\end{definition}

Esta definición es, en la mayoría de los casos prácticos, muy útil. Sin
embargo, \citet{Migon} describe los siguientes dos casos en donde
esta definición es completamente inútil:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \emph{Caso amplio}: sea
  \(\mathcal{P}=\{\text{Todas las distribuciones de probabilidad}\}\) y
  \(\mathcal{F}\) cualquier familia de distribuciones de probabilidad.
  Entonces \(\mathcal{P}\) es conjugada con respecto a \(\mathcal{F}\) puesto
  que toda posible distribución posterior será un miembro de
  \(\mathcal{P}\).
\item
  \emph{Caso restringido}: sea \(\mathcal{P}=\{p \mid p(\theta=\theta_0)=1\}\),
  esto es, \(\mathcal{P}\) corresponde a todas las distribuciones
  concentradas en un punto. Sea \(\mathcal{F}\) cualquier familia de
  distribuciones de probabilidad. De esta manera, la distribución
  posterior de \(\theta\) estará dada por
\end{enumerate}

\begin{align*}
    p(\theta \mid Y)\propto
    p(Y \mid \theta)p(\theta)
    &=
    \begin{cases}
    p(Y \mid \theta)\times 1 \ \ \ \ \text{si $\theta=\theta_0$}\\
    p(Y \mid \theta)\times 0 \ \ \ \ \text{si $\theta\neq\theta_0$}\\
    \end{cases}\\
    &=
    \begin{cases}
    p(Y \mid \theta) \ \ \ \ \text{si $\theta=\theta_0$}\\
    0           \ \ \ \ \text{si $\theta\neq\theta_0$}\\
    \end{cases}
\end{align*}

De lo anterior y dado que \(\int p(\theta \mid Y)\ d\theta=1\), entonces
\(p(Y \mid \theta)=1\) si y sólo si \(\theta=\theta_0\). Con el anterior
razonamiento, se concluye que \(\mathcal{P}\) es conjugada con respecto a
\(\mathcal{F}\).

Por lo tanto, se deben buscar distribuciones previas que sean
conjugadas de una forma tan amplia que permita proponer una distribución
previa adecuada, pero al mismo tiempo tan restringida para que la
definición de conjugada tenga sentido práctico. Ahora introducimos una
familia de distribuciones muy importante para el desarrollo de la teoría
estadística, tanto en el ámbito bayesiano como en el clásico.

\hypertarget{familia-exponencial}{%
\subsection{Familia exponencial}\label{familia-exponencial}}

Dependiendo de la naturaleza del parámetro \(\theta\), la familia
exponencial puede ser uniparamétrica o multiparamétrica. En el primer
caso, una distribución de probabilidad pertenece a la familia
exponencial uniparamétrica si se puede escribir de la forma

\begin{equation}
\label{eq:uniexpo}
p(Y \mid \theta)=\exp\{d(\theta)T(y)-c(\theta)\}h(y)
\end{equation}

donde \(T(y)\) y \(h(y)\) son funciones que dependen de \(y\) únicamente, y
\(d(\theta)\) y \(c(\theta)\) son funciones que depende de \(\theta\)
únicamente. Análogamente, una distribución de probabilidad pertenece a
la familia exponencial multi-paramétrica si se puede escribir de la
forma

\begin{equation}
\label{eq:multiexpo}
p(Y \mid \boldsymbol \theta)=\exp\{\mathbf{d}(\boldsymbol \theta)'\mathbf{T}(y)-c(\boldsymbol \theta)\}h(y)
\end{equation} donde \(\mathbf{T}(y)\) y \(\mathbf{d}(\boldsymbol \theta)\) son
funciones vectoriales, \(h(y)\) y \(c(\boldsymbol \theta)\) son funciones reales.

La ventaja de la familia exponencial radica en que es una familia
relativamente restringuida de distribuciones que a la vez conservan la
propiedad de ser distribuciones conjugadas, tal como muestra el
siguiente resultado:

\begin{proposition}
\protect\hypertarget{prp:FE1}{}{\label{prp:FE1} }Sea \(Y\) una variable aleatoria con función de densidad perteneciente a la familia exponencial uniparamétrica, entonces la familia exponencial uniparamétrica es conjugada con respecto a sí misma.
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}Observando la expresión \eqref{eq:uniexpo}, se debe encontrar una distribución previa en la familia exponencial uniparamétrica, tal que la distribución posterior, resultante del producto de la distribución previa con la verosimilitud sea también miembro de la familia exponencial uniparamétrica. Con base en lo anterior, la distribución previa, parametrizada por el hiperparámetro \(\alpha\), debe ser una función exponencial de los términos \(d(\theta)\) y \(c(\theta)\) como lo afirma \citet{Jordan}. Esto es,
\begin{equation}
p(\theta \mid \alpha)\propto\exp\{w(\alpha) d(\theta)-\delta c(\theta)\},
\end{equation}

donde \(\delta\) es una constante real (posiblemente dependiente de \(\alpha\)). Por otro lado, para garantizar que \(p(\theta \mid \alpha)\) sea una auténtica función de densidad se normaliza de la siguiente manera
\begin{equation}
p(\theta \mid \alpha)=\frac{1}{k(\alpha,\delta)}\exp\{w(\alpha) d(\theta)-\delta c(\theta)\},
\end{equation}

con
\begin{equation*}
k(\alpha,\delta)=\int\exp\{w(\alpha) d(\theta)-\delta c(\theta)\} \ d\theta.
\end{equation*}

De esta manera, no es difícil comprobar que la definición de distribución previa, parametrizada por el hiper-parámetro \(\alpha\), pertenece a la familia exponencial, puesto que
\begin{equation}
p(\theta \mid \alpha)=\exp\{\underbrace{w(\alpha)}_{d(\alpha)} \underbrace{d(\theta)}_{T(\theta)} - \underbrace{\ln k(\alpha,\delta)}_{c(\alpha)}\}\underbrace{\exp\{-\delta c(\theta)\}}_{h(\theta)}.
\end{equation}

Por otro lado, del teorema de Bayes se tiene que
\begin{align*}
p(\theta \mid Y) &\propto p(Y \mid \theta)p(\theta \mid \alpha)\\
&=\exp\{w(\alpha) d(\theta) + d(\theta)T(y) - c(\theta) -\ln k(\alpha,\delta) \}\exp\{-\delta c(\theta)\}h(y)\\
&=\exp\{\underbrace{[\alpha+T(y)]}_{d(y)} \underbrace{d(\theta)}_{T(\theta)} -\underbrace{[\ln k(\alpha,\delta)-\ln h(y)]}_{c(y)}\} \underbrace{\exp\{-(\delta+1) c(\theta)\}}_{h(\theta)}\\
&\propto \exp\{[w(\alpha)+T(y)] d(\theta)\}\exp\{-(\delta+1) c(\theta)\}.
\end{align*}

Por lo tanto, la distribución posterior resultante también pertenece a la familia exponencial uniparamétrica.
\end{proof}

La extensión del anterior resultado puede ser extendedida para el caso en el que se cuenta con una muestra aleatoria de observaciones, tal como se expone a
continuación:

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-3}{}{\label{prp:unnamed-chunk-3} }Sean \(\mathbf{Y}=\{Y_1, \ldots, Y_n\}\) una muestra aleatoria de variables distribuidas con función de densidad común perteneciente a la familia exponencial uniparamétrica, cuya función de densidad conjunta \(p(\mathbf{Y} \mid \theta)\) también pertenece a la familia exponencial uniparamétrica. Bajo las anteriores condiciones la familia exponencial uniparamétrica es conjugada con respecto a sí misma.
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}La demostración es inmediata utilizando el resultado anterior y notando que la forma funcional de la densidad conjunta para \(\mathbf{Y}\) es
\begin{equation}
p(\mathbf{Y} \mid \theta)=\exp\left\{d(\theta)\sum_{i=1}^nT(y_i)-nc(\theta)\right\}\prod_{i=1}^nh(y_i)
\end{equation}
la cual hace parte de la familia exponencial.
\end{proof}

Otra extensión del resultado \ref{prp:FE1} corresponde al caso cuando la
distribución de la observación está reparametrizado por un vector de
parámetros \(\boldsymbol \theta\). A continuación se expone el resultado y la prueba
correspondiente.

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-5}{}{\label{prp:unnamed-chunk-5} }Sea \(Y\) una variable aleatoria con función de densidad perteneciente a la familia exponencial multiparamétrica. Sea \(\boldsymbol \theta\) el parámetro de interés con distribución previa parametrizada por un vector de hiperparámetros \(\boldsymbol \eta\) y perteneciente a la familia exponencial multiparamétrica. Entonces la familia exponencial multiparamétrica es conjugada con respecto a sí misma.
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}En primer lugar, la distribución de probabilidad de \(Y\) perteneciente a la familia exponencial multiparamétrica está dada por \eqref{eq:multiexpo}. Siguiendo el mismo razonamiento de la demostración del Resultado \ref{prp:FE1}, la distribución previa del parámetro de interés debe estar definida de la siguiente manera
\begin{equation}
p(\boldsymbol \theta\mid \boldsymbol \eta)=\exp\left\{\underbrace{w(\boldsymbol \eta)'}_{\mathbf{d}(\boldsymbol \eta)}
\underbrace{\mathbf{d}(\boldsymbol \theta)}_{\mathbf{T}(\boldsymbol \theta)} - \underbrace{\ln k(\boldsymbol \eta,\delta)}_{c(\boldsymbol \eta)}\right\}\underbrace{\exp\{-\delta c(\boldsymbol \theta)\}}_{h(\boldsymbol \theta)},
\end{equation}

con
\begin{equation*}
k(\boldsymbol \eta,\delta)=\int\exp\{w(\boldsymbol \eta)'\mathbf{d}(\boldsymbol \theta)-\delta c(\boldsymbol \theta)\} \ d\boldsymbol \theta.
\end{equation*}

Utilizando el teorema de Bayes, se tiene que, la distribución posterior del parámetro \(\theta\) es
\begin{align*}
p(\boldsymbol \theta\mid Y) &\propto p(Y \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\\
&= \exp\{\mathbf{T}(y)'\mathbf{d}(\boldsymbol \theta) - c(\boldsymbol \theta) + w(\boldsymbol \eta)' \mathbf{d}(\boldsymbol \theta) - \delta c(\boldsymbol \theta) - \ln k(\boldsymbol \eta,\delta) +\ln h(y)\}\\
& =
\exp\left\{\underbrace{(w(\boldsymbol \eta)+\mathbf{T}(y))'}_{\mathbf{d}(y)}
\underbrace{\mathbf{d}(\boldsymbol \theta)}_{\mathbf{T}(\theta)} - \underbrace{\left[\ln k(\boldsymbol \eta,\delta)-\ln h(y)\right]}_{c(y)}\right\}\underbrace{\exp\{-(\delta+1)c(\boldsymbol \theta)\}}_{h(\boldsymbol \theta)}
\end{align*}

La anterior expresión también hace parte de la familia exponencial biparamétrica y con esto se concluye la demostración
\end{proof}

Nótese que el anterior resultado también cobija situaciones donde la
verosimilitud sea perteneciente a la familia exponencial uniparamétrica.
Más aún, a cualquier familia exponencial multiparamétrica de orden menor
o igual al orden de la distribución previa.

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-7}{}{\label{prp:unnamed-chunk-7} }Sean \(\mathbf{Y}=\{Y_1, \ldots, Y_n\}\) una muestra aleatoria con función de densidad conjunta o verosimilitud dada por \eqref{eq:multiexpo}. Bajo este escenario la familia exponencial multi-paramétrica es conjugada con respecto a sí misma.
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}La demostración sigue los mismos lineamentos que la demostración del resultado anterior concluyendo que la distribución posterior de \(\boldsymbol \theta\) está dada por
\begin{align*}
&p(\boldsymbol \theta\mid \mathbf{Y}) \propto p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\\
&= \exp\left\{\sum_{i=1}^n\mathbf{T}(y_i)'\mathbf{d}(\boldsymbol \theta) - nc(\boldsymbol \theta) + \boldsymbol \eta' \mathbf{d}(\boldsymbol \theta) - \delta c(\boldsymbol \theta) - \ln k(\boldsymbol \eta,\delta) +\sum_{i=1}^n\ln h(y_i)\right\}\\
& =\exp\left\{\underbrace{\left(\boldsymbol \eta+\sum_{i=1}^n\mathbf{T}(y_i)\right)'}_{\mathbf{d}(\mathbf{y})}
\underbrace{\mathbf{d}(\boldsymbol \theta)}_{\mathbf{T}(\theta)} - \underbrace{\left[\ln k(\boldsymbol \eta,\delta)-\sum_{i=1}^n\ln h(y_i)\right]}_{c(\mathbf{y})}\right\} \\
&  \times \underbrace{\exp\left\{-(\delta+n)c(\boldsymbol \theta)\right\}}_{h(\boldsymbol \theta)}
\end{align*}
La anterior expresión también hace parte de la familia exponencial.
\end{proof}

Ahora, estudiamos las expresiones relacionadas con la distribución
predictiva de nuevas observaciones dentro del contexto de la familia
exponencial:

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-9}{}{\label{prp:unnamed-chunk-9} }Sea \(Y\) una variable aleatoria con función de densidad perteneciente a la familia exponencial, dada por \eqref{eq:uniexpo}. Sea \(\theta\) el parámetro de interés con distribución previa en la familia exponencial biparamétrica. La distribución predictiva previa de \(Y\) está dada por

\begin{equation}
p(Y)=\frac{k(\alpha+T(y),\delta+1)}{k(\alpha,\delta)}h(y)
\end{equation}

donde
\begin{equation*}
k(a,b)=\int \exp\{w(a) d(\theta)-b c(\theta)\}\ d\theta
\end{equation*}
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}\begin{align*}
p(Y)&=\int p(\theta)p(Y \mid \theta)\ d\theta\\
&=\int \exp\{w(\alpha) d(\theta)-\ln k(\alpha,\delta)-\delta c(\theta)\}\exp\{d(\theta)T(y)-c(\theta)\}h(y)d\theta\\
&=\frac{h(y)}{k(\alpha,\delta)}\int \exp\{[w(\alpha)+T(y)]d(\theta)-(\delta+1)c(\theta)\}d\theta\\
&=\frac{k(\alpha+T(y),\delta+1)h(y)}{k(\alpha,\delta)}
\end{align*}

donde
\begin{equation*}
k(\alpha,\delta)=\int \exp\{w(\alpha) d(\theta)-\delta c(\theta)\}\ d\theta
\end{equation*}

y
\begin{equation*}
k(\alpha+T(y),\delta+1)=\int \exp\{[w(\alpha)+T(y)]d(\theta)-(\delta+1)c(\theta)\} \ d\theta.
\end{equation*}
\end{proof}

La extensión al caso de contar con una muestra aleatoria de
observaciones se encuentra a continuación:

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-11}{}{\label{prp:unnamed-chunk-11} }Sea \(\mathbf{Y}=\{Y_1\ldots,Y_n\}\) una muestra aleatoria con función de densidad conjunta perteneciente a la familia exponencial, dada por \eqref{eq:multiexpo}. Sea \(\theta\) el parámetro de interés con distribución previa exponencial multiparamétrica. La distribución predictiva previa de \(\mathbf{Y}\) está dada por

\begin{equation}
p(\mathbf{Y})=\frac{k(\alpha+T(\mathbf{y}),\delta+n)}{k(\alpha,\beta)}h(\mathbf{y})
\end{equation}
donde \(k\) se define tal como en el resultado anterior.
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}La prueba se tiene de inmediato siguiendo los lineamentos de la demostración del anterior resultado.
\end{proof}

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-13}{}{\label{prp:unnamed-chunk-13} }En términos de la distribución predictiva posterior, se tiene que para una sola observación \(\tilde{y}\), ésta está dada por
\begin{equation}
p(\tilde{y} \mid Y)=\frac{k(\alpha+T(y)+T(\tilde{y}),\delta+2)}{k(\alpha+T(y),\delta+1)}h(\tilde{y})
\end{equation}
y en el caso en donde se tiene una muestra aleatoria, entonces la distribución predictiva posterior para una nueva muestra \(\tilde{\mathbf{y}}=\{\tilde{y}_1,\ldots,\tilde{y}_{n^*}\}\) de tamaño \(n^*\) está dada por
\begin{equation}
p(\tilde{\mathbf{y}} \mid \mathbf{Y})=
\frac{k(\alpha+T(\mathbf{y})+T(\tilde{\mathbf{y}}),\delta+n+n^*)}
{k(\alpha+T(\mathbf{y}),\delta+n)}h(\tilde{\mathbf{y}})
\end{equation}
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}De la definición de distribución predictiva posterior dada por la expresión \eqref{eq:predictpos} se tiene que
\begin{align*}
p(\tilde{y} \mid Y)&=\int p(\tilde{y} \mid \theta)p(\theta \mid y)\ d\theta\\
&=\int \exp\{d(\theta)T(\tilde{y})-c(\theta)\}h(\tilde{y})\dfrac{\exp\{[w(\alpha)+T(y)]d(\theta)-(\delta+1)c(\theta)\}}{k(\alpha+T(y),\delta+1)}\ d\theta\\
&=\frac{h(\tilde{y})}{k(w(\alpha)+T(y),\delta+1)}\int \exp\{[\alpha+T(y)+T(\tilde{y})]d(\theta)-(\delta+2)c(\theta)\}\ d\theta\\
&=\frac{k(\alpha+T(y)+T(\tilde{y}),\delta+2)}{k(\alpha+T(y),\delta+1)}h(\tilde{y}),
\end{align*}

con
\begin{equation*}
k(\alpha+T(y)+T(\tilde{y}),\delta+2)=\int \exp\{[w(\alpha)+T(y)+T(\tilde{y})]d(\theta)-(\delta+2)c(\theta)\}\ d\theta.
\end{equation*}

La demostración para la nueva muestra se lleva a cabo de manera análoga.
\end{proof}

\hypertarget{distribuciones-previas-no-informativas}{%
\subsection{Distribuciones previas no informativas}\label{distribuciones-previas-no-informativas}}

Cuando no existe una base poblacional sobre el parámetro de interés o
cuando existe total ignorancia de parte del investigador acerca del
comportamiento de probabilístico del parámetro, es necesario definir
distribuciones previas que sean no informativas. Es decir, que jueguen un papel mínimo en términos de
influencia en la distribución posterior. Una característica de
estas distribuciones es que su forma es vaga, plana o difusa.
Por tanto la pregunta de interés que surge en este instante es: ¿cómo
seleccionar distribuciones previas no
informativas\footnote{Existen muchas denominaciones para las distribuciones uniformes que no son informativas. Por ejemplo, \citet{BoxTiao} proponen el nombre de distribuciones localmente uniformes para asegurar que cumplan con las condiciones de función de densidad de probabilidad en un rango particular del espacio paramétrico. Sin embargo, en este texto vamos a utilizar la expresión \emph{no informativa} al referirse a este tipo de distribuciones a previa.}
sobre el parámetro de interés?

En los anteriores términos, la distribución uniforme define una
distribución previa que cumple con las características de no
información en la mayoría de escenarios. Específicamente en aquellos
problemas en donde el parámetro de interés está limitado a un espacio de
muestreo acotado. Por ejemplo, en la distribución Binomial, el parámetro
de interés está limitado al espacio de muestreo \([0,1]\). Sin embargo, no
en todos los problemas encaja la distribución uniforme. Nótese, por
ejemplo, que en el caso en que la distribución exponencial se acomode a
los datos como candidata a verosimilitud, entonces el espacio de
muestreo del parámetro de interés estaría dado por \((0,\infty)\) en cuyo
caso la distribución uniforme no sería conveniente puesto que sería una
distribución impropia en el espacio de muestreo del parámetro de
interés. Es decir

\begin{equation*}
\text{Si } p(\theta)\propto k\ I_{\Theta}(\theta) \text{, entonces } \int_{\Theta}p(\theta) \ d(\theta)\longrightarrow \infty
\end{equation*}

donde \(\Theta\) denota espacio de muestreo del parámetro \(\theta\) e \(I\)
denota la función indicadora. Por otro lado, una característica
importante que debe tener una distribución previa no informativa
es que sea invariante en términos de transformaciones matemáticas. Es
decir, si el parámetro de interés es \(\theta\) con distribución
previa no informativa dada por \(p(\theta)\), y sea
\(\phi=h(\theta)\) una transformaición de \(\theta\) por medio de la función
\(h\), entonces la distribución previa de \(\phi\) también debería
ser no informativa. Sin embargo, la teoría de probabilidad afirma que la
distribución de probabilidad de una transformación está dada por

\begin{equation}
\label{eq:teotransf}
p(\phi)=p(\theta) \mid \frac{d\theta}{d\phi} \mid =p(\theta) \mid h'(\theta) \mid ^{-1}
\end{equation}

y claramente si la función \(h\) no es una función lineal, entonces los
resultados encontrados por medio de este enfoque indicarían que la
distribución previa \(p(\phi)\) sería informativa contradiciendo
los supuestos de \(p(\theta)\). El siguiente ejemplo ilustra este
planteamiento:

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-15}{}{\label{exm:unnamed-chunk-15} }Suponga que el parámetro de interés es \(\theta\) y que está restringido a un espacio de muestreo dado por el intervalo \([0,1]\). Si se supone completa ignorancia acerca del comportamiento del parámetro, entonces una buena opción, con respecto a la distribución previa, sería la distribución uniforme en el intervalo \([0,1]\). Es decir, la distribución previa no informativa estaría dada por
\begin{equation*}
p(\theta) = I_{[0,1]}(\theta)
\end{equation*}

Suponga ahora que existe una transformación del parámetro de interés dada por \(\phi=h(\theta)=\ln(\theta)\). Por tanto, siguiendo \eqref{eq:teotransf} se tiene que la distribución de \(\phi\) está dada por
\begin{equation*}
p(\phi)=I_{(-\infty,0)}(\phi)e^{\phi}
\end{equation*}

la cual es informativa con respecto al parámetro \(\phi\). Sin embargo, es el mismo problema y existe una contradicción en términos de que para \(\theta\) se desconoce todo, pero para una función \(\phi\) existe evidencia de que el parámetro se comporta de cierta manera.
\end{example}

Para palear las anteriores diferencias, es necesario encontrar una
distribución previa no informativa que sea invariante a
transformaciones matemáticas. La distribución previa no
informativa de Jeffreys, definida a continuación, cuenta con esta
agradable propiedad.

\begin{definition}
\protect\hypertarget{def:unnamed-chunk-16}{}{\label{def:unnamed-chunk-16} }Si la verosimilitud de los datos está determinada por un único parámetro \(\theta\), la distribución previa no informativa de Jeffreys tiene distribución de probabilidad dada por
\begin{equation}
p(\theta)\propto (I(\theta))^{1/2}
\end{equation}

con \(I(\theta)\) la información de Fisher definida como
\begin{align*}
I(\theta)&=E\left\{\left[\frac{\partial}{\partial\theta}\log{p(\mathbf{Y}\mid\theta)}\right]^2\right\}\\
&=-E\left\{\dfrac{\partial^2}{\partial\theta^2}\log{p(\mathbf{Y}\mid\theta)}\right\}
\end{align*}

Si la verosimilitud de los datos está determinada por un vector de parámetros \(\boldsymbol \theta\), la distribución previa no informativa de Jeffreys tiene distribución de probabilidad dada por
\begin{equation}
p(\theta)\propto |\mathbf{I}(\boldsymbol \theta)|^{1/2}
\end{equation}

donde \(\mathbf{I}\) es la matriz de información de Fisher, cuyo elemento en la fila \(i\) y columna \(j\) está definida como
\begin{align*}
\mathbf{I}_{[ij]}(\boldsymbol \theta)&=E\left\{\left[\frac{\partial}{\partial\theta_i}\log{p(\mathbf{Y}\mid\theta)}\right]\left[\frac{\partial}{\partial\theta_j}\log{p(\mathbf{Y}\mid\boldsymbol \theta)}\right]\right\}\\
&=-E\left\{\dfrac{\partial^2}{\partial\theta_i\partial\theta_j}\log{p(\mathbf{Y}\mid\boldsymbol \theta)}\right\}
\end{align*}
donde \(\theta_i\) y \(\theta_j\) son los elementos \(i\) y \(j\) del vector \(\boldsymbol \theta\).
\end{definition}

Nótese que si la verosimilitud de las observaciones pertenecen a la
familia de distribuciones exponencial, entonces la distribución previa
de Jeffreys no es difícil de calcular. Por otro lado nótese que la
distribución previa no informativa de Jeffreys depende, de cierta
manera, del mecanismo probabilístico que rige a los datos. Lo anterior
hace que ciertos críticos de la estadística bayesiana manifiesten su incorformidad puesto que se supone que la formulación de la distribución a
previa es independiente de los datos observados.

A continuación se evidencia la propiedad de esta distribución previa de
seguir siendo no informativa con diferentes parametrizaciones.

\begin{proposition}
\protect\hypertarget{prp:unnamed-chunk-17}{}{\label{prp:unnamed-chunk-17} }La distribución previa no informativa de Jeffreys es invariante a transformaciones uno a uno. Es decir, si \(\phi=h(\theta)\), entonces \(p(\phi)\propto(I(\phi))^{1/2}\).
\end{proposition}

\begin{proof}
\iffalse{} {Prueba. } \fi{}En primer lugar nótese que
\begin{align*}
I(\theta)=I(\phi) \mid \frac{\partial\phi}{\partial\theta} \mid ^{2}
\end{align*}

puesto que al utilizar la regla de la cadena del cálculo matemático se tiene que
\begin{align*}
I(\phi)= - E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \phi)}{\partial\phi^2}\right]
&= - E\left[\frac{\partial}{\partial\phi}\left(\frac{\partial \log p(\mathbf{Y} \mid \phi)}{\partial\phi}\right)\right]\\
&= - E\left[\frac{\partial}{\partial\theta}\left(\frac{\partial \log p(\mathbf{Y} \mid \phi)}{\partial\phi}\right) \mid \frac{\partial\theta}{\partial\phi} \mid \right]\\
&= - E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \phi)}{d\theta^2} \mid \frac{\partial\theta}{\partial\phi} \mid ^{2}\right]\\
&= - E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \theta =h^{-1}(\phi))}{d\theta^2} \mid \frac{\partial\theta}{\partial\phi} \mid ^{2}\right]\\
&= I(\theta) \mid \frac{\partial\theta}{\partial\phi} \mid ^{2}
\end{align*}

Ahora, de la definición de función de distribución para una función y utilizando \eqref{eq:teotransf}, se tiene que
\begin{align*}
p(\phi)&=p(\theta) \mid \frac{\partial\theta}{\partial\phi} \mid
\propto (I(\theta))^{1/2} \mid \frac{\partial\theta}{\partial\phi} \mid
\propto I(\phi)^{1/2} \mid \frac{\partial\phi}{\partial\theta} \mid  \mid \frac{d\theta}{\partial\phi} \mid =I(\phi)^{1/2}
\end{align*}
\end{proof}

En \citet[p.~59]{BoxTiao} es posible encontrar un resumen exhaustivo de distribuciones previas no informativas para las distribuciones de verosimilitud más comunes. A continuación, se exponen
algunos ejemplos que utilizan este enfoque.

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-19}{}{\label{exm:unnamed-chunk-19} }Si \(Y\) es una variable aleatoria con distribución Binomial, entonces el espacio de muestreo del parámetro de interés será el intervalo \([0,1]\); sería conveniente utilizar la función de distribución uniforme sobre este intervalo como distribución previa no informativa. Con el enfoque de Jeffreys se llega a este mismo resultado puesto que la información de Fisher para la distribución binomial es \(J(\theta)=n/\theta(1- \theta)\) dado que
\begin{equation*}
\log p(Y \mid \theta)=\log \binom{n}{y} + y\log(\theta)+(n-y)\log(1-\theta)
\end{equation*}
y
\begin{equation*}
\frac{\partial^2 \log p(Y \mid \theta)}{\partial\theta^2}=-\frac{y}{\theta^2}-\frac{n-y}{(1-\theta)^2}
\end{equation*}
Por lo tanto, al calcular la esperanza, y por consiguiente la información de Fisher, se tiene que
\begin{equation*}
I(\theta)=- E\left[\frac{\partial^2 \log p(Y \mid \theta)}{\partial\theta^2}\right]
=\frac{n\theta}{\theta^2}+\frac{n-n\theta}{(1-\theta)^2}= \frac{n}{\theta(1-\theta)}
\end{equation*}
Es decir, la distribución previa no informativa para el parámetro de interés \(\theta\) es proporcional a \(\theta^{-1/2}(1-\theta)^{-1/2}\), la cual comparte la misma forma estructural de una distribución \(Beta(1/2,1/2)\) que a su vez es idéntica a la distribución uniforme. En términos de la distribución posterior para el parámetro de interés, se tiene que
\begin{align*}
p(\theta \mid Y) &\propto p(Y \mid \theta) p(\theta)\\
&\propto \theta^{y}(1-\theta)^{n-y}\theta^{-1/2}(1-\theta)^{-1/2}\\
&=\theta^{y+1/2-1}(1-\theta)^{n-y+1/2-1}
\end{align*}
Por tanto, la distribución de \(\theta \mid Y\) es \(Beta(y+1/2,n-y+1/2)\). Por construcción, esta distribución no está alterada ni influenciada por la distribución previa pues la misma es no informativa.
\end{example}

\begin{example}
\protect\hypertarget{exm:EjemPoisson}{}{\label{exm:EjemPoisson} }Si \(\mathbf{Y}=\{Y_1,\ldots,Y_n\}\) es una muestra aleatoria de variables con distribución de Poisson, entonces el espacio de muestreo del parámetro de interés será el intervalo \((0,\infty)\); por tanto utilizar la distribución uniforme como distribución previa no informativa no es conveniente. Ahora, la información de Fisher para la distribución conjunta es \(I(\theta)=n/\theta\) puesto que
\begin{equation*}
\log p(\mathbf{Y} \mid \theta)=-n\theta+\log(\theta)\sum_{i=1}^ny_i-\sum_{i=1}^n\log(y_i!)
\end{equation*}
y
\begin{equation*}
\frac{\partial^2 \log p(\mathbf{Y} \mid \theta)}{\partial\theta^2}=-\frac{\sum_{i=1}^ny_i}{\theta^2}
\end{equation*}
Por lo tanto al calcular la esperanza, y por consiguiente la información de Fisher, se tiene que
\begin{equation*}
I(\theta)=- E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \theta)}{\partial\theta^2}\right]
=\frac{\sum_{i=1}^nE(y_i)}{\theta^2}=\frac{n}{\theta}
\end{equation*}
Es decir, la distribución previa no informativa para el parámetro de interés es proporcional a \(\theta^{-1/2}\). En términos de la distribución posterior para el parámetro de interés, se tiene que
\begin{align*}
p(\theta \mid Y) \propto p(Y \mid \theta) p(\theta) \propto e^{-n\theta} \theta^{\sum_{i=1}^ny_i}\theta^{-1/2}
=e^{-n\theta} \theta^{\sum_{i=1}^ny_i-1/2}
\end{align*}
Por tanto, la distribución de \(\theta \mid \mathbf{Y}\) es \(Gamma(\sum_{i=1}^ny_i+1/2,n)\). Por construcción, esta distribución no está alterada ni influenciada por la distribución previa pues la misma es no informativa.
\end{example}

\begin{example}
\protect\hypertarget{exm:unnamed-chunk-20}{}{\label{exm:unnamed-chunk-20} }Suponga que \(\mathbf{Y}=\{Y_1\ldots, Y_n\}\) es una muestra aleatoria con distribución normal de parámetros \((\theta, \sigma^2)'\). Se puede verificar que la matriz de información de Fisher para el vector de parámetros está dada por
\begin{equation}
\begin{pmatrix}
  \frac{n}{\sigma^2} & 0 \\
  0 & \frac{n}{2\sigma^4} \\
\end{pmatrix}
\end{equation}

cuyo determinante está dado por \(\frac{n^2}{2\sigma^6}\). Por lo tanto, la distribución a previa no informativa de Jeffreys está dada por
\begin{equation}
p(\theta,\sigma^2)\propto 1/\sigma^3
\end{equation}
\end{example}

\hypertarget{pruebas-de-hipuxf3tesis}{%
\section{Pruebas de hipótesis}\label{pruebas-de-hipuxf3tesis}}

A excepción del juzgamiento de hipótesis, las inferencias que hacen los
estadísticos bayesianos, acerca de poblaciones normales, son muy
similares a las que los estadísticos de la tradición frecuentista, de
Neyman y Pearson, hacen. Consideremos la siguiente situación.

\begin{quote}
Un instrumento mide la posición de un objeto con un determinado error. Éste
error está distribuido de manera uniforme en el intervalo (-1cm, 1cm).
Supongamos que el instrumento midió la posición de un objeto en
+0.9999cm del origen. Planteamos la siguiente hipótesis nula, \textbf{H: La
posición real del objeto es exactamente el origen}.
\end{quote}

Imagine que planteamos este problema de inferencia estadística a dos estadísticos, uno frecuentista clásico y el otro acérrimo bayesiano.

\begin{itemize}
\tightlist
\item
  \emph{Razonamiento del frecuentista}: si la hipótesis nula es verdadera, ha ocurrido un
  evento con una probabilidad (a dos colas) de ocurrencia de 0.0001 o
  menos. Mediante un criterio razonable (nivel de significación), este es
  un evento muy raro y por lo tanto rechaza la hipótesis nula.
\item
  \emph{Razonamiento del bayesiano}: dada una
  observación, la verosimilitud asociada con la posición del objeto en el
  intervalo -0.0001 y +1.9999 es la misma, 0.5. Fuera de esos límites la
  verosimilitud es nula. Ahora, el origen está dentro de la región en
  donde la verosimilitud es máxima; por lo tanto sea cual sea la
  distribución a previa asociada al parámetro de posición, la distribución
  posterior tomara el valor cero en cualquier lugar fuera del intervalo
  -0.0001 y +1.9999. Así, con la observación disponible, no hay evidencia
  para el rechazo de la hipótesis nula.
\end{itemize}

Bajo esta paradoja, \citet{Brewer2002} sugiere que
ambos estadísticos tienen razón, pero a la vez están equivocados. El
frecuentista tiene razón en afirmar que, con la evidencia disponible, ha
ocurrido un evento extraordinariamente extraño o que la hipótesis nula
es falsa. El bayesiano tiene razón en argumentar que, en términos de la
situación, no hay evidencia en contra de la hipótesis nula. Esta
paradoja se presenta porque los bayesianos tienden a trabajar dentro de
la situación que ellos creen que existe y la lógica bayesiana se mueve en ese marco de
referencia. Los bayesianos hacen las inferencias en términos de la
verosimilitud de los eventos observados, mientras que los frecuentistas
hacen inferencias en términos de eventos que ni siquiera han ocurrido. .

\hypertarget{factor-de-bayes}{%
\subsection{Factor de Bayes}\label{factor-de-bayes}}

El juzgamiento de hipótesis del enfoque frecuentista se puede efectuar
en el ámbito Bayesiano por medio del contraste entre dos modelos. Suponiendo
que existen dos modelos \(M1\) y \(M2\) candidatos para \(\mathbf{Y}\), se
define el \emph{Factor de Bayes} en favor del modelo \(M1\) como la razón
de las densidades marginales de los datos para los dos modelos. Es
posible demostrar que este factor es equivalente a la siguiente expresión:

\begin{equation}
\label{eq:FB}
FB=\frac{p(\mathbf{Y} \mid M1)}{p(\mathbf{Y} \mid M2)}=\frac{Pr(M1 \mid \mathbf{Y})/Pr(M2 \mid \mathbf{Y})}{Pr(M1)/Pr(M2)}
\end{equation}

Para evaluar esta última expresión es necesario recurrir a la densidad
previa y posterior del parámetro de interés, asumiendo que los modelos
están parametrizados por éstos. Se puede ver que cuando los modelos \(M1\)
y \(M2\) tienen la misma distribución previa, entonces el factor de Bayes
se reduce a la razón de densidad posterior de los dos modelos.
Adicionalmente este factor sólo está definido cuando la integral de la
densidad marginal de \(\mathbf{Y}\) bajo cada modelo converge. En la
expresión \eqref{eq:FB} se claro que valores grandes del factor muestran
evidencia a favor del modelo \(M1\); valores menores de 1, a favor del
modelo \(M2\); mientras que valores cercanos a 1 no muestran evidencias
claras hacia ninguno de los dos modelos.

En \citet{Gelman95} se presenta el siguiente ejemplo sencillo sobre la
presencia o ausencia de la enfermedad de la hemofilia, una enfermedad genética
especialmente grave en las mujeres. Para una mujer quien tiene un hermano
portador del gen, el parámetro \(\theta\) describe la presencia o ausencia
del gen en ella, y toma valores de 1 (presencia del gen) y 0 (ausencia
del gen). La distribución previa del parámetro es
\(Pr(\theta=1)=Pr(\theta=0)=0.5\). El objetivo es evaluar el sistema
\(M_1:\ \theta=1\) y \(M_2:\ \theta=0\), con base en el hecho de que ella
tiene dos hijos ambos no portadores del gen. De esta forma, el factor de Bayes se expresa como:

\begin{equation*}
FB=\frac{p(y_1=0,\ y_2=0|\theta=1)}{p(y_1=0,\ y_2=0|\theta=0)}=\frac{0.25}{1}=0.25
\end{equation*} De donde se evidencia mayor apoyo a la hipótesis
\(\theta=0\).

\hypertarget{valor-p-bayesiano}{%
\subsection{\texorpdfstring{Valor-\(p\) Bayesiano}{Valor-p Bayesiano}}\label{valor-p-bayesiano}}

En la inferencia clásica, se define el valor-\(p\) como la probabilidad de
que la estadística de prueba tome valores más extremos a los observados,
y se compara con el nivel de significancia, previamente establecido,
para tomar una decisión acerca de la hipótesis nula. En el ámbito
Bayesiano, el valor-\(p\) se define como la probabilidad de que la
estadística de prueba \(T\) calculada sobre los datos replicados \(y^{rep}\)
sean más extremos al observado, y la probabilidad se toma sobre la
distribución posterior del parámetro \(\theta\) y la distribución
predictiva posterior de \(y^{rep}\). Específicamente, queda determinado
por la siguiente expresión:

\begin{equation*}
p_B=\int\int_{T(y^{rep}) \geq T(y)}p(y^{rep}|\theta)p(\theta|y)dy^{rep}d\theta
\end{equation*}

A diferencia del valor-\(p\) clásico, donde solo valores pequeños muestran
evidencia en contra de la hipótesis nula, un valor-\(p\) Bayesiano extremo
(menor a 0.01 o mayor a 0.99) sugiere que los valores observados
difícilmente pueden ser replicados si el modelo fuera verdadero.

\hypertarget{criterios-de-informaciuxf3n}{%
\section{Criterios de información}\label{criterios-de-informaciuxf3n}}

Los criterios de información constituyen una herramienta muy importante
en el modelamiento estadístico, pues contribuyen a la selección de
modelos de manera simple. Existen una variedad de estos criterios, a
continuación se describen los dos criterios más comunes en el análisis
bayesiano.

\hypertarget{criterio-dic}{%
\subsection{Criterio DIC}\label{criterio-dic}}

El criterio de información de \emph{devianza} (DIC, por sus iniciales en inglés) es una generalización del popular criterio AIC para
los modelos jerárquicos, y se basa en el concepto de la devianza que se
define como

\begin{equation}
D(y, \boldsymbol \theta)=-2*\log(p(y|\boldsymbol \theta))
\end{equation}

cuya media posterior es una medida usual del ajuste del modelo.
\citet{Dempster74} sugirió graficar la distribución posterior de
la devianza para observar el ajuste del modelo a los datos. Una
estimación de esta media posterior se basa en simulación de \(M\) valores
\(\boldsymbol \theta^1,\cdots,\boldsymbol \theta^M\) de la distribución posterior de \(\boldsymbol \theta\),
y está dada por

\begin{equation*}
\hat{E}_D=\frac{1}{M}\sum_{m=1}^MD(y,\boldsymbol \theta^m)
\end{equation*}

El DIC se define como

\begin{equation*}
DIC=\hat{E}_D+p_D
\end{equation*}

Donde \(p_D\) es el número efectivo de parámetros. Nótese que en la
anterior formulación, el DIC se puede descomponer en dos partes: la
parte de la bondad de ajuste del modelo, medido a través de \(E_D\), y la
parte que mide la complejidad del modelo \(p_D\). Otra formulación
equivalente del DIC se obtiene teniendo en cuenta que

\begin{equation*}
p_D=\hat{E}_D - \hat{D}
\end{equation*}

Donde \(\hat{D}=-2*\log(p(y|\hat{\boldsymbol \theta}))\) con \(\hat{\boldsymbol \theta}\)
denotando la mediposterior de \(\boldsymbol \theta\); es decir, \(\hat{D}\) es la
estimación de la devianza usando \(\hat{\boldsymbol \theta}\), y \(p_D\) se puede ver
como la mediposterior de la devianza menos la devianza de las medias
posterior \citep{Spiegel}. De esta forma, el DIC también se puede
escribir como \begin{equation*}
DIC=\hat{D}+2p_D
\end{equation*}

Interpretación de DIC: El modelo con el menor DIC es considerado como el
modelo que mejor predice un conjunto de datos con la misma estructura
que los datos observados. Al respecto se deben tener en cuenta las
siguientes consideraciones:

\begin{itemize}
\tightlist
\item
  El DIC puede ser negativo puesto que \(p(y|\theta)\) puede tomar valores
  mayores a 1 asociado a una devianza pequeña.
\item
  \(p_D\), y por consiguiente el DIC, no es invariante a parametrizaciones del
  modelo. Se sugiere en la práctica usar parametrizaciones que conducen a
  la normalidad en la distribución posterior.
\end{itemize}

\hypertarget{criterios-aic-y-bic}{%
\subsection{Criterios AIC y BIC}\label{criterios-aic-y-bic}}

El criterio de información de Akaike (AIC) fue formalmente presentado por \citet{Akaike}. Este criterio mide la pérdida de información al
ajustar un modelo a un conjunto de datos; por esto, se buscan modelos
que arrojen valores pequeños de AIC. Posteriormente \citep{AICc}
introdujo el factor de corrección para evitar que el AIC escoja modelos
con demasiados parámetros en situaciones de tamaño de muestra pequeño.

Por otro lado, el criterio de información bayesiano BIC, también
conocido como el criterio de Schwarz \citep{Schwarz}, también está
formulado en términos de la función de verosimilitudel modelo y del
número de parámetros. La expresión de estos criterios es como sigue:

\begin{align*}
AIC&=-2\log(p(y|\hat{\boldsymbol \theta}))+2p\\
AIC_c&=AIC+\frac{2p^2+2p}{n-p-1}\\
BIC&=-2\log(p(y|\hat{\boldsymbol \theta}))+p\log(n)
\end{align*}

Donde \(p\) es el número de parámetros en el modelo y \(n\) el número de
datos observados. Cabe resaltar que en el criterio BIC hay una mayor
penalización por el número excesivo de parámetros que en el criterio
AIC, y en la práctica se prefieren los modelos con un BIC menor.

Se debe recalcar que los dos criterios tienen diferentes
enfoques, el criterio BIC se enfoca en identificar el modelo verdadero,
mientras que el criterio DIC enfoca en encontrar el modelo con mejor
capacidad de predicción.

\hypertarget{appendix-apuxe9ndice}{%
\appendix}


\hypertarget{algunas-distribuciones-de-probabilidad}{%
\chapter{Algunas distribuciones de probabilidad}\label{algunas-distribuciones-de-probabilidad}}

ss

\hypertarget{distribuciones-discretas}{%
\section{Distribuciones discretas}\label{distribuciones-discretas}}

ss

\hypertarget{referencias}{%
\chapter*{Referencias}\label{referencias}}
\addcontentsline{toc}{chapter}{Referencias}

  \bibliography{book.bib}

\end{document}
