<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.1 Teoría de la decisión | Modelos Bayesianos con R y STAN" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
<meta name="github-repo" content="psirusteam/bookdownBayesiano" />

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />

<meta name="date" content="2021-06-04" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN.">

<title>1.1 Teoría de la decisión | Modelos Bayesianos con R y STAN</title>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#prefacio">Prefacio</a></li>
<li><a href="antes-de-comenzar.html#antes-de-comenzar">Antes de comenzar</a>
<ul>
<li><a href="cuestionamientos-sobre-el-enfoque-bayesiano.html#cuestionamientos-sobre-el-enfoque-bayesiano">Cuestionamientos sobre el enfoque bayesiano</a></li>
<li><a href="acerca-de-la-notación.html#acerca-de-la-notación">Acerca de la notación</a></li>
</ul></li>
<li><a href="1-tópicos-básicos.html#tópicos-básicos"><span class="toc-section-number">1</span> Tópicos básicos</a>
<ul>
<li><a href="1-1-teoría-de-la-decisión.html#teoría-de-la-decisión"><span class="toc-section-number">1.1</span> Teoría de la decisión</a></li>
<li><a href="1-2-algunos-resultados-de-probabilidad.html#algunos-resultados-de-probabilidad"><span class="toc-section-number">1.2</span> Algunos resultados de probabilidad</a></li>
<li><a href="1-3-teorema-de-bayes.html#teorema-de-bayes"><span class="toc-section-number">1.3</span> Teorema de Bayes</a></li>
</ul></li>
<li><a href="2-inferencia-bayesiana.html#inferencia-bayesiana"><span class="toc-section-number">2</span> Inferencia bayesiana</a>
<ul>
<li><a href="2-1-la-distribución-previa.html#la-distribución-previa"><span class="toc-section-number">2.1</span> La distribución previa</a>
<ul>
<li><a href="2-1-la-distribución-previa.html#distribuciones-conjugadas"><span class="toc-section-number">2.1.1</span> Distribuciones conjugadas</a></li>
<li><a href="2-1-la-distribución-previa.html#familia-exponencial"><span class="toc-section-number">2.1.2</span> Familia exponencial</a></li>
<li><a href="2-1-la-distribución-previa.html#distribuciones-previas-no-informativas"><span class="toc-section-number">2.1.3</span> Distribuciones previas no informativas</a></li>
</ul></li>
<li><a href="2-2-pruebas-de-hipótesis.html#pruebas-de-hipótesis"><span class="toc-section-number">2.2</span> Pruebas de hipótesis</a>
<ul>
<li><a href="2-2-pruebas-de-hipótesis.html#factor-de-bayes"><span class="toc-section-number">2.2.1</span> Factor de Bayes</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#valor-p-bayesiano"><span class="toc-section-number">2.2.2</span> Valor-<span class="math inline">\(p\)</span> Bayesiano</a></li>
</ul></li>
<li><a href="2-3-criterios-de-información.html#criterios-de-información"><span class="toc-section-number">2.3</span> Criterios de información</a>
<ul>
<li><a href="2-3-criterios-de-información.html#criterio-dic"><span class="toc-section-number">2.3.1</span> Criterio DIC</a></li>
<li><a href="2-3-criterios-de-información.html#criterios-aic-y-bic"><span class="toc-section-number">2.3.2</span> Criterios AIC y BIC</a></li>
</ul></li>
</ul></li>
<li><a href="3-modelos-uniparamétricos.html#modelos-uniparamétricos"><span class="toc-section-number">3</span> Modelos uniparamétricos</a>
<ul>
<li><a href="3-1-modelo-bernoulli.html#modelo-bernoulli"><span class="toc-section-number">3.1</span> Modelo Bernoulli</a></li>
<li><a href="3-2-modelo-binomial.html#modelo-binomial"><span class="toc-section-number">3.2</span> Modelo Binomial</a></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li><a href="A-elementos-de-probabilidad.html#elementos-de-probabilidad"><span class="toc-section-number">A</span> Elementos de probabilidad</a>
<ul>
<li><a href="A-1-distribuciones-discretas.html#distribuciones-discretas"><span class="toc-section-number">A.1</span> Distribuciones discretas</a>
<ul>
<li><a href="A-1-distribuciones-discretas.html#distribución-uniforme-discreta"><span class="toc-section-number">A.1.1</span> Distribución uniforme discreta</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-hipergeométrica"><span class="toc-section-number">A.1.2</span> Distribución hipergeométrica</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-bernoulli"><span class="toc-section-number">A.1.3</span> Distribución Bernoulli</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-binomial"><span class="toc-section-number">A.1.4</span> Distribución binomial</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-binomial-negativa"><span class="toc-section-number">A.1.5</span> Distribución Binomial negativa</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-de-poisson"><span class="toc-section-number">A.1.6</span> Distribución de Poisson</a></li>
</ul></li>
<li><a href="A-2-distribuciones-continuas.html#distribuciones-continuas"><span class="toc-section-number">A.2</span> Distribuciones continuas</a>
<ul>
<li><a href="A-2-distribuciones-continuas.html#distribución-uniforme-continua"><span class="toc-section-number">A.2.1</span> Distribución Uniforme Continua</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-weibull"><span class="toc-section-number">A.2.2</span> Distribución Weibull</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-valor-extremo"><span class="toc-section-number">A.2.3</span> Distribución valor-extremo</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-gamma"><span class="toc-section-number">A.2.4</span> Distribución Gamma</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-gamma-inversa"><span class="toc-section-number">A.2.5</span> Distribución Gamma-inversa</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-exponencial"><span class="toc-section-number">A.2.6</span> Distribución exponencial</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-beta"><span class="toc-section-number">A.2.7</span> Distribución Beta</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-normal"><span class="toc-section-number">A.2.8</span> Distribución normal</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-log-normal"><span class="toc-section-number">A.2.9</span> Distribución log-normal</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-ji-cuadrado"><span class="toc-section-number">A.2.10</span> Distribución Ji-cuadrado</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-t-student"><span class="toc-section-number">A.2.11</span> Distribución t-student</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-t-student-generalizada"><span class="toc-section-number">A.2.12</span> Distribución t-student generalizada</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-f"><span class="toc-section-number">A.2.13</span> Distribución F</a></li>
</ul></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribuciones-multivariadas"><span class="toc-section-number">A.3</span> Distribuciones multivariadas</a>
<ul>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-multinomial"><span class="toc-section-number">A.3.1</span> Distribución Multinomial</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-dirichelt"><span class="toc-section-number">A.3.2</span> Distribución Dirichelt</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-normal-multivariante"><span class="toc-section-number">A.3.3</span> Distribución Normal Multivariante</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-wishart"><span class="toc-section-number">A.3.4</span> Distribución Wishart</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-inversa-wishart"><span class="toc-section-number">A.3.5</span> Distribución inversa-Wishart</a></li>
</ul></li>
</ul></li>
<li><a href="B-matriz-de-información.html#matriz-de-información"><span class="toc-section-number">B</span> Matriz de información</a></li>
<li><a href="C-elementos-de-simulación-estadística.html#elementos-de-simulación-estadística"><span class="toc-section-number">C</span> Elementos de simulación estadística</a>
<ul>
<li><a href="C-1-métodos-directos.html#métodos-directos"><span class="toc-section-number">C.1</span> Métodos directos</a>
<ul>
<li><a href="C-1-métodos-directos.html#método-de-la-transformación-uniforme"><span class="toc-section-number">C.1.1</span> Método de la transformación uniforme</a></li>
<li><a href="C-1-métodos-directos.html#método-de-la-grilla"><span class="toc-section-number">C.1.2</span> Método de la grilla</a></li>
</ul></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#métodos-de-monte-carlo-vía-cadenas-de-markov"><span class="toc-section-number">C.2</span> Métodos de Monte Carlo vía cadenas de Markov</a>
<ul>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-muestreador-de-gibbs"><span class="toc-section-number">C.2.1</span> El muestreador de Gibbs</a></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-algoritmo-de-metrópolis-hastings"><span class="toc-section-number">C.2.2</span> El algoritmo de Metrópolis-Hastings</a></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#buenas-prácticas-en-la-aplicación-de-métodos-mcmc"><span class="toc-section-number">C.2.3</span> Buenas prácticas en la aplicación de métodos MCMC</a></li>
</ul></li>
</ul></li>
<li><a href="referencias.html#referencias">Referencias</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="teoría-de-la-decisión" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Teoría de la decisión</h2>
<p>El problema estadístico de estimar un parámetro se puede ver dentro del contexto de la teoría de decisión: la estimación que proveemos, sea en el ámbito de la estadística clásica o la estadística bayesiana, depende de los datos muestrales, <span class="math inline">\(\mathbf{X}\)</span>, de tal forma que si éstos cambian, la estimación también cambia. De esta manera, el proceso de estimación puede ser representado como una función que toma un conjunto de datos muestrales y los convierte en una estimación (<span class="math inline">\(A(\mathbf{X})\)</span> o simplemente <span class="math inline">\(A\)</span>) del parámetro de interés. En la teoría de decisión, la anterior función se conoce como una regla de decisión.</p>
<p>Así como en la vida cotidiana, por la incertidumbre del futuro (en el ámbito estadístico, por la incertidumbre acerca del parámetro), toda acción que se tome (toda estimación que se provea) puede traer consigo un grado de falla o riesgo. Y es necesario escoger la acción óptima que de alguna forma minimice ese riesgo. Formalizando esta idea intuitiva, se define la función de pérdida <span class="math inline">\(L\)</span> que asocia a cada dupla conformada por la acción tomada y el parámetro de interés <span class="math inline">\(\theta\)</span>, <span class="math inline">\((A, \ \theta)\)</span> con un número no negativo que cuantifica la pérdida que ocasiona la acción (o la estimación) <span class="math inline">\(A\)</span> con respecto al parámetro <span class="math inline">\(\theta\)</span>.</p>
<p>Es claro que se desea escoger aquella acción que minimice de alguna forma la pérdida que ésta ocasiona, pero la función <span class="math inline">\(L\)</span> no se puede minimizar directamente, puesto que:</p>
<ul>
<li><p>En el ámbito de la estadística clásica, el parámetro <span class="math inline">\(\theta\)</span> se considera fijo, y los datos muestrales <span class="math inline">\(\mathbf{X}\)</span> aleatorios. Como la función de pérdida <span class="math inline">\(L\)</span> depende de <span class="math inline">\(\mathbf{X}\)</span>, entonces ésta también será una variable aleatoria, y no se puede minimizar directamente. Por lo tanto se define el riesgo o la pérdida promedio como la esperanza matemática de <span class="math inline">\(L\)</span>; denotando el riesgo como <span class="math inline">\(R\)</span>, éste está definido como <span class="math inline">\(R=E(L)\)</span> (la esperanza se toma con respecto a la distribución probabilística de <span class="math inline">\(\mathbf{X}\)</span>).</p></li>
<li><p>En el ámbito de la estadística bayesiana, <span class="math inline">\(\theta\)</span> sigue siendo una cantidad fija, pero la incertidumbre que tiene el investigador sobre la localización del parámetro se puede modelar mediante funciones de probabilidad. La herramienta fundamental para conocer características de <span class="math inline">\(\theta\)</span> es su función de densidad posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>. En este caso, el riesgo <span class="math inline">\(R\)</span> se define como</p></li>
</ul>
<p><span class="math display">\[\begin{equation*}
R=E(L)=\int L(A, \theta)p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>En cualquiera de los dos casos anteriores, se busca la estimación que minimice el riesgo <span class="math inline">\(R\)</span>. Ilustramos los anteriores conceptos en los siguientes ejemplos tanto en la estadística clásica como en la estadística bayesiana.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-1" class="example"><strong>Ejemplo 1.1  </strong></span>Sea <span class="math inline">\(X_i\)</span> con <span class="math inline">\(i=1,\cdots, n\)</span> una muestra aleatoria con media <span class="math inline">\(\theta\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>, ambas fijas, y suponga que se desea encontrar el mejor estimador de <span class="math inline">\(\theta\)</span> bajo la función de pérdida cuadrática dada por</p>
<p><span class="math display">\[\begin{equation*}
L(A,\theta)=(A-\theta)^2
\end{equation*}\]</span></p>
<p>cuyo riesgo asociado está dado por <span class="math inline">\(R=E(A-\theta)^2\)</span>. En primer lugar, buscaremos dicho estimador dentro de todas las formas lineales de <span class="math inline">\(X_i\)</span>, es decir, los estimadores de la forma <span class="math inline">\(A=\sum_{i=1}^nc_iX_i\)</span>. Por tanto, el riesgo se puede expresar como
<span class="math display">\[\begin{align*}
R=E(A-\theta)^2&amp;=Var(A)+(E(A)-\theta)^2\\
&amp;=\sum_{i=1}^nc_i^2\sigma^2+\theta^2(\sum_{i=1}^nc_i-1)^2
\end{align*}\]</span></p>
<p>Y al buscar los coeficientes <span class="math inline">\(c_i\)</span> que minimizan la anterior expresión, encontramos que <span class="math inline">\(c_i=\theta^2/(\sigma^2+n\theta^2)\)</span> para todo <span class="math inline">\(i\)</span>. Como estos coeficientes conducen a un estimador que depende del parámetro desconocido, concluimos que no hay ningún estimador que minimiza el riesgo.</p>
Para encontrar una solución, es necesario restringir aún más el rango de estimadores; para eso, se impone la restricción de que <span class="math inline">\(\sum_{i=1}^n c_i=1\)</span>. De esta forma, el riesgo está dado por <span class="math inline">\(R=\sum c_i^2\sigma^2\)</span>. Dado que <span class="math inline">\(\sigma^2\)</span> es fijo, al minimizar <span class="math inline">\(\sum c_i^2\)</span> sujeto a la restricción, se tiene que la solución es <span class="math inline">\(c_i=1/n\)</span> para todo <span class="math inline">\(i\)</span>, y así encontramos que el mejor estimador (en el sentido de minimizar el riesgo de la función de pérdida cuadrática) dentro de todas las formas lineales con <span class="math inline">\(\sum c_i=1\)</span> es la media muestral <span class="math inline">\(\bar{X}\)</span>.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-2" class="example"><strong>Ejemplo 1.2  </strong></span>Suponga que se desea estimar un parámetro de interés <span class="math inline">\(\theta\)</span> en el contexto de la estadística bayesiana y denotamos la función de densidad posterior de <span class="math inline">\(\theta\)</span> como <span class="math inline">\(p(\theta|\mathbf{X})\)</span>, entonces si utilizamos la función de pérdida cuadrática, el riesgo asociado será</p>
<p><span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))=E (A-\theta)^2=Var(\theta)+(E(\theta)-A)^2
\end{align*}\]</span></p>
que es minimizado si <span class="math inline">\(A=E(\theta)\)</span>. Es decir, la mejor acción para estimar <span class="math inline">\(\theta\)</span> es utilizar su tomada con respecto a la distribución posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Ejemplo 1.3  </strong></span>En el mismo contexto del ejemplo anterior, si cambiamos la función de pérdida a la siguiente
<span class="math display">\[\begin{equation*}
L(A,\theta)=|A-\theta|=(A-\theta)I_{(A\geq\theta)}+(\theta-A)I_{(\theta&gt;A)}
\end{equation*}\]</span></p>
<p>El riesgo estará dado por
<span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))\\
&amp;=\int L(A,\theta)p(\theta|\mathbf{X})d\theta\\
&amp;=\int_{(A\geq\theta)}(A-\theta)p(\theta|\mathbf{X})d\theta+\int_{(\theta&gt;A)}(\theta-A)p(\theta|\mathbf{X})d\theta
\end{align*}\]</span></p>
<p>Derivando el riesgo con respecto a la acción <span class="math inline">\(A\)</span>, se tiene que
<span class="math display">\[\begin{equation*}
\frac{\partial R}{\partial A}=\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta-\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>Igualando a cero, tenemos que
<span class="math display">\[\begin{equation*}
\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta=\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta=0.5
\end{equation*}\]</span></p>
Y concluimos que la acción <span class="math inline">\(A\)</span> que induce menor riesgo corresponde al percentil 50% o la mediana de la distribución posterior de <span class="math inline">\(\theta\)</span>.
</div>
<p><br></p>
<p>De los anteriores ejemplos se observa que, bajo un mismo contexto, cuando se utilizan diferentes funciones de pérdida, también se obtienen distintas estimaciones, y distintas acciones que optimizan el riesgo.</p>
</div>
<p style="text-align: center;">
<a href="1-tópicos-básicos.html"><button class="btn btn-default">Previous</button></a>
<a href="1-2-algunos-resultados-de-probabilidad.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
