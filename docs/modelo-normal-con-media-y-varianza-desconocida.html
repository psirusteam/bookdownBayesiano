<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.1 Modelo Normal con media y varianza desconocida | Modelos Bayesianos con R y STAN</title>
  <meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="4.1 Modelo Normal con media y varianza desconocida | Modelos Bayesianos con R y STAN" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="github-repo" content="psirusteam/bookdownBayesiano" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.1 Modelo Normal con media y varianza desconocida | Modelos Bayesianos con R y STAN" />
  
  <meta name="twitter:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />


<meta name="date" content="2021-06-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modelos-multiparamétricos.html"/>
<link rel="next" href="elementos-de-probabilidad.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Bayesianos con R y STAN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="" data-path="antes-de-comenzar.html"><a href="antes-de-comenzar.html"><i class="fa fa-check"></i>Antes de comenzar</a>
<ul>
<li class="chapter" data-level="" data-path="cuestionamientos-sobre-el-enfoque-bayesiano.html"><a href="cuestionamientos-sobre-el-enfoque-bayesiano.html"><i class="fa fa-check"></i>Cuestionamientos sobre el enfoque bayesiano</a></li>
<li class="chapter" data-level="" data-path="acerca-de-la-notación.html"><a href="acerca-de-la-notación.html"><i class="fa fa-check"></i>Acerca de la notación</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html"><i class="fa fa-check"></i><b>1</b> Tópicos básicos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="teoría-de-la-decisión.html"><a href="teoría-de-la-decisión.html"><i class="fa fa-check"></i><b>1.1</b> Teoría de la decisión</a></li>
<li class="chapter" data-level="1.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html"><i class="fa fa-check"></i><b>1.2</b> Algunos resultados de probabilidad</a></li>
<li class="chapter" data-level="1.3" data-path="teorema-de-bayes.html"><a href="teorema-de-bayes.html"><i class="fa fa-check"></i><b>1.3</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html"><i class="fa fa-check"></i><b>2</b> Inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="2.1" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html"><i class="fa fa-check"></i><b>2.1</b> La distribución previa</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>2.1.1</b> Distribuciones conjugadas</a></li>
<li class="chapter" data-level="2.1.2" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#familia-exponencial"><i class="fa fa-check"></i><b>2.1.2</b> Familia exponencial</a></li>
<li class="chapter" data-level="2.1.3" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#distribuciones-previas-no-informativas"><i class="fa fa-check"></i><b>2.1.3</b> Distribuciones previas no informativas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>2.2</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#factor-de-bayes"><i class="fa fa-check"></i><b>2.2.1</b> Factor de Bayes</a></li>
<li class="chapter" data-level="2.2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#valor-p-bayesiano"><i class="fa fa-check"></i><b>2.2.2</b> Valor-<span class="math inline">\(p\)</span> Bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="criterios-de-información.html"><a href="criterios-de-información.html"><i class="fa fa-check"></i><b>2.3</b> Criterios de información</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="criterios-de-información.html"><a href="criterios-de-información.html#criterio-dic"><i class="fa fa-check"></i><b>2.3.1</b> Criterio DIC</a></li>
<li class="chapter" data-level="2.3.2" data-path="criterios-de-información.html"><a href="criterios-de-información.html#criterios-aic-y-bic"><i class="fa fa-check"></i><b>2.3.2</b> Criterios AIC y BIC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modelos-uniparamétricos.html"><a href="modelos-uniparamétricos.html"><i class="fa fa-check"></i><b>3</b> Modelos uniparamétricos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modelo-bernoulli.html"><a href="modelo-bernoulli.html"><i class="fa fa-check"></i><b>3.1</b> Modelo Bernoulli</a></li>
<li class="chapter" data-level="3.2" data-path="modelo-binomial.html"><a href="modelo-binomial.html"><i class="fa fa-check"></i><b>3.2</b> Modelo Binomial</a></li>
<li class="chapter" data-level="3.3" data-path="modelo-binomial-negativo.html"><a href="modelo-binomial-negativo.html"><i class="fa fa-check"></i><b>3.3</b> Modelo Binomial negativo</a></li>
<li class="chapter" data-level="3.4" data-path="modelo-poisson.html"><a href="modelo-poisson.html"><i class="fa fa-check"></i><b>3.4</b> Modelo Poisson</a></li>
<li class="chapter" data-level="3.5" data-path="modelo-exponencial.html"><a href="modelo-exponencial.html"><i class="fa fa-check"></i><b>3.5</b> Modelo Exponencial</a></li>
<li class="chapter" data-level="3.6" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html"><i class="fa fa-check"></i><b>3.6</b> Modelo Normal con media desconocida</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html#distribución-previa-no-informativa-para-theta"><i class="fa fa-check"></i><b>3.6.1</b> Distribución previa no informativa para <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="3.6.2" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html#diferentes-formas-de-hallar-la-distribución-previa-para-theta"><i class="fa fa-check"></i><b>3.6.2</b> Diferentes formas de hallar la distribución previa para <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="3.6.3" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html#distribuciones-predictivas"><i class="fa fa-check"></i><b>3.6.3</b> Distribuciones predictivas</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="modelo-normal-con-varianza-desconocida.html"><a href="modelo-normal-con-varianza-desconocida.html"><i class="fa fa-check"></i><b>3.7</b> Modelo normal con varianza desconocida</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="modelos-multiparamétricos.html"><a href="modelos-multiparamétricos.html"><i class="fa fa-check"></i><b>4</b> Modelos multiparamétricos</a>
<ul>
<li class="chapter" data-level="4.1" data-path="modelo-normal-con-media-y-varianza-desconocida.html"><a href="modelo-normal-con-media-y-varianza-desconocida.html"><i class="fa fa-check"></i><b>4.1</b> Modelo Normal con media y varianza desconocida</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="modelo-normal-con-media-y-varianza-desconocida.html"><a href="modelo-normal-con-media-y-varianza-desconocida.html#parámetros-independientes"><i class="fa fa-check"></i><b>4.1.1</b> Parámetros independientes</a></li>
<li class="chapter" data-level="4.1.2" data-path="modelo-normal-con-media-y-varianza-desconocida.html"><a href="modelo-normal-con-media-y-varianza-desconocida.html#parámetros-dependientes"><i class="fa fa-check"></i><b>4.1.2</b> Parámetros dependientes</a></li>
<li class="chapter" data-level="4.1.3" data-path="modelo-normal-con-media-y-varianza-desconocida.html"><a href="modelo-normal-con-media-y-varianza-desconocida.html#parámetros-no-informativos"><i class="fa fa-check"></i><b>4.1.3</b> Parámetros no informativos</a></li>
<li class="chapter" data-level="4.1.4" data-path="modelo-normal-con-media-y-varianza-desconocida.html"><a href="modelo-normal-con-media-y-varianza-desconocida.html#distribución-predictiva"><i class="fa fa-check"></i><b>4.1.4</b> Distribución predictiva</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="A" data-path="elementos-de-probabilidad.html"><a href="elementos-de-probabilidad.html"><i class="fa fa-check"></i><b>A</b> Elementos de probabilidad</a>
<ul>
<li class="chapter" data-level="A.1" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html"><i class="fa fa-check"></i><b>A.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-uniforme-discreta"><i class="fa fa-check"></i><b>A.1.1</b> Distribución uniforme discreta</a></li>
<li class="chapter" data-level="A.1.2" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-hipergeométrica"><i class="fa fa-check"></i><b>A.1.2</b> Distribución hipergeométrica</a></li>
<li class="chapter" data-level="A.1.3" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-bernoulli"><i class="fa fa-check"></i><b>A.1.3</b> Distribución Bernoulli</a></li>
<li class="chapter" data-level="A.1.4" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-binomial"><i class="fa fa-check"></i><b>A.1.4</b> Distribución binomial</a></li>
<li class="chapter" data-level="A.1.5" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-binomial-negativa"><i class="fa fa-check"></i><b>A.1.5</b> Distribución Binomial negativa</a></li>
<li class="chapter" data-level="A.1.6" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-de-poisson"><i class="fa fa-check"></i><b>A.1.6</b> Distribución de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html"><i class="fa fa-check"></i><b>A.2</b> Distribuciones continuas</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-uniforme-continua"><i class="fa fa-check"></i><b>A.2.1</b> Distribución Uniforme Continua</a></li>
<li class="chapter" data-level="A.2.2" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-weibull"><i class="fa fa-check"></i><b>A.2.2</b> Distribución Weibull</a></li>
<li class="chapter" data-level="A.2.3" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-valor-extremo"><i class="fa fa-check"></i><b>A.2.3</b> Distribución valor-extremo</a></li>
<li class="chapter" data-level="A.2.4" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-gamma"><i class="fa fa-check"></i><b>A.2.4</b> Distribución Gamma</a></li>
<li class="chapter" data-level="A.2.5" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-gamma-inversa"><i class="fa fa-check"></i><b>A.2.5</b> Distribución Gamma-inversa</a></li>
<li class="chapter" data-level="A.2.6" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-exponencial"><i class="fa fa-check"></i><b>A.2.6</b> Distribución exponencial</a></li>
<li class="chapter" data-level="A.2.7" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-beta"><i class="fa fa-check"></i><b>A.2.7</b> Distribución Beta</a></li>
<li class="chapter" data-level="A.2.8" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-normal"><i class="fa fa-check"></i><b>A.2.8</b> Distribución normal</a></li>
<li class="chapter" data-level="A.2.9" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-log-normal"><i class="fa fa-check"></i><b>A.2.9</b> Distribución log-normal</a></li>
<li class="chapter" data-level="A.2.10" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-ji-cuadrado"><i class="fa fa-check"></i><b>A.2.10</b> Distribución Ji-cuadrado</a></li>
<li class="chapter" data-level="A.2.11" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-t-student"><i class="fa fa-check"></i><b>A.2.11</b> Distribución t-student</a></li>
<li class="chapter" data-level="A.2.12" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-t-student-generalizada"><i class="fa fa-check"></i><b>A.2.12</b> Distribución t-student generalizada</a></li>
<li class="chapter" data-level="A.2.13" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-f"><i class="fa fa-check"></i><b>A.2.13</b> Distribución F</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>A.3</b> Distribuciones multivariadas</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-multinomial"><i class="fa fa-check"></i><b>A.3.1</b> Distribución Multinomial</a></li>
<li class="chapter" data-level="A.3.2" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-dirichelt"><i class="fa fa-check"></i><b>A.3.2</b> Distribución Dirichelt</a></li>
<li class="chapter" data-level="A.3.3" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-normal-multivariante"><i class="fa fa-check"></i><b>A.3.3</b> Distribución Normal Multivariante</a></li>
<li class="chapter" data-level="A.3.4" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-wishart"><i class="fa fa-check"></i><b>A.3.4</b> Distribución Wishart</a></li>
<li class="chapter" data-level="A.3.5" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-inversa-wishart"><i class="fa fa-check"></i><b>A.3.5</b> Distribución inversa-Wishart</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="matriz-de-información.html"><a href="matriz-de-información.html"><i class="fa fa-check"></i><b>B</b> Matriz de información</a></li>
<li class="chapter" data-level="C" data-path="elementos-de-simulación-estadística.html"><a href="elementos-de-simulación-estadística.html"><i class="fa fa-check"></i><b>C</b> Elementos de simulación estadística</a>
<ul>
<li class="chapter" data-level="C.1" data-path="métodos-directos.html"><a href="métodos-directos.html"><i class="fa fa-check"></i><b>C.1</b> Métodos directos</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="métodos-directos.html"><a href="métodos-directos.html#método-de-la-transformación-uniforme"><i class="fa fa-check"></i><b>C.1.1</b> Método de la transformación uniforme</a></li>
<li class="chapter" data-level="C.1.2" data-path="métodos-directos.html"><a href="métodos-directos.html#método-de-la-grilla"><i class="fa fa-check"></i><b>C.1.2</b> Método de la grilla</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><i class="fa fa-check"></i><b>C.2</b> Métodos de Monte Carlo vía cadenas de Markov</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-muestreador-de-gibbs"><i class="fa fa-check"></i><b>C.2.1</b> El muestreador de Gibbs</a></li>
<li class="chapter" data-level="C.2.2" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-algoritmo-de-metrópolis-hastings"><i class="fa fa-check"></i><b>C.2.2</b> El algoritmo de Metrópolis-Hastings</a></li>
<li class="chapter" data-level="C.2.3" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#buenas-prácticas-en-la-aplicación-de-métodos-mcmc"><i class="fa fa-check"></i><b>C.2.3</b> Buenas prácticas en la aplicación de métodos MCMC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a Modelos Bayesianos con R y STAN</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Bayesianos con R y STAN</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modelo-normal-con-media-y-varianza-desconocida" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Modelo Normal con media y varianza desconocida</h2>
<p>Supongamos que se dispone de realizaciones de un conjunto de variables independientes e idénticamente distribuidas <span class="math inline">\(Y_1,\cdots,Y_n\sim N(\theta,\sigma^2)\)</span>. Cuando se desconoce tanto la media como la varianza de la distribución es necesario plantear diversos enfoques y situarse en el más conveniente, según el contexto del problema. En términos de la asignación de las distribuciones previas para <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> es posible:</p>
<ul>
<li>Suponer que la distribución previa <span class="math inline">\(p(\theta)\)</span> es independiente de la distribución previa <span class="math inline">\(p(\sigma^2)\)</span> y que ambas distribuciones son informativas.</li>
<li>Suponer que la distribución previa <span class="math inline">\(p(\theta)\)</span> es independiente de la distribución previa <span class="math inline">\(p(\sigma^2)\)</span> y que ambas distribuciones son no informativas.</li>
<li>Suponer que la distribución previa para <span class="math inline">\(\theta\)</span> depende de <span class="math inline">\(\sigma^2\)</span> y escribirla como <span class="math inline">\(p(\theta \mid \sigma^2)\)</span>, mientras que la distribución previa de <span class="math inline">\(\sigma^2\)</span> no depende de <span class="math inline">\(\theta\)</span> y se puede escribir como <span class="math inline">\(p(\sigma^2)\)</span>.</li>
</ul>
<p>A continuación, analizamos cada uno de estos planteamientos, y desarrollamos los resultados necesarios para la estimación de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>.</p>
<div id="parámetros-independientes" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Parámetros independientes</h3>
<p>El primer enfoque que consideraremos para el análisis de los parámetros de interés <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> en una distribución normal univariada es aquel que supone que las distribuciones previas de cada uno de ellos son independientes, pero al mismo tiempo informativas. <span class="citation"><a href="#ref-Gelman03" role="doc-biblioref">A. Gelman et al.</a> (<a href="#ref-Gelman03" role="doc-biblioref">2003</a>)</span> afirman que este supuesto de independencia es atractivo en problemas para los cuales la información previa para <span class="math inline">\(\theta\)</span> no toma la forma de un número fijo de observaciones con varianza <span class="math inline">\(\sigma^2\)</span>. Adicionalmente, este supuesto de independencia es coherente con el hecho de que en la teoría clásica de estimación los estimadores insesgados de varianza mínima de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> son independientes <span class="citation">(<a href="#ref-Zhang" role="doc-biblioref">Zhang y Gutiérrez 2010</a>, Sección 2.4)</span></p>
<p>En este orden de ideas, y siguiendo la argumentación del capítulo anterior, la distribución previa para el parámetro <span class="math inline">\(\theta\)</span> será</p>
<p><span class="math display">\[\begin{equation*}
\theta \sim Normal(\mu,\tau^2)
\end{equation*}\]</span></p>
<p>Y la distribución previa para el parámetro <span class="math inline">\(\sigma^2\)</span> será
<span class="math display">\[\begin{equation*}
\sigma^2 \sim Inversa-Gamma(n_0/2,n_0\sigma^2_0/2)
\end{equation*}\]</span></p>
<p>Asumiendo independencia previa, la distribución previa conjunta estará dada por</p>
<p><span class="math display">\[\begin{equation}
p(\theta,\sigma^2)\propto (\sigma^2)^{-n_0/2-1}\exp\left\{-\dfrac{n_0\sigma^2_0}{2\sigma^2}\right\}
\exp\left\{-\frac{1}{2\tau^2}(\theta-\mu)^2\right\}
\end{equation}\]</span></p>
<p>Una vez que se conoce la forma estructural de la distribución previa conjunta, es posible establecer la distribución posterior conjunta puesto que la verosimilitud de los datos, <span class="math inline">\(p(\mathbf{Y} \mid \theta,\sigma^2)\)</span>, está dada por la expresión <a href="modelo-normal-con-media-desconocida.html#eq:veronormal">(3.16)</a> y</p>
<p><span class="math display">\[\begin{equation*}
p(\theta,\sigma^2 \mid \mathbf{Y})\propto p(\mathbf{Y} \mid \theta,\sigma^2)p(\theta,\sigma^2)
\end{equation*}\]</span></p>

<div class="proposition">
<p><span id="prp:unnamed-chunk-1" class="proposition"><strong>Resultado 3.1  </strong></span>La distribución posterior conjunta de los parámetros de interés está dada por</p>
<span class="math display">\[\begin{align}
p(\theta,\sigma^2 \mid \mathbf{Y})&amp;\propto (\sigma^2)^{-(n+n_0)/2-1} \notag \\
&amp;\times
\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+(n-1)S^2+n(\bar{y}-\theta)^2\right]-\frac{1}{2\tau^2}(\theta-\mu)^2\right\}
\end{align}\]</span>
</div>
<p><br></p>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> Tenemos que
<span class="math display">\[\begin{align*}
p(\theta,\sigma^2 \mid \mathbf{Y})&amp;\propto p(\mathbf{Y} \mid \theta,\sigma^2)p(\theta,\sigma^2)\\
&amp;\propto(\sigma^2)^{-n/2}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-\theta)^2\right\}(\sigma^2)^{-n_0/2-1}\exp\left\{-\dfrac{n_0\sigma^2_0}{2\sigma^2}\right\}
\exp\left\{-\frac{1}{2\tau^2}(\theta-\mu)^2\right\} \\
&amp;=(\sigma^2)^{-(n+n_0)/2-1}\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+\sum_{i=1}^n(y_i-\theta)^2\right]-\frac{1}{2\tau^2}(\theta-\mu)^2\right\}\\
&amp;\propto (\sigma^2)^{-(n+n_0)/2-1}\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+(n-1)S^2+n(\bar{y}-\theta)^2\right]-\frac{1}{2\tau^2}(\theta-\mu)^2\right\}
\end{align*}\]</span>
donde la última expresión se obtiene al sumar y restar <span class="math inline">\(\bar{y}\)</span> dentro de <span class="math inline">\((y_i-\theta)^2\)</span>.
</div>
<p><br></p>
<p>Nótese que la distribución posterior conjunta no tiene una forma estructural conocida y por lo tanto no es posible realizar el método de integración analítica para obtener una constante de integración <span class="citation">(<a href="#ref-Migon" role="doc-biblioref">Migon y Gamerman 1999</a>)</span>. Sin embargo, sí es posible obtener las distribuciones condicionales posteriores de <span class="math inline">\(\theta\)</span> y de <span class="math inline">\(\sigma^2\)</span>, notando que</p>
<p><span class="math display">\[\begin{align*}
p(\theta \mid \sigma^2,\mathbf{Y})\propto p(\theta,\underbrace{\sigma^2}_{fijo} \mid \mathbf{Y})
\ \ \ \ \ \ \ \ \ \text{y} \ \ \ \ \ \ \ \ \ \
p(\sigma^2 \mid \theta,\mathbf{Y})\propto p(\underbrace{\theta}_{fijo},\sigma^2 \mid \mathbf{Y})
\end{align*}\]</span></p>
<p>Es decir, para encontrar la distribución posterior condicional de <span class="math inline">\(\theta | \sigma^2\)</span>, se utiliza la distribución posterior conjunta y los términos que no dependan de <span class="math inline">\(\theta\)</span> se incorporan en la constante de proporcionalidad. El mismo razonamiento se aplica para encontrar la distribución posterior condicional de <span class="math inline">\(\sigma^2 | \theta\)</span>.</p>

<div class="proposition">
<p><span id="prp:unnamed-chunk-3" class="proposition"><strong>Resultado 2.2  </strong></span>La distribución posterior condicional de <span class="math inline">\(\theta\)</span> es</p>
<p><span class="math display" id="eq:PostThetaGibbs">\[\begin{equation}
\tag{4.1}
\theta  \mid  \sigma^2,\mathbf{Y} \sim Normal(\mu_n,\tau_n^2)
\end{equation}\]</span></p>
<p>En donde las expresiones para <span class="math inline">\(\mu_n\)</span> y <span class="math inline">\(\tau_n^2\)</span> están dadas por <a href="modelo-normal-con-media-desconocida.html#eq:TauSigman">(3.17)</a>. Por otro lado, la distribución posterior condicional de <span class="math inline">\(\sigma^2\)</span> es</p>
<p><span class="math display" id="eq:PostSigma2Gibbs">\[\begin{equation}
\tag{4.2}
\sigma^2  \mid  \theta,\mathbf{Y} \sim Inversa-Gamma\left(\dfrac{n_0+n}{2},\dfrac{v_0}{2}\right)
\end{equation}\]</span></p>
con <span class="math inline">\(v_0=n_0\sigma^2_0+(n-1)S^2+n(\bar{y}-\theta)^2\)</span>.
</div>
<p><br></p>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Acudiendo a la distribución posterior conjunta, e incorporando los términos que no dependen de <span class="math inline">\(\theta\)</span> en la constante de proporcionalidad, se tiene que</p>
<p><span class="math display">\[\begin{align*}
p(\theta \mid \sigma^2,\mathbf{Y})&amp;\propto \exp\left\{-\frac{n}{2\sigma^2}(\bar{y}-\theta)^2-\frac{1}{2\tau^2}(\theta-\mu)^2\right\}
\end{align*}\]</span></p>
Completando los cuadrados se encuentra una expresión idéntica a la función de distribución de una variable aleatoria con distribución <span class="math inline">\(Normal(\mu_n, \tau^2_n)\)</span>. Similarmente, después de un desarrollo algebraico breve, se tiene la distribución posterior condicional de <span class="math inline">\(\sigma^2\)</span>.
</div>
<p><br></p>
<p>Una vez encontradas las distribuciones posteriores condicionales de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>, es posible obtener la estimación puntual de estos parámetros usando métodos de Montecarlo, específicamente el muestreo de Gibbs que, en el contexto de este capítulo, se resume en los siguientes pasos:</p>
<ol style="list-style-type: decimal">
<li>Fijar un valor inicial para <span class="math inline">\(\theta\)</span>, denotado por <span class="math inline">\(\theta_{(1)}\)</span>.</li>
<li>Simular un valor de la distribución de <span class="math inline">\(\sigma^2|\theta,\mathbf{Y}\)</span> en <a href="modelo-normal-con-media-y-varianza-desconocida.html#eq:PostSigma2Gibbs">(4.2)</a>. Nótese que el parámetro <span class="math inline">\(v_0\)</span>, que depende de <span class="math inline">\(\theta\)</span>, debe ser reemplazado por <span class="math inline">\(\theta_{(1)}\)</span> del paso anterior. Este valor simulado se denotará como <span class="math inline">\(\sigma^2_{(1)}\)</span>.</li>
<li>Simular un valor de la distribución de <span class="math inline">\(\theta|\sigma^2,\mathbf{Y}\)</span> en <a href="modelo-normal-con-media-y-varianza-desconocida.html#eq:PostThetaGibbs">(4.1)</a>. Nótese que en <span class="math inline">\(\mu_n\)</span> y <span class="math inline">\(\tau^2_n\)</span> se debe reemplazar <span class="math inline">\(\sigma^2\)</span> por <span class="math inline">\(\sigma^2_{(1)}\)</span>. Este valor simulado se denotará como <span class="math inline">\(\theta_{(2)}\)</span>.</li>
<li>Repetir los pasos (2) y (3) hasta completar un número de iteraciones suficientes para alcanzar la convergencia en ambos parámetros.</li>
</ol>
<p>Después de ejecutar el muestreo de Gibbs, se eliminan los primeros valores simulados para descartar la influencia del valor inicial; además, posiblemente se deba efectuar la fase de <em>thinning</em> para eliminar las correlaciones que pueden estar presentes en las cadenas generadas. Posteriormente, se obtendrán los valores finales simulados de las distribuciones de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>, con los cuales se podrá calcular las estimaciones respectivas, además de estimar los intervalos de credibilidad resultantes con los percentiles muestrales de los valores simulados.</p>
<p>En cuanto a la distribución predictiva para una nueva observación <span class="math inline">\(\tilde{y}\)</span>, esta está dada por la siguiente expresión
<span class="math display">\[\begin{equation*}
p(\tilde{y}\mid\mathbf{Y})=\int_0^\infty\int_{-\infty}^\infty p(\tilde{y}\mid\theta,\ \sigma^2)p(\theta,\ \sigma^2\mid\mathbf{Y})d\theta\ d\sigma^2
\end{equation*}\]</span></p>
<p>Hallar esta distribución de forma exacta no es fácil, y podemos optar por conocer el comportamiento probabilístico de <span class="math inline">\(\tilde{y}\)</span> por medio de la simulación estadística. Tal como se explicó en el capítulo anterior, se debe simular en primer lugar valores de <span class="math inline">\(\theta\)</span> y de <span class="math inline">\(\sigma^2\)</span> de la distribución posterior <span class="math inline">\(p(\theta,\ \sigma^2\mid\mathbf{Y})\)</span> - usando el muestreo de Gibbs - y posteriormente, valores de <span class="math inline">\(\tilde{y}\)</span> de la distribución <span class="math inline">\(p(\tilde{y}\mid\theta,\ \sigma^2)\)</span>.</p>
<p>Por otro lado, si se quiere conocer el comportamiento de una nueva muestra aleatoria <span class="math inline">\(Y_1^{*},\cdots,Y_{n^*}^{*}\)</span>, es posible hacerlo por medio de la distribución predictiva de la media <span class="math inline">\(\bar{Y}^*\)</span>, simulando en primer lugar valores de <span class="math inline">\(\theta\)</span> y de <span class="math inline">\(\sigma^2\)</span> de la distribución posterior <span class="math inline">\(p(\theta,\ \sigma^2\mid\mathbf{Y})\)</span> - usando el muestreo de Gibbs - y posteriormente valores de <span class="math inline">\(\bar{Y}^*\)</span> de la distribución <span class="math inline">\(N(\theta,\frac{\sigma^2}{n^*})\)</span>.</p>

<div class="example">
<p><span id="exm:EjeRenal" class="example"><strong>Ejemplo 4.1  </strong></span><span class="citation"><a href="#ref-Efronims" role="doc-biblioref">Efron</a> (<a href="#ref-Efronims" role="doc-biblioref">2010</a>)</span> consideró un conjunto de datos que muestran la función renal de 157 individuos que se sometieron a una prueba médica exhaustiva en un hospital. Los resultados de la prueba renal están en un intervalo de -6 puntos a 4 puntos. Entre más alto sea el resultado, se concluye que el riñón del individuo es más sano. Nótese que estas pruebas son importantes para predecir el comportamiento de un riñón donado a un paciente con problemas renales.</p>
<p>En principio, es de interés para el investigador conocer la media y la dispersión de estos datos, para poder analizar a fondo la situación de los pacientes que esperan un transplante. Dado que se trata de una primera aproximación, se prefiere utilizar distribuciones previas no informativas para los parámetros de la media y varianza. Lo anterior se logra en <code>STAN</code> definiendo las distribuciones previas de <code>theta ~ normal(0, 10000)</code> y de <code>sigma2 ~ inv_gamma(0.001, 0.001)</code>. De esta forma, la distribución previa de <span class="math inline">\(\theta\)</span> está centrada en cero, pero con una varianza muy grande al igual que la distribución de la varianza, los cuales representan distribuciones previas no informativas.</p>
El siguiente código en <code>STAN</code> muestra cómo se lleva a cabo la inferencia.
</div>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-1" aria-hidden="true" tabindex="-1"></a>NormalMeanVar <span class="ot">&lt;-</span> <span class="st">&#39;</span></span>
<span id="cb78-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-2" aria-hidden="true" tabindex="-1"></a><span class="st">data {</span></span>
<span id="cb78-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="st">  int&lt;lower=0&gt; n;</span></span>
<span id="cb78-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-4" aria-hidden="true" tabindex="-1"></a><span class="st">  real y[n];</span></span>
<span id="cb78-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-5" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb78-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-6" aria-hidden="true" tabindex="-1"></a><span class="st">parameters {</span></span>
<span id="cb78-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-7" aria-hidden="true" tabindex="-1"></a><span class="st">  real sigma;</span></span>
<span id="cb78-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-8" aria-hidden="true" tabindex="-1"></a><span class="st">  real theta;</span></span>
<span id="cb78-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb78-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-10" aria-hidden="true" tabindex="-1"></a><span class="st">transformed parameters {</span></span>
<span id="cb78-11"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-11" aria-hidden="true" tabindex="-1"></a><span class="st">  real sigma2;</span></span>
<span id="cb78-12"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-12" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma2 = pow(sigma, 2);</span></span>
<span id="cb78-13"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-13" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb78-14"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-14" aria-hidden="true" tabindex="-1"></a><span class="st">model {</span></span>
<span id="cb78-15"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-15" aria-hidden="true" tabindex="-1"></a><span class="st">  y ~ normal(theta, sigma);</span></span>
<span id="cb78-16"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-16" aria-hidden="true" tabindex="-1"></a><span class="st">  theta ~ normal(0, 1000);</span></span>
<span id="cb78-17"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-17" aria-hidden="true" tabindex="-1"></a><span class="st">  sigma2 ~ inv_gamma(0.001, 0.001);</span></span>
<span id="cb78-18"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-18" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb78-19"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-19" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb78-20"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-21"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-21" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fl">1.69045085</span>, <span class="sc">-</span><span class="fl">1.41076082</span>, <span class="sc">-</span><span class="fl">0.27909483</span>, </span>
<span id="cb78-22"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-22" aria-hidden="true" tabindex="-1"></a>       <span class="sc">-</span><span class="fl">0.91387987</span>,  <span class="fl">3.21868429</span>, <span class="sc">-</span><span class="fl">1.47282460</span>, </span>
<span id="cb78-23"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-23" aria-hidden="true" tabindex="-1"></a>       <span class="sc">-</span><span class="fl">0.96524353</span>, <span class="sc">-</span><span class="fl">2.45084934</span>,  <span class="fl">1.03838153</span>, </span>
<span id="cb78-24"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-24" aria-hidden="true" tabindex="-1"></a>        <span class="fl">1.79928679</span>,  <span class="fl">0.97826621</span>,  <span class="fl">0.67463830</span>, </span>
<span id="cb78-25"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-25" aria-hidden="true" tabindex="-1"></a>       <span class="sc">-</span><span class="fl">1.08665864</span>, <span class="sc">-</span><span class="fl">0.00509027</span>,  <span class="fl">0.43708128</span>)</span>
<span id="cb78-26"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-26" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb78-27"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-28"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-28" aria-hidden="true" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">y =</span> y,</span>
<span id="cb78-29"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-29" aria-hidden="true" tabindex="-1"></a>                    <span class="at">n =</span> n)</span>
<span id="cb78-30"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-30" aria-hidden="true" tabindex="-1"></a>NormalMVfit <span class="ot">&lt;-</span> <span class="fu">stan</span>(<span class="at">model_code =</span> NormalMeanVar,</span>
<span id="cb78-31"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb78-31" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> sample_data, <span class="at">verbose =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(NormalMVfit, <span class="at">digits =</span> <span class="dv">4</span>, </span>
<span id="cb79-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb79-2" aria-hidden="true" tabindex="-1"></a>      <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;theta&quot;</span>, <span class="st">&quot;sigma&quot;</span>, <span class="st">&quot;sigma2&quot;</span>), <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>## Inference for Stan model: de363179728705eed697c67cf38b3332.
## 4 chains, each with iter=2000; warmup=1000; thin=1; 
## post-warmup draws per chain=1000, total post-warmup draws=4000.
## 
##          mean se_mean     sd    2.5%  97.5% n_eff   Rhat
## theta  0.0773  0.0089 0.4111 -0.7173 0.8999  2137 1.0004
## sigma  1.5517  0.0083 0.3157  1.0826 2.3188  1441 1.0021
## sigma2 2.5073  0.0321 1.1161  1.1721 5.3768  1208 1.0025
## 
## Samples were drawn using NUTS(diag_e) at Mon Jun 14 23:55:14 2021.
## For each parameter, n_eff is a crude measure of effective sample size,
## and Rhat is the potential scale reduction factor on split chains (at 
## convergence, Rhat=1).</code></pre>
<p>Después de ejecutar las iteraciones necesarias, la salida del anterior código muestra una estimación puntual para la esperanza de <span class="math inline">\(Y\)</span> de 0.09 con un intervalo de credibilidad del 95% dado por (-0.71, 0.91). Por otro lado, la estimación puntual de la desviación estándar de <span class="math inline">\(Y\)</span> es de 1.55 con un intervalo de credibilidad del 95% dado por (1.09, 2.31).</p>
<p>Las figuras <a href="modelo-normal-con-media-y-varianza-desconocida.html#fig:posNormalMVStan2">4.1</a> muestra la distribución posterior para este ejemplo, junto con la estimación puntual, correspondiente a la desviación estándar.</p>
<div class="figure" style="text-align: center"><span id="fig:posNormalMVStan2"></span>
<img src="4Multiparametricos_files/figure-html/posNormalMVStan2-1.svg" alt="Distribuciones posteriores." width="576" />
<p class="caption">
Figura 4.1: Distribuciones posteriores.
</p>
</div>
<p>A continuación se ilustra el uso de <code>R</code> en la programación de un algoritmo de Gibbs para los datos del ejemplo anterior. Se recalca que se utiliza la librería <code>MCMCpack</code> <span class="citation">(<a href="#ref-MCMCpack" role="doc-biblioref">Martin, Quinn, y Park 2011</a>)</span> para generar las realizaciones de la distribución Inversa-Gamma.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb81-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-3" aria-hidden="true" tabindex="-1"></a><span class="co">#parametros previos de theta</span></span>
<span id="cb81-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb81-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-5" aria-hidden="true" tabindex="-1"></a>tau2 <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb81-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-6" aria-hidden="true" tabindex="-1"></a><span class="co">#parametros previos de sigma2</span></span>
<span id="cb81-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-7" aria-hidden="true" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb81-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-8" aria-hidden="true" tabindex="-1"></a>b <span class="ot">&lt;-</span> <span class="fl">0.001</span></span>
<span id="cb81-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-10" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb81-11"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-11" aria-hidden="true" tabindex="-1"></a>theta.pos <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb81-12"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-12" aria-hidden="true" tabindex="-1"></a>sigma2.pos <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb81-13"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-14"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Valor inicial de theta</span></span>
<span id="cb81-15"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-15" aria-hidden="true" tabindex="-1"></a>theta.pos[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb81-16"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-17"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-17" aria-hidden="true" tabindex="-1"></a><span class="co">#parametros posteriores de sigma2   </span></span>
<span id="cb81-18"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-18" aria-hidden="true" tabindex="-1"></a>a.n <span class="ot">&lt;-</span> a <span class="sc">+</span> n<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb81-19"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-19" aria-hidden="true" tabindex="-1"></a>b.n <span class="ot">&lt;-</span> b <span class="sc">+</span> ((n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">var</span>(y) <span class="sc">+</span> n <span class="sc">*</span> (<span class="fu">mean</span>(y) <span class="sc">-</span> theta.pos[<span class="dv">1</span>]))<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb81-20"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-20" aria-hidden="true" tabindex="-1"></a><span class="co">#simulacion de la distribucion posterior condicional de theta</span></span>
<span id="cb81-21"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-21" aria-hidden="true" tabindex="-1"></a>sigma2.pos[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(<span class="dv">1</span>, a.n, b.n)</span>
<span id="cb81-22"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-23"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-23" aria-hidden="true" tabindex="-1"></a><span class="do">#####################</span></span>
<span id="cb81-24"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Muestreo de Gibbs #</span></span>
<span id="cb81-25"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-25" aria-hidden="true" tabindex="-1"></a><span class="do">#####################</span></span>
<span id="cb81-26"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-27"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-27" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>nsim){</span>
<span id="cb81-28"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-28" aria-hidden="true" tabindex="-1"></a>  <span class="co">#parametros posteriores de theta  </span></span>
<span id="cb81-29"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-29" aria-hidden="true" tabindex="-1"></a>  tau2.n <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> ((n<span class="sc">/</span>sigma2.pos[i <span class="sc">-</span> <span class="dv">1</span>]) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">/</span>tau2))</span>
<span id="cb81-30"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-30" aria-hidden="true" tabindex="-1"></a>  mu.n <span class="ot">&lt;-</span> tau2.n <span class="sc">*</span> (<span class="fu">mean</span>(y) <span class="sc">*</span> (n<span class="sc">/</span>sigma2.pos[i <span class="sc">-</span> <span class="dv">1</span>]) <span class="sc">+</span> mu<span class="sc">/</span>tau2)</span>
<span id="cb81-31"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-31" aria-hidden="true" tabindex="-1"></a>  <span class="co">#simulacion de la distribucion posterior condicional de theta</span></span>
<span id="cb81-32"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-32" aria-hidden="true" tabindex="-1"></a>  theta.pos[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean=</span>mu.n, <span class="at">sd=</span><span class="fu">sqrt</span>(tau2.n))</span>
<span id="cb81-33"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-33" aria-hidden="true" tabindex="-1"></a>  <span class="co">#parametros posteriores de sigma2 </span></span>
<span id="cb81-34"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-34" aria-hidden="true" tabindex="-1"></a>  a.n <span class="ot">&lt;-</span> a <span class="sc">+</span> n<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb81-35"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-35" aria-hidden="true" tabindex="-1"></a>  b.n <span class="ot">&lt;-</span> b <span class="sc">+</span> ((n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> <span class="fu">var</span>(y) <span class="sc">+</span> n <span class="sc">*</span> (<span class="fu">mean</span>(y) <span class="sc">-</span> theta.pos[i])) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb81-36"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-36" aria-hidden="true" tabindex="-1"></a>  <span class="co">#simulacion de la distribucion posterior condicional de theta</span></span>
<span id="cb81-37"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-37" aria-hidden="true" tabindex="-1"></a>  sigma2.pos[i] <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(<span class="dv">1</span>, a.n, b.n)</span>
<span id="cb81-38"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb81-38" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(theta.pos)</span></code></pre></div>
<pre><code>## [1] 0.08134119</code></pre>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta.pos, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##       2.5%      97.5% 
## -0.7351317  0.8825539</code></pre>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">sqrt</span>(sigma2.pos))</span></code></pre></div>
<pre><code>## [1] 1.54241</code></pre>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(<span class="fu">sqrt</span>(sigma2.pos), <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 1.020166 2.347198</code></pre>
<p>De donde podemos concluir que los resultados de este algoritmo de Gibbs coinciden con la estimación puntual para la esperanza de <span class="math inline">\(Y\)</span>, su desviación estándar, y sus intervalos de credibilidad del 95%, obtenidos con <code>STAN</code>.</p>
<div class="figure" style="text-align: center"><span id="fig:plotsNormalMV"></span>
<img src="4Multiparametricos_files/figure-html/plotsNormalMV-1.svg" alt="Convergencia de las distribuciones posteriores y diagramas de la función de autocorrelación en las cadenas." width="768" />
<p class="caption">
Figura 4.2: Convergencia de las distribuciones posteriores y diagramas de la función de autocorrelación en las cadenas.
</p>
</div>
<p>Las figuras <a href="modelo-normal-con-media-y-varianza-desconocida.html#fig:plotsNormalMV">4.2</a> muestran que la convergencia de las cadenas es inmediata y que además no existen correlaciones importantes en los valores simulados de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>. Por tanto, se concluye que se pueden utilizar directamente estos valores para la obtención de las estimaciones. Finalmente se ilustra la forma de obtener la distribución predictiva para el promedio muestral de 5 nuevos pacientes.</p>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb90-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-1" aria-hidden="true" tabindex="-1"></a>n.ast <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb90-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-2" aria-hidden="true" tabindex="-1"></a>y.bar <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb90-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>(nsim<span class="sc">/</span><span class="dv">2</span>)){</span>
<span id="cb90-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-5" aria-hidden="true" tabindex="-1"></a>  y.bar[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>,</span>
<span id="cb90-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-6" aria-hidden="true" tabindex="-1"></a>                    theta.pos[i <span class="sc">+</span> nsim<span class="sc">/</span><span class="dv">2</span>],</span>
<span id="cb90-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-7" aria-hidden="true" tabindex="-1"></a>                    <span class="fu">sqrt</span>(sigma2.pos[i <span class="sc">+</span> nsim<span class="sc">/</span><span class="dv">2</span>]<span class="sc">/</span>n.ast))</span>
<span id="cb90-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb90-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb90-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb90-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(y.bar)</span></code></pre></div>
<pre><code>## [1] 0.1030324</code></pre>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb92-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(y.bar)</span></code></pre></div>
<pre><code>## [1] 0.7967851</code></pre>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb94-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(y.bar,<span class="fu">c</span>(<span class="fl">0.025</span>,<span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##      2.5%     97.5% 
## -1.514231  1.553076</code></pre>
<p>Podemos ver que se espera que el promedio de las pruebas en 5 nuevos pacientes es de 0.1030324, con un intervalo de credibilidad del 95% que es mucho más ancho que el de <span class="math inline">\(\theta\)</span>, pues naturalmente <span class="math inline">\(\bar{Y}\)</span> tiene mayor incertidumbre que los parámetros del modelo; además, el tamaño de nuevos datos es de cinco, el cual es pequeño y hace que el pronóstico para <span class="math inline">\(\bar{Y}^*\)</span> no sea muy preciso.</p>
</div>
<div id="parámetros-dependientes" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Parámetros dependientes</h3>
<p>En algunas situaciones es muy útil asumir una distribución previa conjugada, y para lograr eso no es posible establecer que los parámetros tengan distribuciones previas independientes. Bajo esta situación, la inferencia posterior de los parámetros de interés debe ser llevada a cabo en dos etapas: En la primera, se debe establecer la distribución previa conjunta para ambos parámetros siguiendo la siguiente regla
<span class="math display">\[\begin{equation*}
p(\theta,\sigma^2)=p(\sigma^2)p(\theta \mid \sigma^2)
\end{equation*}\]</span></p>
<p>En la segunda etapa ya es posible analizar propiamente cada uno de los parámetros de interés siguiendo otra sencilla regla análoga
<span class="math display">\[\begin{equation*}
p(\theta,\sigma^2 \mid \mathbf{Y})\propto p(\mathbf{Y} \mid \theta,\sigma^2)p(\theta,\sigma^2)
\end{equation*}\]</span></p>
<p>La anterior formulación conlleva a asignar una distribución previa para <span class="math inline">\(\theta\)</span> dependiente del parámetro <span class="math inline">\(\sigma^2\)</span>. Esto quiere decir que en la distribución <span class="math inline">\(p(\theta \mid \sigma^2)\)</span>, el valor de <span class="math inline">\(\sigma^2\)</span> se considera una constante fija y conocida, esta distribución previa está dada por<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<p><span class="math display">\[\begin{equation*}
p(\theta \mid \sigma^2) \sim Normal(\mu,\sigma^2/c_0)
\end{equation*}\]</span></p>
<p>donde <span class="math inline">\(c_0\)</span> es una constante. Por otro lado, y siguiendo los argumentos del capítulo anterior, una posible opción para la distribución previa de <span class="math inline">\(\sigma^2\)</span>, que no depende de <span class="math inline">\(\theta\)</span>, corresponde a
<span class="math display">\[\begin{equation*}
p(\sigma^2)\sim Inversa-Gamma(n_0/2,n_0\sigma^2_0/2)
\end{equation*}\]</span></p>
<p>De esta forma, podemos encontrar la distribución conjunta previa de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> como sigue:</p>

<div class="proposition">
<span id="prp:unnamed-chunk-10" class="proposition"><strong>Resultado 4.1  </strong></span>La distribución conjunta previa de los parámetros <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> está dada por
<span class="math display">\[\begin{equation*}
\theta,\sigma^2 \sim Normal-Inversa-Gamma\left(\mu, c_0, \frac{n_0+1}{2},\frac{n_0\sigma^2_0}{2}\right)
\end{equation*}\]</span>
</div>
<p><br></p>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> <span class="math display">\[\begin{align*}
p(\theta,\sigma^2)&amp;=p(\sigma^2)p(\theta \mid \sigma^2)\\
&amp;\propto (\sigma^2)^{-\frac{n_0}{2}-1}\exp\left\{-\dfrac{n_0\sigma_0^2}{2\sigma^2}\right\}
(\sigma^2)^{-\frac{1}{2}}\exp\left\{-\frac{c_0}{2\sigma^2}(\theta-\mu)^2\right\}\\
&amp;= (\sigma^2)^{-\frac{n_0+1}{2}-1}\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+c_0(\theta-\mu)^2\right]\right\}
\end{align*}\]</span>
la cual corresponde a la forma de la función de densidad de la distribución Normal-Inversa-Gamma.
</div>
<p><br></p>
<p>Una vez encontrada la distribución conjunta previa, procedemos a encontrar la distribución conjunta posterior, y así poder encontrar las estimaciones de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>.</p>

<div class="proposition">
<p><span id="prp:unnamed-chunk-12" class="proposition"><strong>Resultado 4.2  </strong></span>La distribución posterior conjunta de los parámetros <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> está dada por
<span class="math display">\[\begin{equation*}
\theta,\sigma^2\mid\mathbf{Y} \sim Normal-Inversa-Gamma\left(\mu_n, c_0+n, \frac{n_0+n+1}{2},\beta \right).
\end{equation*}\]</span></p>
<p>con
<span class="math display">\[\begin{equation*}
\beta=\dfrac{1}{2}\left(n_0\sigma^2_0+(n-1)S^2+\dfrac{c_0n}{c_0+n}(\mu-\bar{y})^2\right)
\end{equation*}\]</span></p>
y
<span class="math display">\[\begin{equation*}
\mu_n=\frac{\frac{n}{\sigma^2}\bar{Y}+\frac{c_0}{\sigma^2}\mu}{\frac{n}{\sigma^2}+\frac{c_0}{\sigma^2}}
=\frac{n\bar{Y}+c_0\mu}{n+c_0}
\end{equation*}\]</span>
</div>
<p><br></p>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> En primer lugar, recordamos que la función de verosimilitud de la muestra está dada por
<span class="math display">\[\begin{align}
p(\mathbf{Y} \mid \theta,\sigma^2)= \frac{1}{(2\pi\sigma^2)^{n/2}}
\exp\left\{-\frac{1}{2\sigma^2}\left[(n-1)S^2+n(\bar{y}-\theta)^2\right]\right\}
\end{align}\]</span></p>
Por otro lado, se tiene que
<span class="math display" id="eq:desarro1">\[\begin{align}
\tag{4.3}
p(\theta,\sigma^2 \mid \mathbf{Y}) &amp; \propto p(\mathbf{Y} \mid \theta,\sigma^2)p(\theta,\sigma^2)\notag\\
&amp;\propto (\sigma^2)^{-\frac{n_0+n+1}{2}-1}
\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+c_0(\theta-\mu)^2+(n-1)S^2+n(\bar{y}-\theta)^2\right]\right\}\notag\\
&amp;= (\sigma^2)^{-\frac{n_0+n+1}{2}-1}\\
&amp;\times
\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+(n-1)S^2+(c_0+n)(\theta-\mu_n)^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2\right]\right\}
\end{align}\]</span>
puesto que
<span class="math display">\[\begin{align*}
c_0(\theta-\mu)^2+n(\bar{y}-\theta)^2=(c_0+n)(\theta-\mu_n)^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2
\end{align*}\]</span>
</div>
<p><br></p>
<p>Para encontrar las distribuciones marginales posterior de cada uno de los parámetros se procede de la siguiente forma:</p>
<ol style="list-style-type: decimal">
<li>Para hallar la distribución posterior condicional de <span class="math inline">\(\theta\)</span>, dada por <span class="math inline">\(P(\theta \mid \sigma^2,\mathbf{Y})\)</span>, se debe considerar que <span class="math inline">\(\sigma^2\)</span> es una constante fija y conocida, tal como se consideró al principio de esta sección. Basado en lo anterior, es posible utilizar la siguiente regla de probabilidad
<span class="math display">\[\begin{align*}
P(\theta \mid \sigma^2,\mathbf{Y})=\frac{p(\theta,\sigma^2 \mid \mathbf{Y})}{p(\sigma^2,\mathbf{Y})}p(\mathbf{Y})\propto p(\theta,\sigma^2 \mid \mathbf{Y})
\end{align*}\]</span>
Lo anterior sugiere que la distribución marginal posterior de <span class="math inline">\(\theta\)</span>, <span class="math inline">\(p(\theta \mid \sigma^2,\mathbf{Y})\)</span>, se encuentra utilizando la distribución posterior conjunta, <span class="math inline">\(p(\theta,\sigma^2 \mid \mathbf{Y})\)</span>, suponiendo que todas las expresiones que involucren al valor <span class="math inline">\(\sigma^2\)</span> se pueden incluir en la constante de proporcionalidad</li>
<li>Dado que <span class="math inline">\(\sigma^2\)</span> no depende de ningún otro parámetro entonces, utilizando la distribución posterior conjunta, es posible encontrar su distribución marginal posterior de la siguiente forma
<span class="math display">\[\begin{align*}
p(\sigma^2 \mid \mathbf{Y})=\int p(\theta,\sigma^2 \mid \mathbf{Y}) d\theta
\end{align*}\]</span></li>
<li>Un razonamiento similar se puede formular para el parámetro <span class="math inline">\(\theta\)</span>; utilizando la distribución posterior conjunta, es posible encontrar su distribución marginal posterior de la siguiente forma
<span class="math display">\[\begin{align*}
p(\theta \mid \mathbf{Y})=\int p(\theta,\sigma^2 \mid \mathbf{Y}) d\sigma^2
\end{align*}\]</span></li>
</ol>

<div class="proposition">
<span id="prp:unnamed-chunk-14" class="proposition"><strong>Resultado 4.3  </strong></span>La distribución posterior de <span class="math inline">\(\theta\)</span> condicional a <span class="math inline">\(\sigma^2,\mathbf{Y}\)</span> está dada por
<span class="math display">\[\begin{equation*}
\theta \mid \sigma^2,\mathbf{Y} \sim Normal(\mu_n,\sigma^2/(n+c_0))
\end{equation*}\]</span>
con <span class="math inline">\(\mu_n=\dfrac{n\bar{y}+c_0\mu}{n+c_0}\)</span>.
</div>
<p><br></p>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> Acudiendo a la distribución posterior conjunta dada en <a href="modelo-normal-con-media-y-varianza-desconocida.html#eq:desarro1">(4.3)</a>, tenemos que
<span class="math display">\[\begin{align*}
p(\theta \mid \sigma^2,\mathbf{Y})&amp;\propto 
p(\theta,\sigma^2 \mid \mathbf{Y}) \\
&amp;\propto(\sigma^2)^{-\frac{n_0+n+1}{2}-1}\\
&amp;\hspace{1cm}\times
\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+(n-1)S^2+(c_0+n)(\theta-\mu_n)^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2\right]\right\}\\
&amp;\propto \exp\left\{-\frac{1}{2\sigma^2}(c_0+n)(\theta-\mu_n)^2\right\}
\end{align*}\]</span>
la cual corresponde a la forma de la función de densidad de la distribución <span class="math inline">\(Normal(\mu_n, \sigma^2/(n+c_0))\)</span>.
</div>
<p>En el anterior resultado, la media de la distribución condicional posterior <span class="math inline">\(\mu_n\)</span> se puede escribir como <span class="math inline">\(\mu_n=\frac{n}{n+c_0}\bar{y}+\frac{c_0}{n+c_0}\mu\)</span>, promedio ponderado entre la estimación clásica <span class="math inline">\(\bar{y}\)</span> y la estimación previa <span class="math inline">\(\mu\)</span>. Observando que las ponderaciones <span class="math inline">\(\frac{n}{n+c_0}\)</span> y <span class="math inline">\(\frac{c_0}{n+c_0}\)</span> forman una combinación lineal convexa, se puede definir a <span class="math inline">\(c_0\)</span> como el número de observaciones en la información previa. De esta forma, las ponderaciones de la estimación clásica y la estimación previa dependerán directamente de los tamaños muestrales respectivos.</p>

<div class="proposition">
<p><span id="prp:PosterSigma2IG" class="proposition"><strong>Resultado 4.4  </strong></span>La distribución marginal posterior del parámetro <span class="math inline">\(\sigma^2\)</span> es
<span class="math display">\[\begin{equation*}
\sigma^2 \mid \mathbf{Y} \sim Inversa-Gamma\left(\frac{n+n_0}{2},\frac{(n+n_0)\sigma^2_n}{2}\right)
\end{equation*}\]</span></p>
Donde <span class="math inline">\((n+n_0)\sigma^2_n=n_0\sigma^2_0+(n-1)S^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2\)</span> corresponde a una suma ponderada de la varianza previa, la varianza muestral y la diferencia entre la media muestral y la media previa.
</div>
<p><br></p>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> De la distribución posterior conjunta <a href="modelo-normal-con-media-y-varianza-desconocida.html#eq:desarro1">(4.3)</a>, e integrando con respecto a <span class="math inline">\(\theta\)</span>, se tiene que</p>
<p><span class="math display">\[\begin{align*}
p(\sigma^2 \mid \mathbf{Y})&amp;=\int p(\theta,\sigma^2 \mid \mathbf{Y}) \ d\theta\\
&amp;\propto (\sigma^2)^{-\frac{n_0+n+1}{2}-1}
\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+(n-1)S^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2\right]\right\}\\
&amp;\hspace{2cm}\times
\int_{-\infty}^{\infty}\exp\left\{-\frac{n+c_0}{2\sigma^2}(\theta-\mu_n)^2\right\} \ d\theta\\
&amp;\propto (\sigma^2)^{-\frac{n_0+n}{2}-1}
\exp\left\{-\frac{1}{2\sigma^2}\left[n_0\sigma^2_0+(n-1)S^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2\right]\right\}\\
&amp;\hspace{2cm}\times
\int_{-\infty}^{\infty}\frac{\sqrt{n+c_0}}{\sqrt{2\pi\sigma^2}}
\exp\left\{-\frac{n+c_0}{2\sigma^2}(\theta-\mu_n)^2\right\} \ d\theta\\
&amp;\propto (\sigma^2)^{-\frac{n_0+n}{2}-1}
\exp\left\{-\frac{(n+n_0)\sigma^2_n}{2\sigma^2}\right\}
\end{align*}\]</span></p>
la cual corresponde a la forma funcional de la densidad <span class="math inline">\(Inversa-Gamma(\frac{n+n_0}{2},\frac{(n+n_0)\sigma^2_n}{2})\)</span>.
</div>
<p><br></p>
<p>Dadas las distribuciones <span class="math inline">\(p(\sigma^2\mid \mathbf{Y})\)</span> y <span class="math inline">\(p(\theta\mid \sigma^2, \mathbf{Y})\)</span>, podemos proceder de la siguiente forma para obtener valores simulados de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> y por consiguiente sus estimaciones puntuales. Si el número de iteraciones se fija como <span class="math inline">\(G\)</span>, entonces se debe seguir el siguiente algoritmo:</p>
<ol style="list-style-type: decimal">
<li>Simular <span class="math inline">\(G\)</span> valores de la distribución de <span class="math inline">\(\sigma^2|\mathbf{Y}\)</span>; es decir, de la distribución <span class="math inline">\(Inversa-Gamma\)</span> encontrada en el anterior resultado. Estos valores se denotan por <span class="math inline">\(\sigma^2_{(1)},\sigma^2_{(2)},\cdots,\sigma^2_{(G)}\)</span>.</li>
<li>Para cada valor de <span class="math inline">\(\sigma^2_{(g)}\)</span>, con <span class="math inline">\(g=1,\cdots,G\)</span>, simular un valor de la distribución de <span class="math inline">\(\theta|\sigma^2,\mathbf{Y}\)</span>; es decir, de la distribución <span class="math inline">\(N(\mu_n,\sigma^2/(n+c_0))\)</span>, donde <span class="math inline">\(\sigma^2\)</span> se reemplaza por <span class="math inline">\(\sigma^2_{(g)}\)</span>. De esta forma, se obtiene los valores <span class="math inline">\(\theta_{(1)},\theta_{(2)},\cdots,\theta_{(G)}\)</span>.</li>
</ol>
<p>Es claro que en el anterior algoritmo, no es necesario fijar algún valor inicial para <span class="math inline">\(\theta\)</span> o para <span class="math inline">\(\sigma^2\)</span>. De la misma forma no existirán correlaciones sustantivas entre los valores simulados para ningún parámetro. Por lo tanto, estos valores se pueden usar directamente para el cálculo de las estimaciones, y no es necesario descartar los primeros valores simulados, ni realizar la fase de <em>thinning</em>.</p>
<p>Ahora bien, existe otra alternativa para obtener la estimación de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>, la cual depende directamente de la distribución posterior de cada parámetro. En efecto, la distribución posterior de <span class="math inline">\(\sigma^2\)</span> ya se encontró en el resultado <a href="modelo-normal-con-media-y-varianza-desconocida.html#prp:PosterSigma2IG">4.4</a>, resta encontrar la distribución posterior de <span class="math inline">\(\theta\)</span>, la cual se presenta en el siguiente resultado.</p>

<div class="proposition">
<span id="prp:PosThetaTnoestandar" class="proposition"><strong>Resultado 4.5  </strong></span>La distribución posterior del parámetro <span class="math inline">\(\theta\)</span> corresponde a una <span class="math inline">\(t\)</span> no estandarizada con <span class="math inline">\(n_0+n\)</span> grados de libertad, parámetro de localización <span class="math inline">\(\mu_n=\dfrac{n\bar{Y}+c_0\mu}{n+c_0}\)</span> y parámetro de escala <span class="math inline">\(\dfrac{\sigma_n}{\sqrt{c_0+n}}\)</span>, con <span class="math inline">\((n+n_0)\sigma^2_n=n_0\sigma^2_0+(n-1)S^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2\)</span>. Esto es,
<span class="math display">\[\begin{equation*}
\theta \mid \mathbf{Y} \sim t_{n+n_0}\left(\mu_n, \frac{\sigma^2_n}{c_0+n}\right)
\end{equation*}\]</span>
</div>
<p><br></p>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Partiendo de la distribución posterior conjunta e integrando con respecto a <span class="math inline">\(\sigma^2\)</span>, se tiene que</p>
<p><span class="math display">\[\begin{align*}
p(\theta \mid \mathbf{Y})&amp;= \int_0^{\infty} p(\theta,\sigma^2 \mid \mathbf{Y}) \ d\sigma^2 \\
&amp;\propto \int_0^{\infty} \left(\frac{1}{\sigma^2}\right)^{\frac{n_0+n+1}{2}+1}
\exp\left\{-\frac{1}{2\sigma^2}\left[(n_0+n)\sigma^2_n+(c_0+n)(\theta-\mu_n)^2\right]\right\} \ d\sigma^2
\end{align*}\]</span></p>
<p>Haciendo un cambio de variable tal que
<span class="math display">\[\begin{equation*}
z=\frac{A}{2\sigma^2}, \ \ \ \ \ \ \ \ \ \ \ \text{donde} \ \ \ A=(n_0+n)\sigma^2_n+(c_0+n)(\theta-\mu_n)^2
\end{equation*}\]</span></p>
<p>Por tanto
<span class="math display">\[\begin{equation*}
d\sigma^2=-\frac{A}{2z^2} \ dz
\end{equation*}\]</span></p>
<p>Volviendo a la integral en cuestión, se tiene que
<span class="math display">\[\begin{align*}
p(\theta \mid \mathbf{Y})&amp; \propto
\left(\frac{1}{A}\right)^{\frac{n_0+n+1}{2}+1}\int_{\infty}^{0} \frac{-A}{2z^2} (2z)^{\frac{n_0+n+1}{2}+1}e^{-z} \ dz \\
&amp;\propto A^{-\frac{n_0+n+1}{2}}\underbrace{\int_{0}^{\infty} z^{\frac{n_0+n+1}{2}-1}e^{-z}\ dz}_{Gamma\left(\frac{n_0+n+1}{2},1\right)}\\
&amp;\propto A^{-\frac{n_0+n+1}{2}}\\
&amp;= \left[(n_0+n)\sigma^2_n+(c_0+n)(\theta-\mu_n)^2\right]^{-\frac{n_0+n+1}{2}}\\
&amp;\propto \left[1+\frac{(c_0+n)(\theta-\mu_n)^2}{(n_0+n)\sigma^2_n}\right]^{-\frac{n_0+n+1}{2}}\\
&amp;=\left[1+\frac{1}{n_0+n}\left(\frac{\theta-\mu_n}{\sigma_n/\sqrt{c_0+n}}\right)^2\right]^{-\frac{n_0+n+1}{2}}
\end{align*}\]</span></p>
la cual corresponde a la forma de la función de densidad de la distribución deseada.
</div>
<p><br></p>
<p>Las distribuciones encontradas en los resultados <a href="modelo-normal-con-media-y-varianza-desconocida.html#prp:PosterSigma2IG">4.4</a> y <a href="modelo-normal-con-media-y-varianza-desconocida.html#prp:PosThetaTnoestandar">4.5</a> permiten estimar directamente los parámetros <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> usando las esperanzas teóricas de las distribuciones posteriores. Por ende, las estimaciones puntuales son:</p>
<p><span class="math display">\[\begin{align*}
\hat{\theta}
&amp;=\mu_n=\dfrac{n\bar{Y}+c_0\mu}{n+n_0}\\
\hat{\sigma}^2
&amp;=\dfrac{(n+n_0)\sigma^2_n/2}{(n+n_0)/2-1}=\dfrac{(n+n_0)\sigma^2_n}{n+n_0-2}\approx\sigma^2_n=\dfrac{n_0\sigma^2_0+(n-1)S^2+\frac{c_0n}{c_0+n}(\mu-\bar{y})^2}{n+n_0}
\end{align*}\]</span></p>
<p>Los intervalos del <span class="math inline">\((1-\alpha)\times 100\%\)</span> de credibilidad para <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> se construyen usando los percentiles <span class="math inline">\(\alpha/2\)</span> y <span class="math inline">\(1-\alpha/2\)</span> de las respectivas distribuciones posteriores dadas en los resultados mencionados anteriormente. Ilustramos el uso de la metodología en el siguiente ejemplo.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-18" class="example"><strong>Ejemplo 2.2  </strong></span>Para los datos de función renal  que se muestran en el Ejemplo <a href="modelo-normal-con-media-y-varianza-desconocida.html#exm:EjeRenal">4.1</a>, suponga que la información previa está contenida en la medición de función renal para una muestra de 12 pacientes dadas por: -1.3619, -1.1116, -0.4744, -0.5663, 2.2056, 0.9491, 0.2298, -0.7933, 1.0198, -0.9850, 3.5679 y -1.9504. La media y la varianza muestral de estas 12 observaciones corresponden a <span class="math inline">\(\mu=0.060775\)</span> y <span class="math inline">\(\sigma^2_0=2.598512\)</span>; por consiguiente <span class="math inline">\(c_0=n_0=12\)</span>.</p>
<p>Por otro lado, la media y la varianza muestral de los 15 pacientes en la información actual son <span class="math inline">\(\bar{y}=0.08349249\)</span> y <span class="math inline">\(S^2=2.301684\)</span>. De esta forma, los parámetros de las distribuciones marginales posteriores de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> se pueden calcular como <span class="math inline">\(\mu_n=\frac{15}{15+12}\times 0.08349249+\frac{12}{15+12}\times 0.060775=0.07339583\)</span> y <span class="math display">\[\sigma^2_n=\dfrac{12*2.598512+14*2.301684+6.666667*(0.060775-0.08349249)^2}{15+12}=2.348487\]</span> En conclusión, las distribuciones marginales posterior de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> están dadas por
<span class="math display">\[\begin{equation*}
\theta|\mathbf{Y}\sim t_{27}(0.07339583,2.348487/27=0.086981)
\end{equation*}\]</span></p>
<p>y
<span class="math display">\[\begin{equation*}
\sigma^2|\mathbf{Y}\sim Inversa-Gamma(27/2=13.5,\ 27*2.348487/2=31.70457)
\end{equation*}\]</span></p>
Así, la estimación Bayesiana de <span class="math inline">\(\theta\)</span> es <span class="math inline">\(\mu_n=0.073\)</span> y un intervalo de credibilidad del <span class="math inline">\(95\%\)</span> para <span class="math inline">\(\theta\)</span> se puede calcular como <span class="math inline">\(0.073\pm t_{27,0.975}*\sqrt{0.086981}=(-0.53,\ 0.68)\)</span>. Por otro lado, la estimación Bayesiana de <span class="math inline">\(\sigma^2\)</span> está dada por <span class="math inline">\(31.70457/(13.5-1)=2.53\)</span>, y un intervalo de credibilidad del <span class="math inline">\(95\%\)</span> para <span class="math inline">\(\sigma^2\)</span> se puede calcular como los percentiles <span class="math inline">\(2.5\%\)</span> y <span class="math inline">\(97.5\%\)</span> de la distribución <span class="math inline">\(Inversa-Gamma(13.5,\ 31.70457)\)</span>, dados por <span class="math inline">\((1.5, 4.4)\)</span>. Los anteriores cálculos se ilustran en el siguiente código <code>R</code>.
</div>
<p><br></p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pscl)</span>
<span id="cb96-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos de la informacion previa</span></span>
<span id="cb96-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.3619</span>, <span class="sc">-</span><span class="fl">1.1116</span>, <span class="sc">-</span><span class="fl">0.4744</span>, <span class="sc">-</span><span class="fl">0.5663</span>, </span>
<span id="cb96-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-4" aria-hidden="true" tabindex="-1"></a>        <span class="fl">2.2056</span>,  <span class="fl">0.9491</span>,  <span class="fl">0.2298</span>, <span class="sc">-</span><span class="fl">0.7933</span>, </span>
<span id="cb96-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-5" aria-hidden="true" tabindex="-1"></a>        <span class="fl">1.0198</span>, <span class="sc">-</span><span class="fl">0.9850</span>,  <span class="fl">3.5679</span>, <span class="sc">-</span><span class="fl">1.9504</span>)</span>
<span id="cb96-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos de la informacion actual</span></span>
<span id="cb96-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-7" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>( <span class="fl">1.69045085</span>, <span class="sc">-</span><span class="fl">1.41076082</span>, <span class="sc">-</span><span class="fl">0.27909483</span>, </span>
<span id="cb96-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-8" aria-hidden="true" tabindex="-1"></a>       <span class="sc">-</span><span class="fl">0.91387987</span>,  <span class="fl">3.21868429</span>, <span class="sc">-</span><span class="fl">1.47282460</span>, </span>
<span id="cb96-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-9" aria-hidden="true" tabindex="-1"></a>       <span class="sc">-</span><span class="fl">0.96524353</span>, <span class="sc">-</span><span class="fl">2.45084934</span>,  <span class="fl">1.03838153</span>, </span>
<span id="cb96-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-10" aria-hidden="true" tabindex="-1"></a>        <span class="fl">1.79928679</span>,  <span class="fl">0.97826621</span>,  <span class="fl">0.67463830</span>, </span>
<span id="cb96-11"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-11" aria-hidden="true" tabindex="-1"></a>       <span class="sc">-</span><span class="fl">1.08665864</span>, <span class="sc">-</span><span class="fl">0.00509027</span>,  <span class="fl">0.43708128</span>)</span>
<span id="cb96-12"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Paramatros de la distribucion previa</span></span>
<span id="cb96-13"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-13" aria-hidden="true" tabindex="-1"></a>n0 <span class="ot">&lt;-</span> c0 <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb96-14"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-14" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">mean</span>(x)</span>
<span id="cb96-15"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-15" aria-hidden="true" tabindex="-1"></a>sigma2_0 <span class="ot">&lt;-</span> <span class="fu">var</span>(x)</span>
<span id="cb96-16"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-17"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Informacion</span></span>
<span id="cb96-18"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-18" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(y)</span>
<span id="cb96-19"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-19" aria-hidden="true" tabindex="-1"></a>bar.y <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb96-20"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-20" aria-hidden="true" tabindex="-1"></a>S2 <span class="ot">&lt;-</span> <span class="fu">var</span>(y)</span>
<span id="cb96-21"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-22"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Algunos paramatros de la distribucion posterior</span></span>
<span id="cb96-23"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-23" aria-hidden="true" tabindex="-1"></a>mu.n <span class="ot">&lt;-</span> (n <span class="sc">*</span> bar.y <span class="sc">+</span> c0 <span class="sc">*</span> mu)<span class="sc">/</span>(n <span class="sc">+</span> n0)</span>
<span id="cb96-24"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-24" aria-hidden="true" tabindex="-1"></a>sigma2_n <span class="ot">&lt;-</span> (n0 <span class="sc">*</span> sigma2_0 <span class="sc">+</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> S2 <span class="sc">+</span></span>
<span id="cb96-25"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-25" aria-hidden="true" tabindex="-1"></a>               c0 <span class="sc">*</span> n <span class="sc">*</span> (mu <span class="sc">-</span> bar.y)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>(c0 <span class="sc">+</span> n))<span class="sc">/</span>(n <span class="sc">+</span> n0)</span>
<span id="cb96-26"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimacion puntual</span></span>
<span id="cb96-27"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-27" aria-hidden="true" tabindex="-1"></a>theta.hat <span class="ot">&lt;-</span> mu.n </span>
<span id="cb96-28"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-28" aria-hidden="true" tabindex="-1"></a>sigma2.hat <span class="ot">&lt;-</span> (n <span class="sc">+</span> n0) <span class="sc">*</span> sigma2_n<span class="sc">/</span>(n <span class="sc">+</span> n0 <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb96-29"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb96-29" aria-hidden="true" tabindex="-1"></a>theta.hat</span></code></pre></div>
<pre><code>## [1] 0.07339583</code></pre>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb98-1" aria-hidden="true" tabindex="-1"></a>sigma2.hat</span></code></pre></div>
<pre><code>## [1] 2.536367</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervalo de credibilidad de 95% para theta</span></span>
<span id="cb100-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb100-2" aria-hidden="true" tabindex="-1"></a>mu.n <span class="sc">+</span> <span class="fu">qt</span>(<span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>), <span class="at">df =</span> n <span class="sc">+</span> n0) <span class="sc">*</span> </span>
<span id="cb100-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb100-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sqrt</span>(sigma2_n<span class="sc">/</span>(n <span class="sc">+</span> n0))</span></code></pre></div>
<pre><code>## [1] -0.5317412  0.6785329</code></pre>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb102-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervalo de credibilidad de 95% para sigma2</span></span>
<span id="cb102-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb102-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qigamma</span>(<span class="fl">0.025</span>, <span class="at">alpha =</span> (n <span class="sc">+</span> n0)<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb102-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb102-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">beta =</span> (n <span class="sc">+</span> n0) <span class="sc">*</span> sigma2_n<span class="sc">/</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 1.467991</code></pre>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb104-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qigamma</span>(<span class="fl">0.975</span>, <span class="at">alpha =</span> (n <span class="sc">+</span> n0)<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb104-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb104-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">beta =</span> (n <span class="sc">+</span> n0) <span class="sc">*</span> sigma2_n<span class="sc">/</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 4.351026</code></pre>
<p>Otra forma de estimar los parámetros <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> es utilizando métodos de simulación directa. De esta forma, como se expuso anteriormente, se generan primero los valores de <span class="math inline">\(\sigma^2\)</span> y posteriormente los valores de <span class="math inline">\(\theta\)</span>.</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-1" aria-hidden="true" tabindex="-1"></a>n.sim <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb106-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-2" aria-hidden="true" tabindex="-1"></a>sigma2.res <span class="ot">&lt;-</span> <span class="fu">rigamma</span>(n.sim, (n <span class="sc">+</span> n0)<span class="sc">/</span><span class="dv">2</span>, </span>
<span id="cb106-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-3" aria-hidden="true" tabindex="-1"></a>                        (n <span class="sc">+</span> n0) <span class="sc">*</span> sigma2_n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb106-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-4" aria-hidden="true" tabindex="-1"></a>theta.res <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb106-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n.sim){</span>
<span id="cb106-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-6" aria-hidden="true" tabindex="-1"></a>  theta.res[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu.n, <span class="fu">sqrt</span>(sigma2.res[i]<span class="sc">/</span>(n <span class="sc">+</span> c0)))</span>
<span id="cb106-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-7" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb106-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimaciones puntuales</span></span>
<span id="cb106-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb106-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(theta.res)</span></code></pre></div>
<pre><code>## [1] 0.07384158</code></pre>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(sigma2.res)</span></code></pre></div>
<pre><code>## [1] 2.532906</code></pre>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Intervalos de credibilidad del 95%</span></span>
<span id="cb110-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(theta.res, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##       2.5%      97.5% 
## -0.5472775  0.6694128</code></pre>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(sigma2.res, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span></code></pre></div>
<pre><code>##     2.5%    97.5% 
## 1.453781 4.409619</code></pre>
</div>
<div id="parámetros-no-informativos" class="section level3" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Parámetros no informativos</h3>
<p>En esta sección consideramos el tratamiento de los datos cuando no tenemos información previa disponible. Suponga que <span class="math inline">\(\mathbf{Y}=\{Y_1,\ldots,Y_n\}\)</span> corresponde a una muestra de variables aleatorias con distribución <span class="math inline">\(Normal(\theta, \sigma^2)\)</span>. Luego, la función de distribución conjunta o verosimilitud está dada por</p>
<p><span class="math display" id="eq:VeroNormal">\[\begin{equation*}
\tag{4.4}
p(\mathbf{Y} \mid \theta, \sigma^2)=\frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-\theta)^2\right\}
\end{equation*}\]</span></p>
<p>En primer lugar suponga que los parámetros tienen distribuciones previas independientes. Por ende, en esta primera etapa se realizará el análisis suponiendo que estas distribuciones son no informativas. Lo anterior implica que la distribución previa conjunta de los parámetros de interés está dada por
<span class="math display">\[\begin{equation}
p(\theta,\sigma^2)=p(\theta)p(\sigma^2)
\end{equation}\]</span></p>
<p>Como la distribución previa de <span class="math inline">\(\theta\)</span> es normal, es fácil verificar que ésta empieza a tener las características propias de una distribución no informativa cuando la varianza de la misma se vuelve muy grande, sin importar el valor de la media. Cuando esto sucede, la forma de la distribución previa de <span class="math inline">\(\theta\)</span> se torna plana y es lógico pensar que puede ser acercada mediante una distribución constante, tal que</p>
<p><span class="math display">\[\begin{equation*}
p(\theta)\propto cte
\end{equation*}\]</span></p>
<p>Por otro lado, <span class="citation"><a href="#ref-Gelman03" role="doc-biblioref">A. Gelman et al.</a> (<a href="#ref-Gelman03" role="doc-biblioref">2003</a>)</span> afirmaN que la distribución Inversa-Gamma, la cual es la distribución previa para el parámetro <span class="math inline">\(\sigma^2\)</span>, se vuelve no informativa cuando los hiper-parámetros toman valores muy cercanos a cero. De esta forma haciendo tender <span class="math inline">\(\alpha \longrightarrow 0\)</span> y <span class="math inline">\(\beta \longrightarrow 0\)</span>, entonces la distribución previa de <span class="math inline">\(\sigma^2\)</span> se convierte en</p>
<p><span class="math display">\[\begin{equation*}
p(\sigma^2)\propto \sigma^{-2}
\end{equation*}\]</span></p>
<p>la cual coincide con la distribución previa no informativa de Jeffreys discutida en las secciones anteriores. Por lo anterior, la distribución previa no informativa conjunta está dada por</p>
<p><span class="math display">\[\begin{equation}
p(\theta,\sigma^2)\propto \sigma^{-2}
\end{equation}\]</span></p>
<p>Bajo este marco de referencia se tiene el siguiente resultado sobre la distribución posterior de <span class="math inline">\(\theta\)</span></p>

<div class="proposition">
<p><span id="prp:PosThetaNoInformativa" class="proposition"><strong>Resultado 4.6  </strong></span>La distribución posterior del parámetro <span class="math inline">\(\theta\)</span> sigue una distribución <span class="math inline">\(t\)</span> no estandarizada con <span class="math inline">\(n-1\)</span> grados de libertad, parámetro de localización <span class="math inline">\(\bar{Y}\)</span> y parámetro de escala <span class="math inline">\(\frac{S^2}{n}\)</span>; esto es,</p>
<p><span class="math display">\[\begin{equation*}
\theta \mid \mathbf{Y}\sim t_{n-1}\left(\bar{y},\frac{S^2}{n}\right).
\end{equation*}\]</span></p>
<p>Donde <span class="math inline">\((n-1)S^2=\sum_{i=1}^n(Y_i-\bar{Y})^2\)</span>. Esta distribución también puede expresarse como
<span class="math display">\[\begin{equation*}
\frac{\theta-\bar{y}}{S/\sqrt{n}} \mid \mathbf{Y} \sim t_{n-1}
\end{equation*}\]</span></p>
donde <span class="math inline">\(t_{n-1}\)</span> denota la distribución <span class="math inline">\(t\)</span> estandarizada con <span class="math inline">\(n-1\)</span> grados de libertad.
</div>
<p><br></p>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> En primer lugar nótese que la distribución posterior conjunta de los parámetros de interés es
<span class="math display" id="eq:PropThetaSigma2">\[\begin{align}
\tag{4.5}
p(\theta,\sigma^2 \mid \mathbf{Y})&amp; \propto p(\theta,\sigma^2)p(\mathbf{Y} \mid \theta,\sigma^2) \notag \\
&amp; \propto \frac{1}{\sigma^2}\frac{1}{(2\pi\sigma^2)^{n/2}}\exp\left\{-\frac{1}{2\sigma^2}\sum_{i=1}^n(y_i-\theta)^2\right\} \notag\\
&amp; \propto \left(\frac{1}{\sigma^2}\right)^{n/2+1}
\exp\left\{-\frac{1}{2\sigma^2}\left[\sum_{i=1}^n(y_i-\bar{y})^2+n(\bar{y}-\theta)^2\right]\right\} \notag \\
&amp;= \left(\frac{1}{\sigma^2}\right)^{n/2+1}
\exp\left\{-\frac{1}{2\sigma^2}\left[(n-1)S^2+n(\bar{y}-\theta)^2\right]\right\}
\end{align}\]</span></p>
<p>Para hallar la distribución marginal posterior de <span class="math inline">\(\theta\)</span> es necesario integrar la anterior expresión con respecto a <span class="math inline">\(\sigma^2\)</span>. Con esto, se tiene que</p>
<p><span class="math display">\[\begin{align*}
p(\theta \mid \mathbf{Y})&amp;= \int_0^{\infty} p(\theta,\sigma^2 \mid \mathbf{Y}) \ d\sigma^2 \\
&amp;\propto \int_0^{\infty} \left(\frac{1}{\sigma^2}\right)^{n/2+1}
\exp\left\{-\frac{1}{2\sigma^2}\left[(n-1)S^2+n(\bar{y}-\theta)^2\right]\right\} \ d\sigma^2
\end{align*}\]</span></p>
<p>Haciendo un cambio de variable tal que
<span class="math display">\[\begin{equation*}
z=\frac{A}{2\sigma^2}, \ \ \ \ \ \ \ \ \ \ \ \text{donde} \ \ \ A=(n-1)S^2+n(\bar{y}-\theta)^2
\end{equation*}\]</span></p>
<p>Por tanto
<span class="math display">\[\begin{equation*}
d\sigma^2=-\frac{A}{2z^2} \ dz
\end{equation*}\]</span></p>
<p>Entonces, volviendo a la integral en cuestión, se tiene que
<span class="math display">\[\begin{align*}
p(\theta \mid \mathbf{Y})&amp; \propto
\left(\frac{1}{A}\right)^{n/2+1}\int_{\infty}^{0} \frac{-A}{2z^2} (2z)^{n/2+1}e^{-z} \ dz \\
&amp;\propto A^{-n/2}\underbrace{\int_{0}^{\infty} z^{n/2-1}e^{-z}\ dz}_{Gamma(n/2)}\\
&amp;\propto A^{-n/2}\\
&amp;= [(n-1)S^2+n(\bar{y}-\theta)^2]^{-n/2}\\
&amp;\propto \left[1+\frac{n(\bar{y}-\theta)^2}{(n-1)S^2}\right]^{-n/2}
=\left[1+\frac{1}{n-1}\left(\frac{\bar{y}-\theta}{S/\sqrt{n}}\right)^2\right]^{-\frac{(n-1)+1}{2}}
\end{align*}\]</span></p>
la cual corresponde a la función de densidad de distribución de una variable aleatoria con distribución <span class="math inline">\(t_{n-1}(\bar{y},S^2/n)\)</span>.
</div>
<p><br></p>

<div class="proposition">
<span id="prp:PosSigma2NoInformativa" class="proposition"><strong>Resultado 4.7  </strong></span>La distribución posterior del parámetro <span class="math inline">\(\sigma^2\)</span> sigue una distribución
<span class="math display">\[\begin{equation*}
\sigma^2 \mid \mathbf{Y} \sim Inversa-Gamma((n-1)/2,(n-1)S^2/2).
\end{equation*}\]</span>
</div>
<p><br></p>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Utilizando el mismo argumento del anterior resultado, se tiene que
<span class="math display">\[\begin{align*}
p(\sigma^2 \mid \mathbf{Y})&amp;= \int_{-\infty}^{\infty} p(\theta,\sigma^2 \mid \mathbf{Y}) \ d\theta \\
&amp; \propto \int_{-\infty}^{\infty} \left(\frac{1}{\sigma^2}\right)^{n/2+1}
\exp\left\{-\frac{1}{2\sigma^2}\left[(n-1)S^2+n(\bar{y}-\theta)^2\right]\right\} \ d\theta \\
&amp; = \left(\frac{1}{\sigma^2}\right)^{n/2+1} \sqrt{2\pi\sigma^2/n}\exp\left\{-\frac{1}{2\sigma^2}(n-1)S^2\right\}\underbrace{\int_{-\infty}^{\infty} \frac{1}{\sqrt{2\pi\sigma^2/n}} \exp\left\{-\frac{n}{2\sigma^2}(\bar{y}-\theta)^2\right\} \ d\theta}_{\text{vale $1$}} \\
&amp; \propto (\sigma^2)^{-n/2-1/2}\exp\left\{-\frac{1}{2\sigma^2}(n-1)S^2\right\}\\
&amp;= (\sigma^2)^{-\frac{n-1}{2}-1}\exp\left\{-\frac{1}{2\sigma^2}(n-1)S^2\right\}
\end{align*}\]</span></p>
La cual corresponde a la función de densidad de la distribución <span class="math inline">\(Inversa-Gamma((n-1)/2,(n-1)S^2/2)\)</span>.
</div>
<p><br></p>
<p>De los resultados  y , podemos ver que cuando no se dispone de información previa, la estimación bayesiana de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> están dadas por</p>
<p><span class="math display">\[\begin{align*}
\hat{\theta}_B&amp;=E(\theta\mid\mathbf{Y})=\bar{Y}\\
\hat{\sigma}^2_B&amp;=E(\sigma^2\mid\mathbf{Y})=\dfrac{(n-1)S^2/2}{(n-1)/2-1}=\dfrac{n-1}{n-3}S^2\approx S^2
\end{align*}\]</span></p>
<p>Por consiguiente, podemos concluir que la estimación bayesiana de <span class="math inline">\(\theta\)</span> cuando no hay información previa es idéntica a la estimación clásica de <span class="math inline">\(\theta\)</span>, mientas que la de <span class="math inline">\(\sigma^2\)</span> es muy similar a la estimación clásica. En cuanto a la estimación por intervalo de credibilidad, podemos ver que un intervalo de crediblidad de <span class="math inline">\((1-\alpha)\times 100\%\)</span> está dado por los percentiles <span class="math inline">\(\alpha/2\)</span> y <span class="math inline">\(1-\alpha/2\)</span> de la distribución <span class="math inline">\(t_{n-1}\left(\bar{Y},\dfrac{S^2}{n}\right)\)</span>. Se puede ver que estos corresponden a <span class="math inline">\(\bar{Y}+t_{n-1,\alpha/2}\dfrac{S}{\sqrt{n}}\)</span> y <span class="math inline">\(\bar{Y}+t_{n-1,1-\alpha/2}\dfrac{S}{\sqrt{n}}\)</span>. En conclusión, un intervalo de credibildad para <span class="math inline">\(\theta\)</span> está dado por <span class="math inline">\(\bar{Y}\pm t_{n-1,1-\alpha/2}\dfrac{S}{\sqrt{n}}\)</span>, el cual es idéntico al intervalo de confianza para <span class="math inline">\(\theta\)</span> en la estadística clásica.</p>
<p>En cuanto al intervalo de crediblidad para <span class="math inline">\(\sigma^2\)</span>, este está dado por los percentiles <span class="math inline">\(\alpha/2\)</span> y <span class="math inline">\(1-\alpha/2\)</span> de la distribución <span class="math inline">\(Inversa-Gamma((n-1)/2,\ (n-1)S^2/2)\)</span>. En la estadística clásica, el intervalo de confianza para <span class="math inline">\(\sigma^2\)</span> está dada por <span class="math display">\[\begin{equation*}
IC(\sigma^2)=\left(\dfrac{(n-1)S^2}{\chi^2_{n-1,1-\alpha/2}},\ \dfrac{(n-1)S^2}{\chi^2_{n-1,\alpha/2}}\right)
\end{equation*}\]</span></p>
<p>Aunque la forma de estos dos intervalos son muy diferentes, resultan ser idénticos. A continuación mostramos el porqué. Suponga que <span class="math inline">\(a\)</span> es el percentil <span class="math inline">\(\alpha/2\)</span> de la distribución <span class="math inline">\(Inversa-Gamma((n-1)/2,\ (n-1)S^2/2)\)</span>, esto es, si <span class="math inline">\(X\sim Inversa-Gamma((n-1)/2,\ (n-1)S^2/2)\)</span>, entonces <span class="math inline">\(Pr(X&lt;a)=\alpha/2\)</span>. Ahora por propiedades de la distribución <span class="math inline">\(Inversa-Gamma\)</span>, se tiene que <span class="math inline">\(\dfrac{X}{(n-1)S^2}\sim Inversa-Gamma(\frac{n-1}{2},\ \frac{1}{2})\)</span>. Por la relación entre la distribución <span class="math inline">\(Gamma\)</span> y la distribución <span class="math inline">\(Inversa-Gamma\)</span>, tenemos que <span class="math inline">\(\dfrac{(n-1)S^2}{X}\sim Gamma(\frac{n-1}{2},\ 2)\)</span>, es decir, <span class="math inline">\(\dfrac{(n-1)S^2}{X}\sim\chi^2_{n-1}\)</span>, de donde tenemos que
<span class="math display">\[\begin{align*}
\frac{\alpha}{2}&amp;=Pr(X&lt;a)\\
&amp;=Pr\left(\dfrac{(n-1)S^2}{X}&gt;\dfrac{(n-1)S^2}{a}\right)
\end{align*}\]</span></p>
<p>Esto es, <span class="math inline">\(\dfrac{(n-1)S^2}{a}\)</span> es el percentil <span class="math inline">\(1-\alpha/2\)</span> de la distribución <span class="math inline">\(\chi^2_{n-1}\)</span>, esto es, <span class="math inline">\(\dfrac{(n-1)S^2}{a}=\chi^2_{n-1,1-\alpha/2}\)</span>, de donde <span class="math inline">\(a=\dfrac{(n-1)S^2}{\chi^2_{n-1,1-\alpha/2}}\)</span>, así concluimos que el límite inferior del intervalo de credibilidad coincide con el límite inferior del intervalo de confianza. Análogamente se puede ver que también los límites superiores coinciden, y así vemos que el intervalo para <span class="math inline">\(\sigma^2\)</span> coincide en la estadística clásica y la estadística bayesiana sin información previa.</p>
<div id="enfoque-alterno-para-estimar-theta-y-sigma2" class="section level4 unnumbered">
<h4>Enfoque alterno para estimar <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span></h4>
<p>Existe otra forma de obtener las estimaciones para el parámetro <span class="math inline">\(\theta\)</span>. Recordando la expresión , podemos afirmar que
<span class="math display">\[\begin{equation*}
\theta \mid \sigma^2, \mathbf{Y} \sim Normal(\bar{y},\sigma^2/n)
\end{equation*}\]</span></p>
<p>puesto que
<span class="math display">\[\begin{align*}
p(\theta \mid \sigma^2,\mathbf{Y})&amp;\propto p(\theta, \sigma^2 \mid\mathbf{Y})\\
&amp;\propto\exp\left\{-\frac{1}{2\sigma^2}\left[(n-1)S^2+n(\bar{y}-\theta)^2\right]\right\}\\
&amp;=\exp\left\{-\frac{n}{2\sigma^2}(\bar{y}-\theta)^2\right\}
\end{align*}\]</span></p>
<p>La cual corresponde a la función de densidad de la distribución <span class="math inline">\(Normal(\bar{y},\sigma^2/n)\)</span>. De esta forma, usando las distribución <span class="math inline">\(p(\sigma^2\mid\mathbf{Y})\)</span> y <span class="math inline">\(p(\theta\mid\sigma^2,\mathbf{Y})\)</span>, podemos implementar el siguiente procedimiento para obtener valores simulados de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span>. Si el número de iteraciones se fija como <span class="math inline">\(G\)</span>, entonces se procede a:</p>
<ol style="list-style-type: decimal">
<li>Simular <span class="math inline">\(G\)</span> valores de la distribución de <span class="math inline">\(\sigma^2|\mathbf{Y}\)</span> - es decir, de la distribución <span class="math inline">\(Inversa-Gamma((n-1)/2,(n-1)S^2/2)\)</span>. Estos valores se denotan por <span class="math inline">\(\sigma^2_{(1)},\sigma^2_{(2)},\cdots,\sigma^2_{(G)}\)</span>.</li>
<li>Para cada valor de <span class="math inline">\(\sigma^2_{(g)}\)</span>, con <span class="math inline">\(g=1,\cdots,G\)</span>, simular un valor de la distribución de <span class="math inline">\(\theta|\sigma^2,\mathbf{Y}\)</span> - es decir, de la distribución <span class="math inline">\(N(\bar{y},\sigma^2/n)\)</span>, donde <span class="math inline">\(\sigma^2\)</span> se reemplaza por <span class="math inline">\(\sigma^2_{(g)}\)</span>. De esta forma, se obtiene los valores <span class="math inline">\(\theta_{(1)},\theta_{(2)},\cdots,\theta_{(G)}\)</span>.</li>
</ol>
<p>Las estimaciones de <span class="math inline">\(\theta\)</span> y <span class="math inline">\(\sigma^2\)</span> se pueden obtener de los valores obtenidos <span class="math inline">\(\theta_{(1)},\theta_{(2)},\cdots,\theta_{(G)}\)</span> y <span class="math inline">\(\sigma^2_{(1)},\sigma^2_{(2)},\cdots,\sigma^2_{(G)}\)</span>.</p>
</div>
</div>
<div id="distribución-predictiva" class="section level3" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Distribución predictiva</h3>
<p>La distribución predictiva para una nueva observación <span class="math inline">\(\tilde{Y}\)</span> está dada por
<span class="math display">\[\begin{align*}
p(\tilde{y}\mid\mathbf{Y})
&amp;=\int\int p(\tilde{y}\mid\theta,\sigma^2) p(\theta,\sigma^2\mid\mathbf{Y})\ d\theta\ d\sigma^2\\
&amp;=\int\int p(\tilde{y}\mid \theta,\sigma^2)p(\theta\mid\sigma^2,\mathbf{Y})p(\sigma^2\mid\mathbf{Y})\ d\theta\ d\sigma^2\\
&amp;=\int\left(\int p(\tilde{y}\mid \theta,\sigma^2)p(\theta\mid\sigma^2,\mathbf{Y})\ d\theta\right)p(\sigma^2\mid\mathbf{Y})\ d\sigma^2
\end{align*}\]</span></p>
<p>En la integral dentro del paréntesis, el parámetro <span class="math inline">\(\sigma^2\)</span> permanece fijo; por lo cual, dicha integral corresponde a la distribución <span class="math inline">\(N\left(\bar{y},\left(1+\dfrac{1}{n}\right)\sigma^2\right)\)</span>. De esta forma, al combinarla con la distribución posterior de <span class="math inline">\(\sigma^2\)</span>, tenemos que
<span class="math display">\[\begin{align*}
&amp;\ \ \ \ p(\tilde{y}\mid\mathbf{Y})\\
&amp;=\int_0^\infty \dfrac{1}{\sqrt{2\pi(1+\frac{1}{n})\sigma^2}}\exp\left\{-\dfrac{1}{2\sigma^2(1+\frac{1}{n})}(\tilde{y}-\bar{y})^2\right\}\dfrac{\left(\frac{(n-1)S^2}{2}\right)^{(n-1)/2}}{\Gamma\left(\frac{n-1}{2}\right)}(\sigma^2)^{-\frac{n-1}{2}-1}\exp\left\{-\dfrac{(n-1)S^2}{2\sigma^2}\right\}\ d\sigma^2
\end{align*}\]</span></p>
<p>Después de realizar los pasos algebraicos necesarios, se encuentra que
<span class="math display">\[\begin{equation}
p(\tilde{y}\mid\mathbf{Y})=\dfrac{\Gamma(n/2)}{\Gamma((n-1)/2)}\dfrac{1}{\sqrt{\pi(n-1)}}\left(\left(1+\frac{1}{n}\right)S^2\right)^{-1/2}\left(1+\dfrac{1}{n-1}\dfrac{(\tilde{y}-\bar{y})^2}{\left(1+\frac{1}{n}\right)S^2}\right)^{-n/2}
\end{equation}\]</span></p>
<p>La cual corresponde a la distribución <span class="math inline">\(t\)</span> no estandarizada con <span class="math inline">\(n-1\)</span> grados de libertad, parámetro de localización <span class="math inline">\(\bar{y}\)</span> y parámetro de escala <span class="math inline">\((1+\frac{1}{n})S^2\)</span>. De esta forma, podemos ver que los dos primeros momentos de esta distribución están dados por
<span class="math display">\[\begin{align*}
E(\tilde{Y}\mid\mathbf{Y})&amp;=\bar{y}\\
Var(\tilde{Y}\mid\mathbf{Y})&amp;=\dfrac{n-1}{n-3}\left(1+\frac{1}{n}\right)S^2=\dfrac{(n-1)(n+1)}{n(n-3)}S^2
\end{align*}\]</span></p>
<p>Otra manera equivalente de conocer el comportamiento probabilístico de <span class="math inline">\(\tilde{y}\)</span> es por medio de la simulación. Se debe simular en primer lugar valores de <span class="math inline">\(\theta\)</span> y de <span class="math inline">\(\sigma^2\)</span> de la distribución posterior <span class="math inline">\(p(\theta,\ \sigma^2\mid\mathbf{Y})\)</span> usando el muestreo de Gibbs y posteriormente simulando valores de <span class="math inline">\(\tilde{y}\)</span> de la distribución <span class="math inline">\(p(\tilde{y}\mid\theta,\ \sigma^2)\)</span>. En la figura  se muestran el histograma de 10 mil valores de <span class="math inline">\(\tilde{Y}\)</span> simulados de esta forma, donde los datos corresponden a 20 datos simulados de la distribución <span class="math inline">\(N(12, 3^2)\)</span>. En la misma gráfica se observa también la función de densidad de la distribución <span class="math inline">\(t\)</span>, podemos ver que los valores simulados de <span class="math inline">\(\tilde{Y}\)</span> efectivamente coinciden con la distribución predictiva de <span class="math inline">\(\tilde{Y}\)</span>. Por lo anterior, se puede calcular un predictor de <span class="math inline">\(\tilde{Y}\)</span> como el promedio de los 10 mil valores simulados, y calcular el intervalo de predicción usando los percentiles de estos 10 mil valores.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;MCMCpack&quot;</span>)</span>
<span id="cb114-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-2" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb114-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-3" aria-hidden="true" tabindex="-1"></a>y.tilde <span class="ot">&lt;-</span> theta.pos <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb114-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb114-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">12</span>, <span class="dv">3</span>)</span>
<span id="cb114-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-6" aria-hidden="true" tabindex="-1"></a>y.bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb114-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-8" aria-hidden="true" tabindex="-1"></a>S2 <span class="ot">&lt;-</span> <span class="fu">var</span>(y)</span>
<span id="cb114-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-9" aria-hidden="true" tabindex="-1"></a>a.n <span class="ot">&lt;-</span> (n <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb114-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-10" aria-hidden="true" tabindex="-1"></a>b.n <span class="ot">&lt;-</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> S2<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb114-11"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-11" aria-hidden="true" tabindex="-1"></a>sigma2.pos <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(nsim, a.n, b.n)</span>
<span id="cb114-12"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-13"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>){</span>
<span id="cb114-14"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-14" aria-hidden="true" tabindex="-1"></a>    theta.pos[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, y.bar, <span class="fu">sqrt</span>(sigma2.pos[i]<span class="sc">/</span>n))</span>
<span id="cb114-15"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-15" aria-hidden="true" tabindex="-1"></a>    y.tilde[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, theta.pos[i], <span class="fu">sqrt</span>(sigma2.pos[i]))</span>
<span id="cb114-16"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb114-17"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-18"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-18" aria-hidden="true" tabindex="-1"></a>tn <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb114-19"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-19" aria-hidden="true" tabindex="-1"></a>    v2 <span class="ot">&lt;-</span> (n <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">*</span> S2<span class="sc">/</span>n</span>
<span id="cb114-20"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-20" aria-hidden="true" tabindex="-1"></a>    tnpred <span class="ot">&lt;-</span> (pi <span class="sc">*</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> v2)<span class="sc">^</span>(<span class="sc">-</span> <span class="fl">0.5</span>) <span class="sc">*</span> <span class="fu">gamma</span>(n<span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> </span>
<span id="cb114-21"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-21" aria-hidden="true" tabindex="-1"></a>      (<span class="dv">1</span> <span class="sc">+</span> (x <span class="sc">-</span> y.bar)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>((n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> v2))<span class="sc">^</span>(<span class="sc">-</span> n<span class="sc">/</span><span class="dv">2</span>)<span class="sc">/</span><span class="fu">gamma</span>((n <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb114-22"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(tnpred)</span>
<span id="cb114-23"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb114-24"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-25"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-25" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb114-26"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(y.tilde),</span>
<span id="cb114-27"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-27" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">aes</span>(<span class="at">x =</span> y.tilde, <span class="at">y=</span>..density..),</span>
<span id="cb114-28"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-28" aria-hidden="true" tabindex="-1"></a>                 <span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>,</span>
<span id="cb114-29"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-29" aria-hidden="true" tabindex="-1"></a>                 <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb114-30"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb114-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_density</span>(<span class="at">fun =</span> tn, <span class="fu">aes</span>(<span class="at">x =</span> y.tilde), <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="dv">2</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:PredictivaYprioriNoninformativa"></span>
<img src="4Multiparametricos_files/figure-html/PredictivaYprioriNoninformativa-1.svg" alt="10 mil valores simulados de $\tilde{Y}$ y la función de densidad de la distribución predictiva de $\tilde{Y}$ con parámetros no informativos." width="576" />
<p class="caption">
Figura 4.3: 10 mil valores simulados de <span class="math inline">\(\tilde{Y}\)</span> y la función de densidad de la distribución predictiva de <span class="math inline">\(\tilde{Y}\)</span> con parámetros no informativos.
</p>
</div>
<p>Por otro lado, si consideramos parámetros informativos podríamos usar este mismo método de simulación que es realmente efectivo y que se convertirá de ahora en adelante en nuestro medio para realizar las importantes validaciones predictivas en los diferentes modelos bayesianos que se trabajarán en este libro. Por ejemplo, para el mismo conjunto de datos anterior supongamos que en un experimento anterior se recolectaron 20 datos con media 10 y varianza 5. En la figura <a href="modelo-normal-con-media-y-varianza-desconocida.html#fig:predictivaTsimu">4.4</a> se muestran el histograma de 10 mil valores simulados para una nueva observación. Nótese que convenientemente la forma de la distribución predictiva teórica coincide plenamente con ls distribución predictiva simulada. Esta agradable propiedad nos acompañará en el resto de los capítulos subsecuentes.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MCMCpack)</span>
<span id="cb115-2"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-2" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb115-3"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-3" aria-hidden="true" tabindex="-1"></a>y.tilde <span class="ot">&lt;-</span> theta.pos <span class="ot">&lt;-</span> sigma2.pos <span class="ot">&lt;-</span> <span class="fu">c</span>()</span>
<span id="cb115-4"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb115-5"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="dv">12</span>, <span class="dv">3</span>)</span>
<span id="cb115-6"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-6" aria-hidden="true" tabindex="-1"></a>y.bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb115-7"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-7" aria-hidden="true" tabindex="-1"></a>S2 <span class="ot">&lt;-</span> <span class="fu">var</span>(y)</span>
<span id="cb115-8"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-9"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-9" aria-hidden="true" tabindex="-1"></a><span class="co">#parametros previos de theta</span></span>
<span id="cb115-10"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-10" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb115-11"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-11" aria-hidden="true" tabindex="-1"></a>tau2 <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb115-12"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-12" aria-hidden="true" tabindex="-1"></a><span class="co">#parametros previos de sigma2</span></span>
<span id="cb115-13"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-13" aria-hidden="true" tabindex="-1"></a>n_0 <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb115-14"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-14" aria-hidden="true" tabindex="-1"></a>sigma2_0 <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb115-15"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-16"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Valor inicial de theta</span></span>
<span id="cb115-17"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-17" aria-hidden="true" tabindex="-1"></a>theta.pos[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb115-18"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-19"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-19" aria-hidden="true" tabindex="-1"></a><span class="co">#parametros posteriores de sigma2   </span></span>
<span id="cb115-20"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-20" aria-hidden="true" tabindex="-1"></a>a.n <span class="ot">&lt;-</span> (n_0 <span class="sc">+</span> n)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb115-21"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-21" aria-hidden="true" tabindex="-1"></a>b.n <span class="ot">&lt;-</span> (n_0 <span class="sc">*</span> sigma2_0 <span class="sc">+</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> S2 <span class="sc">+</span> </span>
<span id="cb115-22"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-22" aria-hidden="true" tabindex="-1"></a>          n <span class="sc">*</span> (<span class="fu">mean</span>(y) <span class="sc">-</span> theta.pos[<span class="dv">1</span>]))<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb115-23"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-23" aria-hidden="true" tabindex="-1"></a>sigma2.pos[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(<span class="dv">1</span>, a.n, b.n)</span>
<span id="cb115-24"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-25"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Valor inicial de y.tilde</span></span>
<span id="cb115-26"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-26" aria-hidden="true" tabindex="-1"></a>y.tilde[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, theta.pos[<span class="dv">1</span>], <span class="fu">sqrt</span>(sigma2.pos[<span class="dv">1</span>]))</span>
<span id="cb115-27"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-27" aria-hidden="true" tabindex="-1"></a><span class="do">#####################</span></span>
<span id="cb115-28"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Muestreo de Gibbs #</span></span>
<span id="cb115-29"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-29" aria-hidden="true" tabindex="-1"></a><span class="do">#####################</span></span>
<span id="cb115-30"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-31"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-31" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>nsim){</span>
<span id="cb115-32"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-32" aria-hidden="true" tabindex="-1"></a>  <span class="co">#parametros posteriores de theta  </span></span>
<span id="cb115-33"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-33" aria-hidden="true" tabindex="-1"></a>  tau2.n <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> ((n<span class="sc">/</span>sigma2.pos[i <span class="sc">-</span> <span class="dv">1</span>]) <span class="sc">+</span> (<span class="dv">1</span><span class="sc">/</span>tau2))</span>
<span id="cb115-34"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-34" aria-hidden="true" tabindex="-1"></a>  mu.n <span class="ot">&lt;-</span> tau2.n <span class="sc">*</span> (<span class="fu">mean</span>(y) <span class="sc">*</span> (n<span class="sc">/</span>sigma2.pos[i <span class="sc">-</span> <span class="dv">1</span>]) <span class="sc">+</span> mu<span class="sc">/</span>tau2)</span>
<span id="cb115-35"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">#simulacion de la distribucion posterior condicional de theta</span></span>
<span id="cb115-36"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-36" aria-hidden="true" tabindex="-1"></a>  theta.pos[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, <span class="at">mean =</span> mu.n, <span class="at">sd =</span> <span class="fu">sqrt</span>(tau2.n))</span>
<span id="cb115-37"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-37" aria-hidden="true" tabindex="-1"></a>  <span class="co">#parametros posteriores de sigma2 </span></span>
<span id="cb115-38"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-38" aria-hidden="true" tabindex="-1"></a>  b.n <span class="ot">&lt;-</span> (n_0 <span class="sc">*</span> sigma2_0 <span class="sc">+</span> (n <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> S2 <span class="sc">+</span> </span>
<span id="cb115-39"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-39" aria-hidden="true" tabindex="-1"></a>          n <span class="sc">*</span> (<span class="fu">mean</span>(y) <span class="sc">-</span> theta.pos[i <span class="sc">-</span> <span class="dv">1</span>]))<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb115-40"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-40" aria-hidden="true" tabindex="-1"></a>  <span class="co">#simulacion de la distribucion posterior condicional de theta</span></span>
<span id="cb115-41"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-41" aria-hidden="true" tabindex="-1"></a>  sigma2.pos[i] <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(<span class="dv">1</span>, a.n, b.n)</span>
<span id="cb115-42"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-42" aria-hidden="true" tabindex="-1"></a>  <span class="co">#simulacion de la distribucion predictiva</span></span>
<span id="cb115-43"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-43" aria-hidden="true" tabindex="-1"></a>  y.tilde[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, theta.pos[i], <span class="fu">sqrt</span>(sigma2.pos[i]))</span>
<span id="cb115-44"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-44" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb115-45"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-46"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-46" aria-hidden="true" tabindex="-1"></a>tn <span class="ot">&lt;-</span> <span class="cf">function</span>(x){</span>
<span id="cb115-47"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-47" aria-hidden="true" tabindex="-1"></a>    v0 <span class="ot">&lt;-</span> n_0 <span class="sc">*</span> sigma2_0 <span class="sc">+</span> n <span class="sc">*</span> sigma2_c</span>
<span id="cb115-48"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-48" aria-hidden="true" tabindex="-1"></a>    tnpred <span class="ot">&lt;-</span> (pi <span class="sc">*</span> v0)<span class="sc">^</span>(<span class="sc">-</span> <span class="fl">0.5</span>) <span class="sc">*</span> <span class="fu">gamma</span>((n_0 <span class="sc">+</span> n <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> </span>
<span id="cb115-49"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-49" aria-hidden="true" tabindex="-1"></a>      (<span class="dv">1</span> <span class="sc">+</span> (x <span class="sc">-</span> theta)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>v0)<span class="sc">^</span>(<span class="sc">-</span> (n_0 <span class="sc">+</span> n <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">/</span><span class="dv">2</span>)<span class="sc">/</span><span class="fu">gamma</span>((n_0 <span class="sc">+</span> n)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb115-50"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-50" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(tnpred)</span>
<span id="cb115-51"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-51" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb115-52"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-53"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-53" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb115-54"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">data =</span> <span class="fu">data.frame</span>(y.tilde),</span>
<span id="cb115-55"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-55" aria-hidden="true" tabindex="-1"></a>                 <span class="fu">aes</span>(<span class="at">x =</span> y.tilde, <span class="at">y=</span>..density..),</span>
<span id="cb115-56"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-56" aria-hidden="true" tabindex="-1"></a>                 <span class="at">fill =</span> <span class="st">&quot;gray&quot;</span>,</span>
<span id="cb115-57"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-57" aria-hidden="true" tabindex="-1"></a>                 <span class="at">color =</span> <span class="st">&quot;black&quot;</span>) <span class="sc">+</span></span>
<span id="cb115-58"><a href="modelo-normal-con-media-y-varianza-desconocida.html#cb115-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_density</span>(<span class="at">fun =</span> tn, <span class="fu">aes</span>(<span class="at">x =</span> y.tilde), <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">col =</span> <span class="dv">2</span>) </span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:predictivaTsimu"></span>
<img src="4Multiparametricos_files/figure-html/predictivaTsimu-1.svg" alt="10 mil valores simulados de $\tilde{Y}$ y la función de densidad de la distribución predictiva de $\tilde{Y}$ con parámetros informativos." width="576" />
<p class="caption">
Figura 4.4: 10 mil valores simulados de <span class="math inline">\(\tilde{Y}\)</span> y la función de densidad de la distribución predictiva de <span class="math inline">\(\tilde{Y}\)</span> con parámetros informativos.
</p>
</div>

</div>
</div>
<!-- </div> -->



<h3>Referencias</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Efronims" class="csl-entry">
Efron, B. 2010. <em><span>Large-Scale Inference. Empirical Bayes Methods for Estimation, Testing, and Prediction</span></em>. Cambridge University Press.
</div>
<div id="ref-Gelman03" class="csl-entry">
———. 2003. <em>Bayesian Data Analysis</em>. 2.ª ed. Chapman; Hall/CRC.
</div>
<div id="ref-MCMCpack" class="csl-entry">
Martin, Andrew D., Kevin M. Quinn, y Jong Hee Park. 2011. <span>«<span>MCMCpack</span>: Markov Chain Monte Carlo in <span>R</span>»</span>. <em>Journal of Statistical Software</em> 42 (9): 22. <a href="http://www.jstatsoft.org/v42/i09/">http://www.jstatsoft.org/v42/i09/</a>.
</div>
<div id="ref-Migon" class="csl-entry">
Migon, H. S., y D. Gamerman. 1999. <em>Statistical Inference: An Integrated Approach</em>. Arnold.
</div>
<div id="ref-Zhang" class="csl-entry">
Zhang, H., y H. A. Gutiérrez. 2010. <em>Teoría estadística. Aplicación y métodos.</em> Universidad Santo Tomás.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="9">
<li id="fn9"><p>La forma como la distribución previa de <span class="math inline">\(\theta\)</span> dependa de <span class="math inline">\(\sigma^2\)</span> es coherente con la información de Fisher sobre <span class="math inline">\(\theta\)</span> dada por <span class="math inline">\(\sigma^{-2}\)</span>.<a href="modelo-normal-con-media-y-varianza-desconocida.html#fnref9" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modelos-multiparamétricos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="elementos-de-probabilidad.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/psirusteam/bookdownBayesiano/4Multiparametricos.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ModelosBayesianos.pdf", "ModelosBayesianos.epub", "ModelosBayesianos.mobi"],
"toc": {
"collapse": "section"
},
"tconfig": null
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
