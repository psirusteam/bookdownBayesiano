<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1.1 Teoría de la decisión | Modelos Bayesianos con R y STAN</title>
  <meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="1.1 Teoría de la decisión | Modelos Bayesianos con R y STAN" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="github-repo" content="psirusteam/bookdownBayesiano" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1.1 Teoría de la decisión | Modelos Bayesianos con R y STAN" />
  
  <meta name="twitter:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />


<meta name="date" content="2021-05-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tópicos-básicos.html"/>
<link rel="next" href="algunos-resultados-de-probabilidad.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Bayesianos con R y STAN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="" data-path="antes-de-comenzar.html"><a href="antes-de-comenzar.html"><i class="fa fa-check"></i>Antes de comenzar</a>
<ul>
<li class="chapter" data-level="" data-path="cuestionamientos-sobre-el-enfoque-bayesiano.html"><a href="cuestionamientos-sobre-el-enfoque-bayesiano.html"><i class="fa fa-check"></i>Cuestionamientos sobre el enfoque bayesiano</a></li>
<li class="chapter" data-level="" data-path="acerca-de-la-notación.html"><a href="acerca-de-la-notación.html"><i class="fa fa-check"></i>Acerca de la notación</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html"><i class="fa fa-check"></i><b>1</b> Tópicos básicos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="teoría-de-la-decisión.html"><a href="teoría-de-la-decisión.html"><i class="fa fa-check"></i><b>1.1</b> Teoría de la decisión</a></li>
<li class="chapter" data-level="1.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html"><i class="fa fa-check"></i><b>1.2</b> Algunos resultados de probabilidad</a></li>
<li class="chapter" data-level="1.3" data-path="teorema-de-bayes.html"><a href="teorema-de-bayes.html"><i class="fa fa-check"></i><b>1.3</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html"><i class="fa fa-check"></i><b>2</b> Inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="2.1" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html"><i class="fa fa-check"></i><b>2.1</b> La distribución previa</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>2.1.1</b> Distribuciones conjugadas</a></li>
<li class="chapter" data-level="2.1.2" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#familia-exponencial"><i class="fa fa-check"></i><b>2.1.2</b> Familia exponencial</a></li>
<li class="chapter" data-level="2.1.3" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#distribuciones-previas-no-informativas"><i class="fa fa-check"></i><b>2.1.3</b> Distribuciones previas no informativas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>2.2</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#factor-de-bayes"><i class="fa fa-check"></i><b>2.2.1</b> Factor de Bayes</a></li>
<li class="chapter" data-level="2.2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#valor-p-bayesiano"><i class="fa fa-check"></i><b>2.2.2</b> Valor-<span class="math inline">\(p\)</span> Bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="criterios-de-información.html"><a href="criterios-de-información.html"><i class="fa fa-check"></i><b>2.3</b> Criterios de información</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="criterios-de-información.html"><a href="criterios-de-información.html#criterio-dic"><i class="fa fa-check"></i><b>2.3.1</b> Criterio DIC</a></li>
<li class="chapter" data-level="2.3.2" data-path="criterios-de-información.html"><a href="criterios-de-información.html#criterios-aic-y-bic"><i class="fa fa-check"></i><b>2.3.2</b> Criterios AIC y BIC</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="A" data-path="algunas-distribuciones-de-probabilidad.html"><a href="algunas-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>A</b> Algunas distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="A.1" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html"><i class="fa fa-check"></i><b>A.1</b> Distribuciones discretas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a Modelos Bayesianos con R y STAN</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Bayesianos con R y STAN</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="teoría-de-la-decisión" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Teoría de la decisión</h2>
<p>El problema estadístico de estimar un parámetro se puede ver dentro del contexto de la teoría de decisión: la estimación que proveemos, sea en el ámbito de la estadística clásica o la estadística bayesiana, depende de los datos muestrales, <span class="math inline">\(\mathbf{X}\)</span>, de tal forma que si éstos cambian, la estimación también cambia. De esta manera, el proceso de estimación puede ser representado como una función que toma un conjunto de datos muestrales y los convierte en una estimación (<span class="math inline">\(A(\mathbf{X})\)</span> o simplemente <span class="math inline">\(A\)</span>) del parámetro de interés. En la teoría de decisión, la anterior función se conoce como una regla de decisión.</p>
<p>Así como en la vida cotidiana, por la incertidumbre del futuro (en el ámbito estadístico, por la incertidumbre acerca del parámetro), toda acción que se tome (toda estimación que se provea) puede traer consigo un grado de falla o riesgo. Y es necesario escoger la acción óptima que de alguna forma minimice ese riesgo. Formalizando esta idea intuitiva, se define la función de pérdida <span class="math inline">\(L\)</span> que asocia a cada dupla conformada por la acción tomada y el parámetro de interés <span class="math inline">\(\theta\)</span>, <span class="math inline">\((A, \ \theta)\)</span> con un número no negativo que cuantifica la pérdida que ocasiona la acción (o la estimación) <span class="math inline">\(A\)</span> con respecto al parámetro <span class="math inline">\(\theta\)</span>.</p>
<p>Es claro que se desea escoger aquella acción que minimice de alguna forma la pérdida que ésta ocasiona, pero la función <span class="math inline">\(L\)</span> no se puede minimizar directamente, puesto que:</p>
<ul>
<li><p>En el ámbito de la estadística clásica, el parámetro <span class="math inline">\(\theta\)</span> se considera fijo, y los datos muestrales <span class="math inline">\(\mathbf{X}\)</span> aleatorios. Como la función de pérdida <span class="math inline">\(L\)</span> depende de <span class="math inline">\(\mathbf{X}\)</span>, entonces ésta también será una variable aleatoria, y no se puede minimizar directamente. Por lo tanto se define el riesgo o la pérdida promedio como la esperanza matemática de <span class="math inline">\(L\)</span>; denotando el riesgo como <span class="math inline">\(R\)</span>, éste está definido como <span class="math inline">\(R=E(L)\)</span> (la esperanza se toma con respecto a la distribución probabilística de <span class="math inline">\(\mathbf{X}\)</span>).</p></li>
<li><p>En el ámbito de la estadística bayesiana, <span class="math inline">\(\theta\)</span> sigue siendo una cantidad fija, pero la incertidumbre que tiene el investigador sobre la localización del parámetro se puede modelar mediante funciones de probabilidad. La herramienta fundamental para conocer características de <span class="math inline">\(\theta\)</span> es su función de densidad posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>. En este caso, el riesgo <span class="math inline">\(R\)</span> se define como</p></li>
</ul>
<p><span class="math display">\[\begin{equation*}
R=E(L)=\int L(A, \theta)p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>En cualquiera de los dos casos anteriores, se busca la estimación que minimice el riesgo <span class="math inline">\(R\)</span>. Ilustramos los anteriores conceptos en los siguientes ejemplos tanto en la estadística clásica como en la estadística bayesiana.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-1" class="example"><strong>Ejemplo 1.1  </strong></span>Sea <span class="math inline">\(X_i\)</span> con <span class="math inline">\(i=1,\cdots, n\)</span> una muestra aleatoria con media <span class="math inline">\(\theta\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>, ambas fijas, y suponga que se desea encontrar el mejor estimador de <span class="math inline">\(\theta\)</span> bajo la función de pérdida cuadrática dada por</p>
<p><span class="math display">\[\begin{equation*}
L(A,\theta)=(A-\theta)^2
\end{equation*}\]</span></p>
<p>cuyo riesgo asociado está dado por <span class="math inline">\(R=E(A-\theta)^2\)</span>. En primer lugar, buscaremos dicho estimador dentro de todas las formas lineales de <span class="math inline">\(X_i\)</span>, es decir, los estimadores de la forma <span class="math inline">\(A=\sum_{i=1}^nc_iX_i\)</span>. Por tanto, el riesgo se puede expresar como
<span class="math display">\[\begin{align*}
R=E(A-\theta)^2&amp;=Var(A)+(E(A)-\theta)^2\\
&amp;=\sum_{i=1}^nc_i^2\sigma^2+\theta^2(\sum_{i=1}^nc_i-1)^2
\end{align*}\]</span></p>
<p>Y al buscar los coeficientes <span class="math inline">\(c_i\)</span> que minimizan la anterior expresión, encontramos que <span class="math inline">\(c_i=\theta^2/(\sigma^2+n\theta^2)\)</span> para todo <span class="math inline">\(i\)</span>. Como estos coeficientes conducen a un estimador que depende del parámetro desconocido, concluimos que no hay ningún estimador que minimiza el riesgo.</p>
Para encontrar una solución, es necesario restringir aún más el rango de estimadores; para eso, se impone la restricción de que <span class="math inline">\(\sum_{i=1}^n c_i=1\)</span>. De esta forma, el riesgo está dado por <span class="math inline">\(R=\sum c_i^2\sigma^2\)</span>. Dado que <span class="math inline">\(\sigma^2\)</span> es fijo, al minimizar <span class="math inline">\(\sum c_i^2\)</span> sujeto a la restricción, se tiene que la solución es <span class="math inline">\(c_i=1/n\)</span> para todo <span class="math inline">\(i\)</span>, y así encontramos que el mejor estimador (en el sentido de minimizar el riesgo de la función de pérdida cuadrática) dentro de todas las formas lineales con <span class="math inline">\(\sum c_i=1\)</span> es la media muestral <span class="math inline">\(\bar{X}\)</span>.
</div>
<p><br></p>

<div class="example">
<p><span id="exm:unnamed-chunk-2" class="example"><strong>Ejemplo 1.2  </strong></span>Suponga que se desea estimar un parámetro de interés <span class="math inline">\(\theta\)</span> en el contexto de la estadística bayesiana y denotamos la función de densidad posterior de <span class="math inline">\(\theta\)</span> como <span class="math inline">\(p(\theta|\mathbf{X})\)</span>, entonces si utilizamos la función de pérdida cuadrática, el riesgo asociado será</p>
<p><span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))=E (A-\theta)^2=Var(\theta)+(E(\theta)-A)^2
\end{align*}\]</span></p>
que es minimizado si <span class="math inline">\(A=E(\theta)\)</span>. Es decir, la mejor acción para estimar <span class="math inline">\(\theta\)</span> es utilizar su tomada con respecto a la distribución posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>.
</div>
<p><br></p>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Ejemplo 1.3  </strong></span>En el mismo contexto del ejemplo anterior, si cambiamos la función de pérdida a la siguiente
<span class="math display">\[\begin{equation*}
L(A,\theta)=|A-\theta|=(A-\theta)I_{(A\geq\theta)}+(\theta-A)I_{(\theta&gt;A)}
\end{equation*}\]</span></p>
<p>El riesgo estará dado por
<span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))\\
&amp;=\int L(A,\theta)p(\theta|\mathbf{X})d\theta\\
&amp;=\int_{(A\geq\theta)}(A-\theta)p(\theta|\mathbf{X})d\theta+\int_{(\theta&gt;A)}(\theta-A)p(\theta|\mathbf{X})d\theta
\end{align*}\]</span></p>
<p>Derivando el riesgo con respecto a la acción <span class="math inline">\(A\)</span>, se tiene que
<span class="math display">\[\begin{equation*}
\frac{\partial R}{\partial A}=\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta-\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>Igualando a cero, tenemos que
<span class="math display">\[\begin{equation*}
\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta=\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta=0.5
\end{equation*}\]</span></p>
Y concluimos que la acción <span class="math inline">\(A\)</span> que induce menor riesgo corresponde al percentil 50% o la mediana de la distribución posterior de <span class="math inline">\(\theta\)</span>.
</div>
<p><br></p>
<p>De los anteriores ejemplos se observa que, bajo un mismo contexto, cuando se utilizan diferentes funciones de pérdida, también se obtienen distintas estimaciones, y distintas acciones que optimizan el riesgo.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tópicos-básicos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="algunos-resultados-de-probabilidad.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ModelosBayesianos.pdf", "ModelosBayesianos.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
