<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>C.2 Métodos de Monte Carlo vía cadenas de Markov | Modelos Bayesianos con R y STAN</title>
  <meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="C.2 Métodos de Monte Carlo vía cadenas de Markov | Modelos Bayesianos con R y STAN" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="github-repo" content="psirusteam/bookdownBayesiano" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="C.2 Métodos de Monte Carlo vía cadenas de Markov | Modelos Bayesianos con R y STAN" />
  
  <meta name="twitter:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />


<meta name="date" content="2021-06-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="métodos-directos.html"/>
<link rel="next" href="referencias.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Bayesianos con R y STAN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="" data-path="antes-de-comenzar.html"><a href="antes-de-comenzar.html"><i class="fa fa-check"></i>Antes de comenzar</a>
<ul>
<li class="chapter" data-level="" data-path="cuestionamientos-sobre-el-enfoque-bayesiano.html"><a href="cuestionamientos-sobre-el-enfoque-bayesiano.html"><i class="fa fa-check"></i>Cuestionamientos sobre el enfoque bayesiano</a></li>
<li class="chapter" data-level="" data-path="acerca-de-la-notación.html"><a href="acerca-de-la-notación.html"><i class="fa fa-check"></i>Acerca de la notación</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html"><i class="fa fa-check"></i><b>1</b> Tópicos básicos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="teoría-de-la-decisión.html"><a href="teoría-de-la-decisión.html"><i class="fa fa-check"></i><b>1.1</b> Teoría de la decisión</a></li>
<li class="chapter" data-level="1.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html"><i class="fa fa-check"></i><b>1.2</b> Algunos resultados de probabilidad</a></li>
<li class="chapter" data-level="1.3" data-path="teorema-de-bayes.html"><a href="teorema-de-bayes.html"><i class="fa fa-check"></i><b>1.3</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html"><i class="fa fa-check"></i><b>2</b> Inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="2.1" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html"><i class="fa fa-check"></i><b>2.1</b> La distribución previa</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>2.1.1</b> Distribuciones conjugadas</a></li>
<li class="chapter" data-level="2.1.2" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#familia-exponencial"><i class="fa fa-check"></i><b>2.1.2</b> Familia exponencial</a></li>
<li class="chapter" data-level="2.1.3" data-path="la-distribución-previa.html"><a href="la-distribución-previa.html#distribuciones-previas-no-informativas"><i class="fa fa-check"></i><b>2.1.3</b> Distribuciones previas no informativas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>2.2</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#factor-de-bayes"><i class="fa fa-check"></i><b>2.2.1</b> Factor de Bayes</a></li>
<li class="chapter" data-level="2.2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#valor-p-bayesiano"><i class="fa fa-check"></i><b>2.2.2</b> Valor-<span class="math inline">\(p\)</span> Bayesiano</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="criterios-de-información.html"><a href="criterios-de-información.html"><i class="fa fa-check"></i><b>2.3</b> Criterios de información</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="criterios-de-información.html"><a href="criterios-de-información.html#criterio-dic"><i class="fa fa-check"></i><b>2.3.1</b> Criterio DIC</a></li>
<li class="chapter" data-level="2.3.2" data-path="criterios-de-información.html"><a href="criterios-de-información.html#criterios-aic-y-bic"><i class="fa fa-check"></i><b>2.3.2</b> Criterios AIC y BIC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="modelos-uniparamétricos.html"><a href="modelos-uniparamétricos.html"><i class="fa fa-check"></i><b>3</b> Modelos uniparamétricos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="modelo-bernoulli.html"><a href="modelo-bernoulli.html"><i class="fa fa-check"></i><b>3.1</b> Modelo Bernoulli</a></li>
<li class="chapter" data-level="3.2" data-path="modelo-binomial.html"><a href="modelo-binomial.html"><i class="fa fa-check"></i><b>3.2</b> Modelo Binomial</a></li>
<li class="chapter" data-level="3.3" data-path="modelo-binomial-negativo.html"><a href="modelo-binomial-negativo.html"><i class="fa fa-check"></i><b>3.3</b> Modelo Binomial negativo</a></li>
<li class="chapter" data-level="3.4" data-path="modelo-poisson.html"><a href="modelo-poisson.html"><i class="fa fa-check"></i><b>3.4</b> Modelo Poisson</a></li>
<li class="chapter" data-level="3.5" data-path="modelo-exponencial.html"><a href="modelo-exponencial.html"><i class="fa fa-check"></i><b>3.5</b> Modelo Exponencial</a></li>
<li class="chapter" data-level="3.6" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html"><i class="fa fa-check"></i><b>3.6</b> Modelo Normal con media desconocida</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html#distribución-previa-no-informativa-para-theta"><i class="fa fa-check"></i><b>3.6.1</b> Distribución previa no informativa para <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="3.6.2" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html#diferentes-formas-de-hallar-la-distribución-previa-para-theta"><i class="fa fa-check"></i><b>3.6.2</b> Diferentes formas de hallar la distribución previa para <span class="math inline">\(\theta\)</span></a></li>
<li class="chapter" data-level="3.6.3" data-path="modelo-normal-con-media-desconocida.html"><a href="modelo-normal-con-media-desconocida.html#distribuciones-predictivas"><i class="fa fa-check"></i><b>3.6.3</b> Distribuciones predictivas</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="modelo-normal-con-varianza-desconocida.html"><a href="modelo-normal-con-varianza-desconocida.html"><i class="fa fa-check"></i><b>3.7</b> Modelo normal con varianza desconocida</a></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li class="chapter" data-level="A" data-path="elementos-de-probabilidad.html"><a href="elementos-de-probabilidad.html"><i class="fa fa-check"></i><b>A</b> Elementos de probabilidad</a>
<ul>
<li class="chapter" data-level="A.1" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html"><i class="fa fa-check"></i><b>A.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="A.1.1" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-uniforme-discreta"><i class="fa fa-check"></i><b>A.1.1</b> Distribución uniforme discreta</a></li>
<li class="chapter" data-level="A.1.2" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-hipergeométrica"><i class="fa fa-check"></i><b>A.1.2</b> Distribución hipergeométrica</a></li>
<li class="chapter" data-level="A.1.3" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-bernoulli"><i class="fa fa-check"></i><b>A.1.3</b> Distribución Bernoulli</a></li>
<li class="chapter" data-level="A.1.4" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-binomial"><i class="fa fa-check"></i><b>A.1.4</b> Distribución binomial</a></li>
<li class="chapter" data-level="A.1.5" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-binomial-negativa"><i class="fa fa-check"></i><b>A.1.5</b> Distribución Binomial negativa</a></li>
<li class="chapter" data-level="A.1.6" data-path="distribuciones-discretas.html"><a href="distribuciones-discretas.html#distribución-de-poisson"><i class="fa fa-check"></i><b>A.1.6</b> Distribución de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html"><i class="fa fa-check"></i><b>A.2</b> Distribuciones continuas</a>
<ul>
<li class="chapter" data-level="A.2.1" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-uniforme-continua"><i class="fa fa-check"></i><b>A.2.1</b> Distribución Uniforme Continua</a></li>
<li class="chapter" data-level="A.2.2" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-weibull"><i class="fa fa-check"></i><b>A.2.2</b> Distribución Weibull</a></li>
<li class="chapter" data-level="A.2.3" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-valor-extremo"><i class="fa fa-check"></i><b>A.2.3</b> Distribución valor-extremo</a></li>
<li class="chapter" data-level="A.2.4" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-gamma"><i class="fa fa-check"></i><b>A.2.4</b> Distribución Gamma</a></li>
<li class="chapter" data-level="A.2.5" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-gamma-inversa"><i class="fa fa-check"></i><b>A.2.5</b> Distribución Gamma-inversa</a></li>
<li class="chapter" data-level="A.2.6" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-exponencial"><i class="fa fa-check"></i><b>A.2.6</b> Distribución exponencial</a></li>
<li class="chapter" data-level="A.2.7" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-beta"><i class="fa fa-check"></i><b>A.2.7</b> Distribución Beta</a></li>
<li class="chapter" data-level="A.2.8" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-normal"><i class="fa fa-check"></i><b>A.2.8</b> Distribución normal</a></li>
<li class="chapter" data-level="A.2.9" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-log-normal"><i class="fa fa-check"></i><b>A.2.9</b> Distribución log-normal</a></li>
<li class="chapter" data-level="A.2.10" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-ji-cuadrado"><i class="fa fa-check"></i><b>A.2.10</b> Distribución Ji-cuadrado</a></li>
<li class="chapter" data-level="A.2.11" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-t-student"><i class="fa fa-check"></i><b>A.2.11</b> Distribución t-student</a></li>
<li class="chapter" data-level="A.2.12" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-t-student-generalizada"><i class="fa fa-check"></i><b>A.2.12</b> Distribución t-student generalizada</a></li>
<li class="chapter" data-level="A.2.13" data-path="distribuciones-continuas.html"><a href="distribuciones-continuas.html#distribución-f"><i class="fa fa-check"></i><b>A.2.13</b> Distribución F</a></li>
</ul></li>
<li class="chapter" data-level="A.3" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html"><i class="fa fa-check"></i><b>A.3</b> Distribuciones multivariadas</a>
<ul>
<li class="chapter" data-level="A.3.1" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-multinomial"><i class="fa fa-check"></i><b>A.3.1</b> Distribución Multinomial</a></li>
<li class="chapter" data-level="A.3.2" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-dirichelt"><i class="fa fa-check"></i><b>A.3.2</b> Distribución Dirichelt</a></li>
<li class="chapter" data-level="A.3.3" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-normal-multivariante"><i class="fa fa-check"></i><b>A.3.3</b> Distribución Normal Multivariante</a></li>
<li class="chapter" data-level="A.3.4" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-wishart"><i class="fa fa-check"></i><b>A.3.4</b> Distribución Wishart</a></li>
<li class="chapter" data-level="A.3.5" data-path="distribuciones-multivariadas.html"><a href="distribuciones-multivariadas.html#distribución-inversa-wishart"><i class="fa fa-check"></i><b>A.3.5</b> Distribución inversa-Wishart</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="B" data-path="matriz-de-información.html"><a href="matriz-de-información.html"><i class="fa fa-check"></i><b>B</b> Matriz de información</a></li>
<li class="chapter" data-level="C" data-path="elementos-de-simulación-estadística.html"><a href="elementos-de-simulación-estadística.html"><i class="fa fa-check"></i><b>C</b> Elementos de simulación estadística</a>
<ul>
<li class="chapter" data-level="C.1" data-path="métodos-directos.html"><a href="métodos-directos.html"><i class="fa fa-check"></i><b>C.1</b> Métodos directos</a>
<ul>
<li class="chapter" data-level="C.1.1" data-path="métodos-directos.html"><a href="métodos-directos.html#método-de-la-transformación-uniforme"><i class="fa fa-check"></i><b>C.1.1</b> Método de la transformación uniforme</a></li>
<li class="chapter" data-level="C.1.2" data-path="métodos-directos.html"><a href="métodos-directos.html#método-de-la-grilla"><i class="fa fa-check"></i><b>C.1.2</b> Método de la grilla</a></li>
</ul></li>
<li class="chapter" data-level="C.2" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><i class="fa fa-check"></i><b>C.2</b> Métodos de Monte Carlo vía cadenas de Markov</a>
<ul>
<li class="chapter" data-level="C.2.1" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-muestreador-de-gibbs"><i class="fa fa-check"></i><b>C.2.1</b> El muestreador de Gibbs</a></li>
<li class="chapter" data-level="C.2.2" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-algoritmo-de-metrópolis-hastings"><i class="fa fa-check"></i><b>C.2.2</b> El algoritmo de Metrópolis-Hastings</a></li>
<li class="chapter" data-level="C.2.3" data-path="métodos-de-monte-carlo-vía-cadenas-de-markov.html"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#buenas-prácticas-en-la-aplicación-de-métodos-mcmc"><i class="fa fa-check"></i><b>C.2.3</b> Buenas prácticas en la aplicación de métodos MCMC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="referencias.html"><a href="referencias.html"><i class="fa fa-check"></i>Referencias</a></li>
<li class="divider"></li>
<li><a Modelos Bayesianos con R y STAN</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Bayesianos con R y STAN</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="métodos-de-monte-carlo-vía-cadenas-de-markov" class="section level2" number="6.2">
<h2><span class="header-section-number">C.2</span> Métodos de Monte Carlo vía cadenas de Markov</h2>
<div id="el-muestreador-de-gibbs" class="section level3" number="6.2.1">
<h3><span class="header-section-number">C.2.1</span> El muestreador de Gibbs</h3>
<p>Tal como lo afirma <span class="citation"><a href="#ref-Pena2002" role="doc-biblioref">Peña</a> (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, este procedimiento es apropiado para obtener muestras de una distribución
conjunta cuando es fácil muestrear de las distribuciones condicionadas. El algoritmo se implementa asumiendo que <span class="math inline">\(\boldsymbol \theta_i=(\theta^{(1)}_i, . . . , \theta^{(d)}_i)\)</span> representa a los valores actuales de <span class="math inline">\(\boldsymbol \theta\)</span>. Entonces <span class="math inline">\(\boldsymbol \theta_{i+1}\)</span> se obtiene así:</p>
<ul>
<li>Generar <span class="math inline">\(\theta^{(1)}_{i+1}\)</span> de <span class="math inline">\(p(\theta^{(1)} \mid \theta^{(2)}_i, \ldots,\theta^{(d)}_i,x)\)</span></li>
<li>Generar <span class="math inline">\(\theta^{(2)}_{i+1}\)</span> de <span class="math inline">\(p(\theta^{(2)} \mid \theta^{(1)}_{i+1}, \theta^{(3)}_i, \ldots , \theta^{(d)}_i, x)\)</span></li>
<li><span class="math inline">\(\ldots\)</span></li>
<li>Generar <span class="math inline">\(\theta^{(d)}_{i+1}\)</span> de <span class="math inline">\(p(\theta^{(d)} \mid \theta^{(1)}_{i+1}, \theta^{(2)}_{i+1}, \ldots , \theta^{(d-1)}_{i+1} , x)\)</span></li>
</ul>
<p>La idea de este esquema es renovar cada componente por medio de la simulación de la correspondiente distribución condicional. Una vez que la cadena converge, se tiene que los valores de <span class="math inline">\(\boldsymbol \theta\)</span> corresponden a observaciones de la distribución requerida, <span class="math inline">\(p(\boldsymbol \theta\mid x)\)</span>. Sin embargo, en general, no se garantiza una muestra variables aleatorias <em>totalmente</em> independientes provenientes de la distribución <span class="math inline">\(p(\theta \mid x)\)</span>, dado que el esquema del muestreador de Gibbs usa el valor actual para construir el siguiente valor; por ende, la secuencia de valores que se obtiene estará correlacionada.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-14" class="example"><strong>Ejemplo C.4  </strong></span>Se puede implementar el muestreador de Gibbs para generar una secuencia de observaciones con densidad
conjunta</p>
<p><span class="math display">\[\begin{equation*}
(x,y) \sim N_2 \Bigl(0,
 \begin{pmatrix}
 \rho &amp; 0 \\
 0 &amp; \rho
 \end{pmatrix}
 \Bigl)
\end{equation*}\]</span></p>
<p>Teniendo en cuenta que la media de ambas variables es cero y su
varianza uno, entonces la covarianza entre ambas variables será <span class="math inline">\(\rho\)</span> <span class="citation">(<a href="#ref-Robert" role="doc-biblioref">Robert y Casella 2009</a>)</span>. Por ende, partiendo de valores iniciales <span class="math inline">\((x_t, y_t)\)</span>, el algoritmo se centra en actualizar las distribuciones condicionales según el resultado <a href="distribuciones-multivariadas.html#prp:normalmulti">A.27</a>.</p>
<span class="math display">\[\begin{align*}
x_{t+1}\mid y_t     &amp; \sim N(\rho y_t, 1-\rho^2)\\
y_{t+1}\mid x_{t+1} &amp; \sim N(\rho x_{t+1}, 1-\rho^2)
\end{align*}\]</span>
</div>
<div class="sourceCode" id="cb103"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb103-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-1" aria-hidden="true" tabindex="-1"></a>bivariate.gibbs <span class="ot">&lt;-</span> <span class="cf">function</span> (n, rho, x, y) {</span>
<span id="cb103-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-2" aria-hidden="true" tabindex="-1"></a>  mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> n)</span>
<span id="cb103-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-3" aria-hidden="true" tabindex="-1"></a>  mat[<span class="dv">1</span>, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(x, y)</span>
<span id="cb103-4"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb103-5"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-5" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, rho <span class="sc">*</span> y, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb103-6"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-6" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, rho <span class="sc">*</span> x, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb103-7"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-7" aria-hidden="true" tabindex="-1"></a>    mat[i, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(x, y)</span>
<span id="cb103-8"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb103-9"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-9" aria-hidden="true" tabindex="-1"></a>  mat<span class="ot">&lt;-</span><span class="fu">as.data.frame</span>(mat)</span>
<span id="cb103-10"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(mat)</span>
<span id="cb103-11"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb103-12"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb103-13"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-13" aria-hidden="true" tabindex="-1"></a>biv <span class="ot">&lt;-</span> <span class="fu">bivariate.gibbs</span>(<span class="at">n=</span><span class="dv">2000</span>, <span class="at">rho=</span><span class="fl">0.5</span>, <span class="at">x=</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>)</span>
<span id="cb103-14"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb103-14" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(biv)</span></code></pre></div>
<pre><code>##          V1          V2 
## -0.02273293 -0.01762626</code></pre>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(biv)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">V1</th>
<th align="right">V2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">V1</td>
<td align="right">0.9702333</td>
<td align="right">0.4709515</td>
</tr>
<tr class="even">
<td align="left">V2</td>
<td align="right">0.4709515</td>
<td align="right">0.9728540</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(biv)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">V1</th>
<th align="right">V2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">V1</td>
<td align="right">1.000000</td>
<td align="right">0.484746</td>
</tr>
<tr class="even">
<td align="left">V2</td>
<td align="right">0.484746</td>
<td align="right">1.000000</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(biv)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-15"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-15-1.svg" alt="Generación de valores para una distribución normal bivariada." width="672" />
<p class="caption">
Figura C.7: Generación de valores para una distribución normal bivariada.
</p>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-16" class="example"><strong>Ejemplo C.5  </strong></span>Un problema común es el de descartar los primeros valores, puesto que el algoritmo puede demorar en obtener convergencia;
esto se puede resolver en forma empírica utilizando las medias y varianzas acumuladas y graficándolas se puede tomar una decisión acerca del valor óptimo en el que la cadena converge.</p>
Con el siguiente código computacional, es posible corroborar que un punto de corte óptimo desde el cual se consideraría que las cadenas simuladas anteriormente es a partir de la iteración <strong>600</strong>.
</div>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-1" aria-hidden="true" tabindex="-1"></a>g.diag <span class="ot">&lt;-</span> <span class="cf">function</span>(sample){</span>
<span id="cb108-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-2" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(sample) </span>
<span id="cb108-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-3" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow=</span><span class="dv">2</span>, <span class="at">ncol=</span>n)</span>
<span id="cb108-4"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb108-5"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-5" aria-hidden="true" tabindex="-1"></a>    res[<span class="dv">1</span>, i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample[<span class="dv">1</span> <span class="sc">:</span> i])</span>
<span id="cb108-6"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-6" aria-hidden="true" tabindex="-1"></a>    res[<span class="dv">2</span>, i] <span class="ot">&lt;-</span> <span class="fu">var</span>(sample[<span class="dv">1</span> <span class="sc">:</span> i])</span>
<span id="cb108-7"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb108-8"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb108-9"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb108-10"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-11"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-11" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">g.diag</span>(biv[, <span class="dv">1</span>])</span>
<span id="cb108-12"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-12" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">g.diag</span>(biv[, <span class="dv">2</span>])</span>
<span id="cb108-13"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-14"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-14" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb108-15"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m1[<span class="dv">1</span>, ], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.6</span>, <span class="fl">0.6</span>), <span class="at">col=</span><span class="dv">4</span>)</span>
<span id="cb108-16"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-16" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(m2[<span class="dv">1</span>, ], <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="dv">2</span>)</span>
<span id="cb108-17"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-17" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Diagnóstico - Media acumulada&quot;</span>)</span>
<span id="cb108-18"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-19"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m1[<span class="dv">2</span>, ], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">1.5</span>), <span class="at">col=</span><span class="dv">4</span>)</span>
<span id="cb108-20"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-20" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(m2[<span class="dv">2</span>, ], <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="dv">2</span>)</span>
<span id="cb108-21"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb108-21" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Diagnóstico - Varianza acumulada&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-17"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-17-1.svg" alt="Convergencia de la media y varianza usando el muestreador de Gibbs." width="672" />
<p class="caption">
Figura C.8: Convergencia de la media y varianza usando el muestreador de Gibbs.
</p>
</div>
<p>El muestrador de Gibbs también funciona en una “segunda fase”, cuando queremos seleccionar una muestra de <span class="math inline">\(f(\theta\mid x)\)</span>, es decir, la distribución de los parámetros dada la información observada <span class="math inline">\(x\)</span>.</p>

<div class="example">
<p><span id="exm:GibbsN2" class="example"><strong>Ejemplo C.6  </strong></span>Suponga que <span class="math inline">\(y\)</span> tiene distribución <span class="math inline">\(N(\mu,\sigma^2=1/\phi)\)</span> y queremos obtener una muestra de la distribución posterior del vector aleatorio <span class="math inline">\(\boldsymbol \theta=(\mu,1/\phi)\)</span>. Para este caso supongamos que conocemos las distribuciones previas; para la media <span class="math inline">\(\mu\)</span> se asume una distribución uniforme y para la varianza <span class="math inline">\(\phi\)</span> una distribución Gamma con parámetros <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>. La distribución posterior de <span class="math inline">\((\mu, \phi)\)</span> satisface:</p>
<p><span class="math display">\[\begin{equation}  
p(\mu, \phi \mid y) \propto (\phi)^{n/2}
\exp\left\{-\phi
\frac{\sum_{j=1}^n(y_j-\mu)^2}{2}\right\}(\phi)^{a-1}exp(-b/\phi)
\end{equation}\]</span></p>
<p>En donde la primera parte después del signo de proporcionalidad, corresponde a la verosimilitud de la información observada y la segunda parte corresponde a la distribución posterior de <span class="math inline">\(\phi\)</span>; la distribución posterior de <span class="math inline">\(\mu\)</span> no
aparece pues es una constante. Por tanto, ésta se puede escribir como:</p>
<p><span class="math display">\[\begin{equation*}  
p(\mu, \phi \mid y)\propto(\phi)^{n/2+a-1}exp\left\{-\phi\Bigl(\frac{\sum_{j=1}^n(y_j-\mu)^2}{2}+b\Bigl)\right\}
\end{equation*}\]</span></p>
<p>Acudiendo al resultado <a href="distribuciones-continuas.html#prp:gammainver">A.14</a>, la distribución condicional de la varianza <span class="math inline">\(\sigma^2\)</span> dado <span class="math inline">\((\mu, y)\)</span> es Gamma-inversa con parámetros <span class="math inline">\(a+n/2\)</span> y <span class="math inline">\(\sum_{j=1}^n(y_j-\mu)^2/2+b\)</span>. Por tanto,</p>
<p><span class="math display" id="eq:apmunormal">\[\begin{equation} 
\tag{C.1}
\sigma^2\mid\mu,x\sim Gamma-inversa\biggl(\theta+n/2,\sum_{j=1}^n(y_j-\mu)^2/2+b\biggl)
\end{equation}\]</span></p>
<p>Análogamente, la distribución de <span class="math inline">\(\mu\)</span> dado <span class="math inline">\((\sigma^2, y)\)</span> es normal
con media <span class="math inline">\(\bar{y}\)</span> y varianza <span class="math inline">\(\sigma^2/n\)</span>, es decir,</p>
<p><span class="math display" id="eq:apsigmaig">\[\begin{equation}  
\tag{C.2}
\mu\mid\sigma^2,y\sim N(\bar{y},\sigma^2/n)
\end{equation}\]</span></p>
<p>Para implementar el muestreador de Gibbs con estas distribuciones, primero se deben escoger valores apropiados para <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, con el propósito de representar correctamente la
distribución previa, y luego</p>
<ul>
<li>Defninir un valor inicial para la media y la varianza, <span class="math inline">\((\mu_0, \sigma^2_0)\)</span>.</li>
<li>Generar <span class="math inline">\((\mu_{i+1}, \sigma_{i+1}^2)\)</span> simulando <span class="math inline">\(\mu_{i+1}\)</span> de <a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#eq:apmunormal">(C.1)</a> y luego <span class="math inline">\(\sigma^2_{i+1}\)</span> de <a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#eq:apsigmaig">(C.2)</a>.</li>
<li>Iterar para obtener <span class="math inline">\((\mu_0, \sigma^2_0), (\mu_1, \sigma^2_1), (\mu_2, \sigma^2_2),\cdots,\)</span>.</li>
<li>Suponiendo que el algoritmo converge después de
<span class="math inline">\(m\)</span> iteraciones, descartar los <span class="math inline">\(m\)</span> primeros valores.</li>
</ul>
Entonces <span class="math inline">\((\mu_{m+1}, \sigma^2_{m+1}), (\mu_{m+2}, \sigma^2_{m+2}),\cdots,\)</span> es
una muestra (correlacionada) de <span class="math inline">\(p(\mu, \sigma^2\mid x)\)</span>.
</div>
<p>La siguiente función en <code>R</code> implementa el muestreador de Gibbs para el anterior ejemplo.</p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(invgamma)</span>
<span id="cb109-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-3" aria-hidden="true" tabindex="-1"></a>normal2 <span class="ot">&lt;-</span> <span class="cf">function</span>(datos, a, b, nsim, inicial){</span>
<span id="cb109-4"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-4" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(datos)</span>
<span id="cb109-5"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-5" aria-hidden="true" tabindex="-1"></a>  xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(datos)</span>
<span id="cb109-6"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-6" aria-hidden="true" tabindex="-1"></a>  mu.now <span class="ot">&lt;-</span> inicial[<span class="dv">1</span>]</span>
<span id="cb109-7"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-7" aria-hidden="true" tabindex="-1"></a>  var.now <span class="ot">&lt;-</span> inicial[<span class="dv">2</span>]</span>
<span id="cb109-8"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-8" aria-hidden="true" tabindex="-1"></a>  dummy <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> nsim)</span>
<span id="cb109-9"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-9" aria-hidden="true" tabindex="-1"></a>  dummy[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu.now</span>
<span id="cb109-10"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-10" aria-hidden="true" tabindex="-1"></a>  dummy[<span class="dv">1</span>, <span class="dv">2</span>] <span class="ot">&lt;-</span> var.now</span>
<span id="cb109-11"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb109-12"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span> <span class="sc">:</span> nsim){</span>
<span id="cb109-13"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-13" aria-hidden="true" tabindex="-1"></a>    alp <span class="ot">&lt;-</span> a <span class="sc">+</span> (n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb109-14"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-14" aria-hidden="true" tabindex="-1"></a>    bet <span class="ot">&lt;-</span> b <span class="sc">+</span> (<span class="fu">sum</span>((datos <span class="sc">-</span> mu.now)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb109-15"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-15" aria-hidden="true" tabindex="-1"></a>    var.next <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> alp, <span class="at">rate =</span> bet)</span>
<span id="cb109-16"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-16" aria-hidden="true" tabindex="-1"></a>    mu.next <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, xbar, <span class="fu">sqrt</span>(var.now<span class="sc">/</span>n))</span>
<span id="cb109-17"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-17" aria-hidden="true" tabindex="-1"></a>    dummy[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu.next</span>
<span id="cb109-18"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-18" aria-hidden="true" tabindex="-1"></a>    dummy[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> var.next</span>
<span id="cb109-19"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-19" aria-hidden="true" tabindex="-1"></a>    mu.now <span class="ot">&lt;-</span> mu.next</span>
<span id="cb109-20"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-20" aria-hidden="true" tabindex="-1"></a>    var.now <span class="ot">&lt;-</span> var.next</span>
<span id="cb109-21"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb109-22"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(dummy)</span>
<span id="cb109-23"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb109-24"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-25"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-25" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb109-26"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-26" aria-hidden="true" tabindex="-1"></a>mc1.vals <span class="ot">&lt;-</span> <span class="fu">normal2</span>(datos, <span class="at">a =</span> <span class="dv">2</span>, <span class="at">b =</span> <span class="dv">5</span>, </span>
<span id="cb109-27"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-27" aria-hidden="true" tabindex="-1"></a>                    <span class="at">nsim =</span> <span class="dv">1000</span>, <span class="at">inicial =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb109-28"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-28" aria-hidden="true" tabindex="-1"></a>mc1.vals <span class="ot">&lt;-</span> mc1.vals[<span class="dv">101</span><span class="sc">:</span> <span class="dv">1000</span>, ]</span>
<span id="cb109-29"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb109-29" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(mc1.vals)</span></code></pre></div>
<pre><code>## [1] 5.257333 4.107664</code></pre>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb111-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mc1.vals[, <span class="dv">1</span>], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;mu&#39;</span>)</span>
<span id="cb111-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mc1.vals[, <span class="dv">2</span>], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;sigma^2&#39;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-19"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-19-1.svg" alt="Cadenas generadas desde el muestreador de Gibbs." width="672" />
<p class="caption">
Figura C.9: Cadenas generadas desde el muestreador de Gibbs.
</p>
</div>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb112-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(mc1.vals[, <span class="dv">1</span>], <span class="at">prob =</span> T, <span class="at">xlab=</span><span class="st">&#39;mu&#39;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb112-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(mc1.vals[, <span class="dv">1</span>], <span class="at">kernel=</span><span class="st">&#39;gaussian&#39;</span>))</span>
<span id="cb112-4"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb112-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(mc1.vals[, <span class="dv">2</span>], <span class="at">prob =</span> T, <span class="at">xlab=</span><span class="st">&#39;sigma^2&#39;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb112-5"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb112-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(mc1.vals[, <span class="dv">2</span>], <span class="at">kernel=</span><span class="st">&#39;gaussian&#39;</span>))</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-20"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-20-1.svg" alt="Densidades posteriores generadas con el muestreador de Gibbs." width="672" />
<p class="caption">
Figura C.10: Densidades posteriores generadas con el muestreador de Gibbs.
</p>
</div>
</div>
<div id="el-algoritmo-de-metrópolis-hastings" class="section level3" number="6.2.2">
<h3><span class="header-section-number">C.2.2</span> El algoritmo de Metrópolis-Hastings</h3>
<p>Este algoritmo se basa en proponer un nuevo punto de acuerdo a una función de densidad adecuada y aceptar este nuevo valor propuesto con una probabilidad que depende del punto actual, del nuevo punto y de la densidad de la cual fue propuesto el nuevo punto.</p>
<p>Suponga que deseamos simular valores de una distribución multivariada <span class="math inline">\(p(\theta \mid y)\)</span>. Sea la función de densidad propuesta <span class="math inline">\(q(\theta, \theta&#39;)\)</span>, una función de densidad de probabilidad arbitraria que
describe la probabilidad de aceptación de <span class="math inline">\(\theta&#39;\)</span> a partir de la posición actual de <span class="math inline">\(\theta\)</span>. El algoritmo de Metropolis-Hastings está dado por los siguientes pasos:</p>
<ul>
<li>Siendo el valor actual <span class="math inline">\(\theta_i\)</span>, genere un valor candidato <span class="math inline">\(\theta&#39;\)</span> obtenido como una observación de la densidad <span class="math inline">\(q(\theta_i, \theta&#39;)\)</span>.</li>
<li>Calcule
<span class="math display">\[\begin{equation*}
T(\theta_i, \theta&#39;) =
\begin{cases}
\min \left(1,  \frac{p(\theta&#39; \mid  y)q(\theta&#39;, \theta_i)}{p(\theta_i \mid  y)q(\theta_i, \theta&#39;)} \right),
&amp; \text{  si   } p(\theta_i \mid  y)q(\theta_i, \theta&#39;) &gt; 0,\\ 
1, &amp; \text{  si   }
p(\theta_i \mid y)q(\theta_i, \theta&#39;) = 0
\end{cases}
\end{equation*}\]</span></li>
<li>Acepte el nuevo valor y actualícelo a <span class="math inline">\(\theta_{i+1}=\theta&#39;\)</span> con probabilidad <span class="math inline">\(T(\theta_i, \theta&#39;)\)</span>. De otra forma, rechazar el valor candidato y defina <span class="math inline">\(\theta_{i+1}=\theta_i\)</span>.
Repita el paso anterior para obtener la secuencia <span class="math inline">\(\theta_0,\theta_1,...,\)</span>
donde <span class="math inline">\(\theta_0\)</span> denota un valor arbitrario de arranque.
Descarte los primeros <span class="math inline">\(m\)</span> valores obtenidos.</li>
</ul>
<p>Siguiendo el anterior algoritmo, entonces se tiene que <span class="math inline">\(\theta_{m+1}, \theta_{m+2}, \ldots\)</span> es una secuencia (correlacionada) de la distribución requerida. En principio, puede ser usada cualquier densidad <span class="math inline">\(q\)</span>, pero si ésta es escogida ingenuamente, la eficiencia de la cadena puede ser muy pobre. La relación más importante entre el muestreados de Gibbs y el algorítmo de Metropolis-Hastings, está dada como un teorema en el libro de <span class="citation"><a href="#ref-Robert" role="doc-biblioref">Robert y Casella</a> (<a href="#ref-Robert" role="doc-biblioref">2009</a>pág. 296)</span>.</p>

<div class="proposition">
<span id="prp:unnamed-chunk-21" class="proposition"><strong>Resultado A.10  </strong></span>El muestreador de Gibbs es equivalente al algoritmo de Metropolis-Hastings, con la
probabilidad de aceptación igual a uno para todos los puntos propuestos.
</div>
<p><br></p>
<p>Lo anterior implica que la convergencia para ambos métodos no es la misma. Para cerrar la sección de cadenas de Markov vía Monte Carlo, es importante hacernos la siguiente pregunta: ¿Son independientes las muestras simuladas? En principio no se puede hablar de independencia, pues es claro que la observación <span class="math inline">\(\{i+1\}\)</span> depende de la observación <span class="math inline">\(\{i\}\)</span>. Dado que las observaciones resultantes
se encuentran en estricto orden de medición, podríamos utilizar algunos criterios como la función de auto-correlación (ACF) y la función de auto-correlación parcial (PACF), para conocer sobre la correlación entre observaciones.</p>
<p>Siguiendo con el ejemplo <a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#exm:GibbsN2">C.6</a> del apartado de Gibbs, se ha escogido usar como como distribuciones propuestas <span class="math inline">\(q\)</span> para la media y para la varianza, densidades normales centradas en el actual
parámetro, ambas con varianza igual a uno. Dadas las distribuciones propuestas, algunos valores de la varianza pueden ser negativos; aunque este no es un problema porque la distribución posterior le asignará el valor cero, por tanto este valor será rechazado con un probabilidad de uno.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(invgamma)</span>
<span id="cb113-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-3" aria-hidden="true" tabindex="-1"></a>met.hast <span class="ot">&lt;-</span> <span class="cf">function</span>(datos, a, b, iter, ini){</span>
<span id="cb113-4"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-4" aria-hidden="true" tabindex="-1"></a>  mu0 <span class="ot">&lt;-</span> ini[<span class="dv">1</span>] </span>
<span id="cb113-5"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-5" aria-hidden="true" tabindex="-1"></a>  var0 <span class="ot">&lt;-</span> ini[<span class="dv">2</span>]</span>
<span id="cb113-6"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-6" aria-hidden="true" tabindex="-1"></a>  resul <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> iter)</span>
<span id="cb113-7"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-7" aria-hidden="true" tabindex="-1"></a>  resul[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu0</span>
<span id="cb113-8"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-8" aria-hidden="true" tabindex="-1"></a>  resul[<span class="dv">1</span>, <span class="dv">2</span>] <span class="ot">&lt;-</span> var0</span>
<span id="cb113-9"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span> <span class="sc">:</span> iter){</span>
<span id="cb113-10"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-10" aria-hidden="true" tabindex="-1"></a>    mu.prop <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu0, <span class="dv">1</span>)</span>
<span id="cb113-11"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-11" aria-hidden="true" tabindex="-1"></a>    var.prop <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, var0, <span class="dv">1</span>)</span>
<span id="cb113-12"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (var.prop <span class="sc">&lt;=</span> <span class="dv">0</span>){ T.val <span class="ot">&lt;-</span> <span class="dv">0</span> }</span>
<span id="cb113-13"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>{</span>
<span id="cb113-14"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-14" aria-hidden="true" tabindex="-1"></a>      p1 <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(datos, mu.prop, <span class="fu">sqrt</span>(var.prop))) <span class="sc">*</span></span>
<span id="cb113-15"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-15" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dinvgamma</span>(var.prop, <span class="at">shape =</span> a, <span class="at">rate =</span> b)</span>
<span id="cb113-16"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-16" aria-hidden="true" tabindex="-1"></a>      q1 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(mu0, mu.prop, <span class="dv">1</span>) <span class="sc">*</span></span>
<span id="cb113-17"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(var0, var.prop, <span class="dv">1</span>)</span>
<span id="cb113-18"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-18" aria-hidden="true" tabindex="-1"></a>      p2 <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(datos, mu0, <span class="fu">sqrt</span>(var0))) <span class="sc">*</span> </span>
<span id="cb113-19"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-19" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dinvgamma</span>(var0, <span class="at">shape =</span> a, <span class="at">rate =</span> b)</span>
<span id="cb113-20"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-20" aria-hidden="true" tabindex="-1"></a>      q2 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(mu.prop, mu0, <span class="dv">1</span>) <span class="sc">*</span> </span>
<span id="cb113-21"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-21" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(var.prop, var0, <span class="dv">1</span>)</span>
<span id="cb113-22"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-22" aria-hidden="true" tabindex="-1"></a>      T.val <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, (p1 <span class="sc">*</span> q1)<span class="sc">/</span>(p2 <span class="sc">*</span> q2))</span>
<span id="cb113-23"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb113-24"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-24" aria-hidden="true" tabindex="-1"></a>    u <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>) </span>
<span id="cb113-25"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (u <span class="sc">&lt;=</span> T.val){</span>
<span id="cb113-26"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-26" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu.prop</span>
<span id="cb113-27"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-27" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> var.prop</span>
<span id="cb113-28"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-28" aria-hidden="true" tabindex="-1"></a>      } </span>
<span id="cb113-29"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>{</span>
<span id="cb113-30"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-30" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu0</span>
<span id="cb113-31"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-31" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> var0</span>
<span id="cb113-32"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-32" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb113-33"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-33" aria-hidden="true" tabindex="-1"></a>    mu0 <span class="ot">&lt;-</span> resul[i, <span class="dv">1</span>]</span>
<span id="cb113-34"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-34" aria-hidden="true" tabindex="-1"></a>    var0 <span class="ot">&lt;-</span> resul[i, <span class="dv">2</span>]</span>
<span id="cb113-35"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-35" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb113-36"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(resul)</span>
<span id="cb113-37"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-37" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb113-38"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-39"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-39" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb113-40"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-40" aria-hidden="true" tabindex="-1"></a>mc2 <span class="ot">&lt;-</span> <span class="fu">met.hast</span>(datos, <span class="at">a =</span> <span class="dv">2</span>, <span class="at">b =</span> <span class="dv">5</span>, </span>
<span id="cb113-41"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-41" aria-hidden="true" tabindex="-1"></a>                <span class="at">iter =</span> <span class="dv">1000</span>, <span class="at">ini =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb113-42"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb113-42" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(mc2)</span></code></pre></div>
<pre><code>## [1] 5.061780 4.744852</code></pre>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb115-2"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(mc2[, <span class="dv">1</span>], <span class="dv">100</span>)</span>
<span id="cb115-3"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb115-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(mc2[, <span class="dv">2</span>], <span class="dv">100</span>)</span>
<span id="cb115-4"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb115-4" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(mc2[, <span class="dv">1</span>], <span class="dv">100</span>)</span>
<span id="cb115-5"><a href="métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb115-5" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(mc2[, <span class="dv">2</span>], <span class="dv">100</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-23"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-23-1.svg" alt="Autocorrelación y autocorrelación parcial para las cadenas simuladas del algoritmo MH." width="672" />
<p class="caption">
Figura C.11: Autocorrelación y autocorrelación parcial para las cadenas simuladas del algoritmo MH.
</p>
</div>
</div>
<div id="buenas-prácticas-en-la-aplicación-de-métodos-mcmc" class="section level3" number="6.2.3">
<h3><span class="header-section-number">C.2.3</span> Buenas prácticas en la aplicación de métodos MCMC</h3>
<p>Dado que una gran parte de la inferencia bayesiana está ligada a la programación e implementación de los métodos MCMC para realizar inferencias posteriores de los parámetros de interés, se sugiere seguir el razonamiento y recomendaciones de <span class="citation"><a href="#ref-GelShir2010" role="doc-biblioref">A. Gelman y Shirley</a> (<a href="#ref-GelShir2010" role="doc-biblioref">2010</a>)</span>, que puede ser resumido en los siguientes ítemes para cada parámetro de interés:</p>
<ol style="list-style-type: decimal">
<li>Simulación de tres o más cadenas de forma paralela. Los valores iniciales de cada cadena deben estar dispersos entre sí.</li>
<li>Comprobación de la convergencia de las cadenas mediante el descarte de la primera mitad de los valores generados en las cadenas. Esta etapa se conoce como <em>burning stage</em>.</li>
<li>Una vez que las cadenas converjan, mezclar los tres conjuntos de valores generados por las cadenas. Esto garantiza, en primera instancia, que las cadenas no estén auto-correlacionadas.</li>
<li>Además de realizar esta mezcla, descartar valores intermedios mediante un muestreo sistemático. Esta etapa se conoce como <em>thining stage</em>. Al final se recomienda almacenar una cantidad elevada de valores simulados.</li>
<li>Calibrar el algoritmo si la convergencia de las cadenas no se presenta rápidamente.
<ul>
<li>Para los algoritmos de Metropolis-Hastings, escoger una distribución de salto acorde con la distribución de la cual se desea simular. Por ejemplo, <span class="citation"><a href="#ref-Cepe1" role="doc-biblioref">Cepeda y Gamerman</a> (<a href="#ref-Cepe1" role="doc-biblioref">2001</a>)</span> presentan dos distribuciones de salto para el problema de la modelación de la varianza (cada una de las propuestas presenta tasas de aceptación diferentes).</li>
</ul></li>
<li>Comparación y contraste de los resultados con modelos simples que permitan examinar posibles discrepancias y corregir errores de programación.</li>
</ol>
<p>En términos de inferencia bayesiana, se tienen dos tipos de procesos: el primero y más común, que trata de realizar inferencias acerca de un vector de parámetros de interés <span class="math inline">\(\boldsymbol \theta\)</span>; el segundo trata con los momentos del parámetro, por ejemplo su esperanza. Nótese que el primer proceso se presenta con seguridad en ejercicios empíricos simulados; sin embargo, el segundo se presenta en los ejercicios prácticos con datos reales, en donde se quiere contrastar alguna hipótesis.</p>
<p>Las anteriores dos opciones tienen tratamientos muy diferentes en términos de la cantidad de simulaciones requeridas. Por ejemplo, si el objetivo es inferir acerca de <span class="math inline">\(\boldsymbol \theta\)</span>, para conocer su comportamiento estructural, basta con realizar una simulación que genere una cantidad mediana de valores y que se resumen en un promedio y una desviación estándar. Por otro lado, si el objetivo es inferir acerca de <span class="math inline">\(E(\boldsymbol \theta)\)</span>, se requieren muchas más simulaciones para obtener una buena precisión. Siguiendo a <span class="citation"><a href="#ref-GelShir2010" role="doc-biblioref">A. Gelman y Shirley</a> (<a href="#ref-GelShir2010" role="doc-biblioref">2010</a>)</span>, una vez terminado el proceso de <em>burning</em> y <em>thining</em>, se sugiere que se dividan los valores simulados en las cadenas paralelas y se formen <span class="math inline">\(k\)</span> grupos; de esta forma, una estimación de <span class="math inline">\(E(\boldsymbol \theta)\)</span> será la gran media de las medias muestrales de cada grupo y el error estándar será su desviación estándar dividida por <span class="math inline">\(\sqrt{k}\)</span>.</p>

</div>
</div>
<!-- </div> -->
<h3>Referencias</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Cepe1" class="csl-entry">
Cepeda, E., y D. Gamerman. 2001. <span>«Bayesian Modeling of Variance Heterogeneity in Normal Regression Models»</span>. <em>Brazilian Journal of Probability and Statistics</em> 14: 207-21.
</div>
<div id="ref-GelShir2010" class="csl-entry">
Gelman, A., y K Shirley. 2010. <span>«Handbook of Markov Chain Monte Carlo»</span>. En. CRC.
</div>
<div id="ref-Pena2002" class="csl-entry">
Peña, D. 2002. <em><span>Análisis de datos multivariantes</span></em>. <span>McGraw-Hill</span>.
</div>
<div id="ref-Robert" class="csl-entry">
———. 2009. <em>Introducing Monte Carlo Methods with R</em>. Springer.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="métodos-directos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="referencias.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/psirusteam/bookdownBayesiano/A3Simulacion.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ModelosBayesianos.pdf", "ModelosBayesianos.epub", "ModelosBayesianos.mobi"],
"toc": {
"collapse": "section"
},
"tconfig": null
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
