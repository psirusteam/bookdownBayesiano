<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="C.2 Métodos de Monte Carlo vía cadenas de Markov | Modelos Bayesianos con R y STAN" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
<meta name="github-repo" content="psirusteam/bookdownBayesiano" />

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />

<meta name="date" content="2021-06-04" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN.">

<title>C.2 Métodos de Monte Carlo vía cadenas de Markov | Modelos Bayesianos con R y STAN</title>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#prefacio">Prefacio</a></li>
<li><a href="antes-de-comenzar.html#antes-de-comenzar">Antes de comenzar</a>
<ul>
<li><a href="cuestionamientos-sobre-el-enfoque-bayesiano.html#cuestionamientos-sobre-el-enfoque-bayesiano">Cuestionamientos sobre el enfoque bayesiano</a></li>
<li><a href="acerca-de-la-notación.html#acerca-de-la-notación">Acerca de la notación</a></li>
</ul></li>
<li><a href="1-tópicos-básicos.html#tópicos-básicos"><span class="toc-section-number">1</span> Tópicos básicos</a>
<ul>
<li><a href="1-1-teoría-de-la-decisión.html#teoría-de-la-decisión"><span class="toc-section-number">1.1</span> Teoría de la decisión</a></li>
<li><a href="1-2-algunos-resultados-de-probabilidad.html#algunos-resultados-de-probabilidad"><span class="toc-section-number">1.2</span> Algunos resultados de probabilidad</a></li>
<li><a href="1-3-teorema-de-bayes.html#teorema-de-bayes"><span class="toc-section-number">1.3</span> Teorema de Bayes</a></li>
</ul></li>
<li><a href="2-inferencia-bayesiana.html#inferencia-bayesiana"><span class="toc-section-number">2</span> Inferencia bayesiana</a>
<ul>
<li><a href="2-1-la-distribución-previa.html#la-distribución-previa"><span class="toc-section-number">2.1</span> La distribución previa</a>
<ul>
<li><a href="2-1-la-distribución-previa.html#distribuciones-conjugadas"><span class="toc-section-number">2.1.1</span> Distribuciones conjugadas</a></li>
<li><a href="2-1-la-distribución-previa.html#familia-exponencial"><span class="toc-section-number">2.1.2</span> Familia exponencial</a></li>
<li><a href="2-1-la-distribución-previa.html#distribuciones-previas-no-informativas"><span class="toc-section-number">2.1.3</span> Distribuciones previas no informativas</a></li>
</ul></li>
<li><a href="2-2-pruebas-de-hipótesis.html#pruebas-de-hipótesis"><span class="toc-section-number">2.2</span> Pruebas de hipótesis</a>
<ul>
<li><a href="2-2-pruebas-de-hipótesis.html#factor-de-bayes"><span class="toc-section-number">2.2.1</span> Factor de Bayes</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#valor-p-bayesiano"><span class="toc-section-number">2.2.2</span> Valor-<span class="math inline">\(p\)</span> Bayesiano</a></li>
</ul></li>
<li><a href="2-3-criterios-de-información.html#criterios-de-información"><span class="toc-section-number">2.3</span> Criterios de información</a>
<ul>
<li><a href="2-3-criterios-de-información.html#criterio-dic"><span class="toc-section-number">2.3.1</span> Criterio DIC</a></li>
<li><a href="2-3-criterios-de-información.html#criterios-aic-y-bic"><span class="toc-section-number">2.3.2</span> Criterios AIC y BIC</a></li>
</ul></li>
</ul></li>
<li><a href="3-modelos-uniparamétricos.html#modelos-uniparamétricos"><span class="toc-section-number">3</span> Modelos uniparamétricos</a>
<ul>
<li><a href="3-1-modelo-bernoulli.html#modelo-bernoulli"><span class="toc-section-number">3.1</span> Modelo Bernoulli</a></li>
<li><a href="3-2-modelo-binomial.html#modelo-binomial"><span class="toc-section-number">3.2</span> Modelo Binomial</a></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li><a href="A-elementos-de-probabilidad.html#elementos-de-probabilidad"><span class="toc-section-number">A</span> Elementos de probabilidad</a>
<ul>
<li><a href="A-1-distribuciones-discretas.html#distribuciones-discretas"><span class="toc-section-number">A.1</span> Distribuciones discretas</a>
<ul>
<li><a href="A-1-distribuciones-discretas.html#distribución-uniforme-discreta"><span class="toc-section-number">A.1.1</span> Distribución uniforme discreta</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-hipergeométrica"><span class="toc-section-number">A.1.2</span> Distribución hipergeométrica</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-bernoulli"><span class="toc-section-number">A.1.3</span> Distribución Bernoulli</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-binomial"><span class="toc-section-number">A.1.4</span> Distribución binomial</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-binomial-negativa"><span class="toc-section-number">A.1.5</span> Distribución Binomial negativa</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-de-poisson"><span class="toc-section-number">A.1.6</span> Distribución de Poisson</a></li>
</ul></li>
<li><a href="A-2-distribuciones-continuas.html#distribuciones-continuas"><span class="toc-section-number">A.2</span> Distribuciones continuas</a>
<ul>
<li><a href="A-2-distribuciones-continuas.html#distribución-uniforme-continua"><span class="toc-section-number">A.2.1</span> Distribución Uniforme Continua</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-weibull"><span class="toc-section-number">A.2.2</span> Distribución Weibull</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-valor-extremo"><span class="toc-section-number">A.2.3</span> Distribución valor-extremo</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-gamma"><span class="toc-section-number">A.2.4</span> Distribución Gamma</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-gamma-inversa"><span class="toc-section-number">A.2.5</span> Distribución Gamma-inversa</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-exponencial"><span class="toc-section-number">A.2.6</span> Distribución exponencial</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-beta"><span class="toc-section-number">A.2.7</span> Distribución Beta</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-normal"><span class="toc-section-number">A.2.8</span> Distribución normal</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-log-normal"><span class="toc-section-number">A.2.9</span> Distribución log-normal</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-ji-cuadrado"><span class="toc-section-number">A.2.10</span> Distribución Ji-cuadrado</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-t-student"><span class="toc-section-number">A.2.11</span> Distribución t-student</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-t-student-generalizada"><span class="toc-section-number">A.2.12</span> Distribución t-student generalizada</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-f"><span class="toc-section-number">A.2.13</span> Distribución F</a></li>
</ul></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribuciones-multivariadas"><span class="toc-section-number">A.3</span> Distribuciones multivariadas</a>
<ul>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-multinomial"><span class="toc-section-number">A.3.1</span> Distribución Multinomial</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-dirichelt"><span class="toc-section-number">A.3.2</span> Distribución Dirichelt</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-normal-multivariante"><span class="toc-section-number">A.3.3</span> Distribución Normal Multivariante</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-wishart"><span class="toc-section-number">A.3.4</span> Distribución Wishart</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-inversa-wishart"><span class="toc-section-number">A.3.5</span> Distribución inversa-Wishart</a></li>
</ul></li>
</ul></li>
<li><a href="B-matriz-de-información.html#matriz-de-información"><span class="toc-section-number">B</span> Matriz de información</a></li>
<li><a href="C-elementos-de-simulación-estadística.html#elementos-de-simulación-estadística"><span class="toc-section-number">C</span> Elementos de simulación estadística</a>
<ul>
<li><a href="C-1-métodos-directos.html#métodos-directos"><span class="toc-section-number">C.1</span> Métodos directos</a>
<ul>
<li><a href="C-1-métodos-directos.html#método-de-la-transformación-uniforme"><span class="toc-section-number">C.1.1</span> Método de la transformación uniforme</a></li>
<li><a href="C-1-métodos-directos.html#método-de-la-grilla"><span class="toc-section-number">C.1.2</span> Método de la grilla</a></li>
</ul></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#métodos-de-monte-carlo-vía-cadenas-de-markov"><span class="toc-section-number">C.2</span> Métodos de Monte Carlo vía cadenas de Markov</a>
<ul>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-muestreador-de-gibbs"><span class="toc-section-number">C.2.1</span> El muestreador de Gibbs</a></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-algoritmo-de-metrópolis-hastings"><span class="toc-section-number">C.2.2</span> El algoritmo de Metrópolis-Hastings</a></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#buenas-prácticas-en-la-aplicación-de-métodos-mcmc"><span class="toc-section-number">C.2.3</span> Buenas prácticas en la aplicación de métodos MCMC</a></li>
</ul></li>
</ul></li>
<li><a href="referencias.html#referencias">Referencias</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="métodos-de-monte-carlo-vía-cadenas-de-markov" class="section level2" number="6.2">
<h2><span class="header-section-number">C.2</span> Métodos de Monte Carlo vía cadenas de Markov</h2>
<div id="el-muestreador-de-gibbs" class="section level3" number="6.2.1">
<h3><span class="header-section-number">C.2.1</span> El muestreador de Gibbs</h3>
<p>Tal como lo afirma <span class="citation"><a href="#ref-Pena2002" role="doc-biblioref">Peña</a> (<a href="#ref-Pena2002" role="doc-biblioref">2002</a>)</span>, este procedimiento es apropiado para obtener muestras de una distribución
conjunta cuando es fácil muestrear de las distribuciones condicionadas. El algoritmo se implementa asumiendo que <span class="math inline">\(\boldsymbol \theta_i=(\theta^{(1)}_i, . . . , \theta^{(d)}_i)\)</span> representa a los valores actuales de <span class="math inline">\(\boldsymbol \theta\)</span>. Entonces <span class="math inline">\(\boldsymbol \theta_{i+1}\)</span> se obtiene así:</p>
<ul>
<li>Generar <span class="math inline">\(\theta^{(1)}_{i+1}\)</span> de <span class="math inline">\(p(\theta^{(1)} \mid \theta^{(2)}_i, \ldots,\theta^{(d)}_i,x)\)</span></li>
<li>Generar <span class="math inline">\(\theta^{(2)}_{i+1}\)</span> de <span class="math inline">\(p(\theta^{(2)} \mid \theta^{(1)}_{i+1}, \theta^{(3)}_i, \ldots , \theta^{(d)}_i, x)\)</span></li>
<li><span class="math inline">\(\ldots\)</span></li>
<li>Generar <span class="math inline">\(\theta^{(d)}_{i+1}\)</span> de <span class="math inline">\(p(\theta^{(d)} \mid \theta^{(1)}_{i+1}, \theta^{(2)}_{i+1}, \ldots , \theta^{(d-1)}_{i+1} , x)\)</span></li>
</ul>
<p>La idea de este esquema es renovar cada componente por medio de la simulación de la correspondiente distribución condicional. Una vez que la cadena converge, se tiene que los valores de <span class="math inline">\(\boldsymbol \theta\)</span> corresponden a observaciones de la distribución requerida, <span class="math inline">\(p(\boldsymbol \theta\mid x)\)</span>. Sin embargo, en general, no se garantiza una muestra variables aleatorias <em>totalmente</em> independientes provenientes de la distribución <span class="math inline">\(p(\theta \mid x)\)</span>, dado que el esquema del muestreador de Gibbs usa el valor actual para construir el siguiente valor; por ende, la secuencia de valores que se obtiene estará correlacionada.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-13" class="example"><strong>Ejemplo C.3  </strong></span>Se puede implementar el muestreador de Gibbs para generar una secuencia de observaciones con densidad
conjunta</p>
<p><span class="math display">\[\begin{equation*}
(x,y) \sim N_2 \Bigl(0,
 \begin{pmatrix}
 \rho &amp; 0 \\
 0 &amp; \rho
 \end{pmatrix}
 \Bigl)
\end{equation*}\]</span></p>
<p>Teniendo en cuenta que la media de ambas variables es cero y su
varianza uno, entonces la covarianza entre ambas variables será <span class="math inline">\(\rho\)</span> <span class="citation">(<a href="#ref-Robert" role="doc-biblioref">Robert y Casella 2009</a>)</span>. Por ende, partiendo de valores iniciales <span class="math inline">\((x_t, y_t)\)</span>, el algoritmo se centra en actualizar las distribuciones condicionales según el resultado <a href="A-3-distribuciones-multivariadas.html#prp:normalmulti">A.29</a>.</p>
<span class="math display">\[\begin{align*}
x_{t+1}\mid y_t     &amp; \sim N(\rho y_t, 1-\rho^2)\\
y_{t+1}\mid x_{t+1} &amp; \sim N(\rho x_{t+1}, 1-\rho^2)
\end{align*}\]</span>
</div>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-1" aria-hidden="true" tabindex="-1"></a>bivariate.gibbs <span class="ot">&lt;-</span> <span class="cf">function</span> (n, rho, x, y) {</span>
<span id="cb60-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-2" aria-hidden="true" tabindex="-1"></a>  mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> n)</span>
<span id="cb60-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-3" aria-hidden="true" tabindex="-1"></a>  mat[<span class="dv">1</span>, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(x, y)</span>
<span id="cb60-4"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>n){</span>
<span id="cb60-5"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-5" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, rho <span class="sc">*</span> y, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb60-6"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-6" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, rho <span class="sc">*</span> x, <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">-</span> rho<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb60-7"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-7" aria-hidden="true" tabindex="-1"></a>    mat[i, ] <span class="ot">&lt;-</span> <span class="fu">c</span>(x, y)</span>
<span id="cb60-8"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-8" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb60-9"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-9" aria-hidden="true" tabindex="-1"></a>  mat<span class="ot">&lt;-</span><span class="fu">as.data.frame</span>(mat)</span>
<span id="cb60-10"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(mat)</span>
<span id="cb60-11"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb60-12"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-13"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-13" aria-hidden="true" tabindex="-1"></a>biv <span class="ot">&lt;-</span> <span class="fu">bivariate.gibbs</span>(<span class="at">n=</span><span class="dv">2000</span>, <span class="at">rho=</span><span class="fl">0.5</span>, <span class="at">x=</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>)</span>
<span id="cb60-14"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb60-14" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(biv)</span></code></pre></div>
<pre><code>##          V1          V2 
## -0.03049146 -0.03824099</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(biv)</span></code></pre></div>
<pre><code>##           V1        V2
## V1 0.9603237 0.4710118
## V2 0.4710118 0.9649985</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(biv)</span></code></pre></div>
<pre><code>##           V1        V2
## V1 1.0000000 0.4892825
## V2 0.4892825 1.0000000</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(biv)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-14"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-14-1.png" alt="Generación de valores para una distribución normal bivariada." width="672" />
<p class="caption">
Figura C.7: Generación de valores para una distribución normal bivariada.
</p>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-15" class="example"><strong>Ejemplo 2.1  </strong></span>Un problema común es el de descartar los primeros valores, puesto que el algoritmo puede demorar en obtener convergencia;
esto se puede resolver en forma empírica utilizando las medias y varianzas acumuladas y graficándolas se puede tomar una decisión acerca del valor óptimo en el que la cadena converge.</p>
Con el siguiente código computacional, es posible corroborar que un punto de corte óptimo desde el cual se consideraría que las cadenas simuladas anteriormente es a partir de la iteración <strong>600</strong>.
</div>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-1" aria-hidden="true" tabindex="-1"></a>g.diag <span class="ot">&lt;-</span> <span class="cf">function</span>(sample){</span>
<span id="cb67-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-2" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(sample) </span>
<span id="cb67-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-3" aria-hidden="true" tabindex="-1"></a>  res <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">nrow=</span><span class="dv">2</span>, <span class="at">ncol=</span>n)</span>
<span id="cb67-4"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-4" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n){</span>
<span id="cb67-5"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-5" aria-hidden="true" tabindex="-1"></a>    res[<span class="dv">1</span>, i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample[<span class="dv">1</span> <span class="sc">:</span> i])</span>
<span id="cb67-6"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-6" aria-hidden="true" tabindex="-1"></a>    res[<span class="dv">2</span>, i] <span class="ot">&lt;-</span> <span class="fu">var</span>(sample[<span class="dv">1</span> <span class="sc">:</span> i])</span>
<span id="cb67-7"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-7" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb67-8"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(res)</span>
<span id="cb67-9"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-9" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb67-10"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-11"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-11" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">g.diag</span>(biv[, <span class="dv">1</span>])</span>
<span id="cb67-12"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-12" aria-hidden="true" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">g.diag</span>(biv[, <span class="dv">2</span>])</span>
<span id="cb67-13"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-14"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-14" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb67-15"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m1[<span class="dv">1</span>, ], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.6</span>, <span class="fl">0.6</span>), <span class="at">col=</span><span class="dv">4</span>)</span>
<span id="cb67-16"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-16" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(m2[<span class="dv">1</span>, ], <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="dv">2</span>)</span>
<span id="cb67-17"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-17" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Diagnóstico - Media acumulada&quot;</span>)</span>
<span id="cb67-18"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-19"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(m1[<span class="dv">2</span>, ], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">1.5</span>), <span class="at">col=</span><span class="dv">4</span>)</span>
<span id="cb67-20"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-20" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(m2[<span class="dv">2</span>, ], <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="dv">2</span>)</span>
<span id="cb67-21"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb67-21" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="st">&quot;Diagnóstico - Varianza acumulada&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-16"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-16-1.png" alt="Convergencia de la media y varianza usando el muestreador de Gibbs." width="672" />
<p class="caption">
Figura C.8: Convergencia de la media y varianza usando el muestreador de Gibbs.
</p>
</div>
<p>El muestrador de Gibbs también funciona en una “segunda fase”, cuando queremos seleccionar una muestra de <span class="math inline">\(f(\theta\mid x)\)</span>, es decir, la distribución de los parámetros dada la información observada <span class="math inline">\(x\)</span>.</p>

<div class="example">
<p><span id="exm:GibbsN2" class="example"><strong>Ejemplo C.4  </strong></span>Suponga que <span class="math inline">\(y\)</span> tiene distribución <span class="math inline">\(N(\mu,\sigma^2=1/\phi)\)</span> y queremos obtener una muestra de la distribución posterior del vector aleatorio <span class="math inline">\(\boldsymbol \theta=(\mu,1/\phi)\)</span>. Para este caso supongamos que conocemos las distribuciones previas; para la media <span class="math inline">\(\mu\)</span> se asume una distribución uniforme y para la varianza <span class="math inline">\(\phi\)</span> una distribución Gamma con parámetros <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>. La distribución posterior de <span class="math inline">\((\mu, \phi)\)</span> satisface:</p>
<p><span class="math display">\[\begin{equation}  
p(\mu, \phi \mid y) \propto (\phi)^{n/2}
\exp\left\{-\phi
\frac{\sum_{j=1}^n(y_j-\mu)^2}{2}\right\}(\phi)^{a-1}exp(-b/\phi)
\end{equation}\]</span></p>
<p>En donde la primera parte después del signo de proporcionalidad, corresponde a la verosimilitud de la información observada y la segunda parte corresponde a la distribución posterior de <span class="math inline">\(\phi\)</span>; la distribución posterior de <span class="math inline">\(\mu\)</span> no
aparece pues es una constante. Por tanto, ésta se puede escribir como:</p>
<p><span class="math display">\[\begin{equation*}  
p(\mu, \phi \mid y)\propto(\phi)^{n/2+a-1}exp\left\{-\phi\Bigl(\frac{\sum_{j=1}^n(y_j-\mu)^2}{2}+b\Bigl)\right\}
\end{equation*}\]</span></p>
<p>Acudiendo al resultado <a href="A-2-distribuciones-continuas.html#prp:gammainver">A.14</a>, la distribución condicional de la varianza <span class="math inline">\(\sigma^2\)</span> dado <span class="math inline">\((\mu, y)\)</span> es Gamma-inversa con parámetros <span class="math inline">\(a+n/2\)</span> y <span class="math inline">\(\sum_{j=1}^n(y_j-\mu)^2/2+b\)</span>. Por tanto,</p>
<p><span class="math display" id="eq:apmunormal">\[\begin{equation} 
\tag{C.1}
\sigma^2\mid\mu,x\sim Gamma-inversa\biggl(\theta+n/2,\sum_{j=1}^n(y_j-\mu)^2/2+b\biggl)
\end{equation}\]</span></p>
<p>Análogamente, la distribución de <span class="math inline">\(\mu\)</span> dado <span class="math inline">\((\sigma^2, y)\)</span> es normal
con media <span class="math inline">\(\bar{y}\)</span> y varianza <span class="math inline">\(\sigma^2/n\)</span>, es decir,</p>
<p><span class="math display" id="eq:apsigmaig">\[\begin{equation}  
\tag{C.2}
\mu\mid\sigma^2,y\sim N(\bar{y},\sigma^2/n)
\end{equation}\]</span></p>
<p>Para implementar el muestreador de Gibbs con estas distribuciones, primero se deben escoger valores apropiados para <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, con el propósito de representar correctamente la
distribución previa, y luego</p>
<ul>
<li>Defninir un valor inicial para la media y la varianza, <span class="math inline">\((\mu_0, \sigma^2_0)\)</span>.</li>
<li>Generar <span class="math inline">\((\mu_{i+1}, \sigma_{i+1}^2)\)</span> simulando <span class="math inline">\(\mu_{i+1}\)</span> de <a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#eq:apmunormal">(C.1)</a> y luego <span class="math inline">\(\sigma^2_{i+1}\)</span> de <a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#eq:apsigmaig">(C.2)</a>.</li>
<li>Iterar para obtener <span class="math inline">\((\mu_0, \sigma^2_0), (\mu_1, \sigma^2_1), (\mu_2, \sigma^2_2),\cdots,\)</span>.</li>
<li>Suponiendo que el algoritmo converge después de
<span class="math inline">\(m\)</span> iteraciones, descartar los <span class="math inline">\(m\)</span> primeros valores.</li>
</ul>
Entonces <span class="math inline">\((\mu_{m+1}, \sigma^2_{m+1}), (\mu_{m+2}, \sigma^2_{m+2}),\cdots,\)</span> es
una muestra (correlacionada) de <span class="math inline">\(p(\mu, \sigma^2\mid x)\)</span>.
</div>
<p>La siguiente función en <code>R</code> implementa el muestreador de Gibbs para el anterior ejemplo.</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(invgamma)</span>
<span id="cb68-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-3" aria-hidden="true" tabindex="-1"></a>normal2 <span class="ot">&lt;-</span> <span class="cf">function</span>(datos, a, b, nsim, inicial){</span>
<span id="cb68-4"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-4" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(datos)</span>
<span id="cb68-5"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-5" aria-hidden="true" tabindex="-1"></a>  xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(datos)</span>
<span id="cb68-6"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-6" aria-hidden="true" tabindex="-1"></a>  mu.now <span class="ot">&lt;-</span> inicial[<span class="dv">1</span>]</span>
<span id="cb68-7"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-7" aria-hidden="true" tabindex="-1"></a>  var.now <span class="ot">&lt;-</span> inicial[<span class="dv">2</span>]</span>
<span id="cb68-8"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-8" aria-hidden="true" tabindex="-1"></a>  dummy <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> nsim)</span>
<span id="cb68-9"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-9" aria-hidden="true" tabindex="-1"></a>  dummy[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu.now</span>
<span id="cb68-10"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-10" aria-hidden="true" tabindex="-1"></a>  dummy[<span class="dv">1</span>, <span class="dv">2</span>] <span class="ot">&lt;-</span> var.now</span>
<span id="cb68-11"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-12"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span> <span class="sc">:</span> nsim){</span>
<span id="cb68-13"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-13" aria-hidden="true" tabindex="-1"></a>    alp <span class="ot">&lt;-</span> a <span class="sc">+</span> (n<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb68-14"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-14" aria-hidden="true" tabindex="-1"></a>    bet <span class="ot">&lt;-</span> b <span class="sc">+</span> (<span class="fu">sum</span>((datos <span class="sc">-</span> mu.now)<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb68-15"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-15" aria-hidden="true" tabindex="-1"></a>    var.next <span class="ot">&lt;-</span> <span class="fu">rinvgamma</span>(<span class="dv">1</span>, <span class="at">shape =</span> alp, <span class="at">rate =</span> bet)</span>
<span id="cb68-16"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-16" aria-hidden="true" tabindex="-1"></a>    mu.next <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, xbar, <span class="fu">sqrt</span>(var.now<span class="sc">/</span>n))</span>
<span id="cb68-17"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-17" aria-hidden="true" tabindex="-1"></a>    dummy[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu.next</span>
<span id="cb68-18"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-18" aria-hidden="true" tabindex="-1"></a>    dummy[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> var.next</span>
<span id="cb68-19"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-19" aria-hidden="true" tabindex="-1"></a>    mu.now <span class="ot">&lt;-</span> mu.next</span>
<span id="cb68-20"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-20" aria-hidden="true" tabindex="-1"></a>    var.now <span class="ot">&lt;-</span> var.next</span>
<span id="cb68-21"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-21" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb68-22"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(dummy)</span>
<span id="cb68-23"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb68-24"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-25"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-25" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb68-26"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-26" aria-hidden="true" tabindex="-1"></a>mc1.vals <span class="ot">&lt;-</span> <span class="fu">normal2</span>(datos, <span class="at">a =</span> <span class="dv">2</span>, <span class="at">b =</span> <span class="dv">5</span>, </span>
<span id="cb68-27"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-27" aria-hidden="true" tabindex="-1"></a>                    <span class="at">nsim =</span> <span class="dv">1000</span>, <span class="at">inicial =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb68-28"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-28" aria-hidden="true" tabindex="-1"></a>mc1.vals <span class="ot">&lt;-</span> mc1.vals[<span class="dv">101</span><span class="sc">:</span> <span class="dv">1000</span>, ]</span>
<span id="cb68-29"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb68-29" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(mc1.vals)</span></code></pre></div>
<pre><code>## [1] 4.909503 3.813988</code></pre>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb70-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mc1.vals[, <span class="dv">1</span>], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;mu&#39;</span>)</span>
<span id="cb70-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mc1.vals[, <span class="dv">2</span>], <span class="at">type =</span> <span class="st">&#39;l&#39;</span>, <span class="at">ylab =</span> <span class="st">&#39;sigma^2&#39;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-18"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-18-1.png" alt="Cadenas generadas desde el muestreador de Gibbs." width="672" />
<p class="caption">
Figura C.9: Cadenas generadas desde el muestreador de Gibbs.
</p>
</div>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb71-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(mc1.vals[, <span class="dv">1</span>], <span class="at">prob =</span> T, <span class="at">xlab=</span><span class="st">&#39;mu&#39;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb71-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(mc1.vals[, <span class="dv">1</span>], <span class="at">kernel=</span><span class="st">&#39;gaussian&#39;</span>))</span>
<span id="cb71-4"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(mc1.vals[, <span class="dv">2</span>], <span class="at">prob =</span> T, <span class="at">xlab=</span><span class="st">&#39;sigma^2&#39;</span>, <span class="at">main =</span> <span class="st">&quot;&quot;</span>)</span>
<span id="cb71-5"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(mc1.vals[, <span class="dv">2</span>], <span class="at">kernel=</span><span class="st">&#39;gaussian&#39;</span>))</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-19"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-19-1.png" alt="Densidades posteriores generadas con el muestreador de Gibbs." width="672" />
<p class="caption">
Figura C.10: Densidades posteriores generadas con el muestreador de Gibbs.
</p>
</div>
</div>
<div id="el-algoritmo-de-metrópolis-hastings" class="section level3" number="6.2.2">
<h3><span class="header-section-number">C.2.2</span> El algoritmo de Metrópolis-Hastings</h3>
<p>Este algoritmo se basa en proponer un nuevo punto de acuerdo a una función de densidad adecuada y aceptar este nuevo valor propuesto con una probabilidad que depende del punto actual, del nuevo punto y de la densidad de la cual fue propuesto el nuevo punto.</p>
<p>Suponga que deseamos simular valores de una distribución multivariada <span class="math inline">\(p(\theta \mid y)\)</span>. Sea la función de densidad propuesta <span class="math inline">\(q(\theta, \theta&#39;)\)</span>, una función de densidad de probabilidad arbitraria que
describe la probabilidad de aceptación de <span class="math inline">\(\theta&#39;\)</span> a partir de la posición actual de <span class="math inline">\(\theta\)</span>. El algoritmo de Metropolis-Hastings está dado por los siguientes pasos:</p>
<ul>
<li>Siendo el valor actual <span class="math inline">\(\theta_i\)</span>, genere un valor candidato <span class="math inline">\(\theta&#39;\)</span> obtenido como una observación de la densidad <span class="math inline">\(q(\theta_i, \theta&#39;)\)</span>.</li>
<li>Calcule
<span class="math display">\[\begin{equation*}
T(\theta_i, \theta&#39;) =
\begin{cases}
\min \left(1,  \frac{p(\theta&#39; \mid  y)q(\theta&#39;, \theta_i)}{p(\theta_i \mid  y)q(\theta_i, \theta&#39;)} \right),
&amp; \text{  si   } p(\theta_i \mid  y)q(\theta_i, \theta&#39;) &gt; 0,\\ 
1, &amp; \text{  si   }
p(\theta_i \mid y)q(\theta_i, \theta&#39;) = 0
\end{cases}
\end{equation*}\]</span></li>
<li>Acepte el nuevo valor y actualícelo a <span class="math inline">\(\theta_{i+1}=\theta&#39;\)</span> con probabilidad <span class="math inline">\(T(\theta_i, \theta&#39;)\)</span>. De otra forma, rechazar el valor candidato y defina <span class="math inline">\(\theta_{i+1}=\theta_i\)</span>.
Repita el paso anterior para obtener la secuencia <span class="math inline">\(\theta_0,\theta_1,...,\)</span>
donde <span class="math inline">\(\theta_0\)</span> denota un valor arbitrario de arranque.
Descarte los primeros <span class="math inline">\(m\)</span> valores obtenidos.</li>
</ul>
<p>Siguiendo el anterior algoritmo, entonces se tiene que <span class="math inline">\(\theta_{m+1}, \theta_{m+2}, \ldots\)</span> es una secuencia (correlacionada) de la distribución requerida. En principio, puede ser usada cualquier densidad <span class="math inline">\(q\)</span>, pero si ésta es escogida ingenuamente, la eficiencia de la cadena puede ser muy pobre. La relación más importante entre el muestreados de Gibbs y el algorítmo de Metropolis-Hastings, está dada como un teorema en el libro de <span class="citation"><a href="#ref-Robert" role="doc-biblioref">Robert y Casella</a> (<a href="#ref-Robert" role="doc-biblioref">2009</a>pág. 296)</span>.</p>

<div class="proposition">
<span id="prp:unnamed-chunk-20" class="proposition"><strong>Resultado C.1  </strong></span>El muestreador de Gibbs es equivalente al algoritmo de Metropolis-Hastings, con la
probabilidad de aceptación igual a uno para todos los puntos propuestos.
</div>
<p><br></p>
<p>Lo anterior implica que la convergencia para ambos métodos no es la misma. Para cerrar la sección de cadenas de Markov vía Monte Carlo, es importante hacernos la siguiente pregunta: ¿Son independientes las muestras simuladas? En principio no se puede hablar de independencia, pues es claro que la observación <span class="math inline">\(\{i+1\}\)</span> depende de la observación <span class="math inline">\(\{i\}\)</span>. Dado que las observaciones resultantes
se encuentran en estricto orden de medición, podríamos utilizar algunos criterios como la función de auto-correlación (ACF) y la función de auto-correlación parcial (PACF), para conocer sobre la correlación entre observaciones.</p>
<p>Siguiendo con el ejemplo <a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#exm:GibbsN2">C.4</a> del apartado de Gibbs, se ha escogido usar como como distribuciones propuestas <span class="math inline">\(q\)</span> para la media y para la varianza, densidades normales centradas en el actual
parámetro, ambas con varianza igual a uno. Dadas las distribuciones propuestas, algunos valores de la varianza pueden ser negativos; aunque este no es un problema porque la distribución posterior le asignará el valor cero, por tanto este valor será rechazado con un probabilidad de uno.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(invgamma)</span>
<span id="cb72-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-3" aria-hidden="true" tabindex="-1"></a>met.hast <span class="ot">&lt;-</span> <span class="cf">function</span>(datos, a, b, iter, ini){</span>
<span id="cb72-4"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-4" aria-hidden="true" tabindex="-1"></a>  mu0 <span class="ot">&lt;-</span> ini[<span class="dv">1</span>] </span>
<span id="cb72-5"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-5" aria-hidden="true" tabindex="-1"></a>  var0 <span class="ot">&lt;-</span> ini[<span class="dv">2</span>]</span>
<span id="cb72-6"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-6" aria-hidden="true" tabindex="-1"></a>  resul <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> iter)</span>
<span id="cb72-7"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-7" aria-hidden="true" tabindex="-1"></a>  resul[<span class="dv">1</span>, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu0</span>
<span id="cb72-8"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-8" aria-hidden="true" tabindex="-1"></a>  resul[<span class="dv">1</span>, <span class="dv">2</span>] <span class="ot">&lt;-</span> var0</span>
<span id="cb72-9"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span> <span class="sc">:</span> iter){</span>
<span id="cb72-10"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-10" aria-hidden="true" tabindex="-1"></a>    mu.prop <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, mu0, <span class="dv">1</span>)</span>
<span id="cb72-11"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-11" aria-hidden="true" tabindex="-1"></a>    var.prop <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1</span>, var0, <span class="dv">1</span>)</span>
<span id="cb72-12"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (var.prop <span class="sc">&lt;=</span> <span class="dv">0</span>){ T.val <span class="ot">&lt;-</span> <span class="dv">0</span> }</span>
<span id="cb72-13"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>{</span>
<span id="cb72-14"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-14" aria-hidden="true" tabindex="-1"></a>      p1 <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(datos, mu.prop, <span class="fu">sqrt</span>(var.prop))) <span class="sc">*</span></span>
<span id="cb72-15"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-15" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dinvgamma</span>(var.prop, <span class="at">shape =</span> a, <span class="at">rate =</span> b)</span>
<span id="cb72-16"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-16" aria-hidden="true" tabindex="-1"></a>      q1 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(mu0, mu.prop, <span class="dv">1</span>) <span class="sc">*</span></span>
<span id="cb72-17"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-17" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(var0, var.prop, <span class="dv">1</span>)</span>
<span id="cb72-18"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-18" aria-hidden="true" tabindex="-1"></a>      p2 <span class="ot">&lt;-</span> <span class="fu">prod</span>(<span class="fu">dnorm</span>(datos, mu0, <span class="fu">sqrt</span>(var0))) <span class="sc">*</span> </span>
<span id="cb72-19"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-19" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dinvgamma</span>(var0, <span class="at">shape =</span> a, <span class="at">rate =</span> b)</span>
<span id="cb72-20"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-20" aria-hidden="true" tabindex="-1"></a>      q2 <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(mu.prop, mu0, <span class="dv">1</span>) <span class="sc">*</span> </span>
<span id="cb72-21"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-21" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(var.prop, var0, <span class="dv">1</span>)</span>
<span id="cb72-22"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-22" aria-hidden="true" tabindex="-1"></a>      T.val <span class="ot">&lt;-</span> <span class="fu">min</span>(<span class="dv">1</span>, (p1 <span class="sc">*</span> q1)<span class="sc">/</span>(p2 <span class="sc">*</span> q2))</span>
<span id="cb72-23"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-23" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb72-24"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-24" aria-hidden="true" tabindex="-1"></a>    u <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>) </span>
<span id="cb72-25"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (u <span class="sc">&lt;=</span> T.val){</span>
<span id="cb72-26"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-26" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu.prop</span>
<span id="cb72-27"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-27" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> var.prop</span>
<span id="cb72-28"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-28" aria-hidden="true" tabindex="-1"></a>      } </span>
<span id="cb72-29"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>{</span>
<span id="cb72-30"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-30" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">1</span>] <span class="ot">&lt;-</span> mu0</span>
<span id="cb72-31"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-31" aria-hidden="true" tabindex="-1"></a>      resul[i, <span class="dv">2</span>] <span class="ot">&lt;-</span> var0</span>
<span id="cb72-32"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-32" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb72-33"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-33" aria-hidden="true" tabindex="-1"></a>    mu0 <span class="ot">&lt;-</span> resul[i, <span class="dv">1</span>]</span>
<span id="cb72-34"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-34" aria-hidden="true" tabindex="-1"></a>    var0 <span class="ot">&lt;-</span> resul[i, <span class="dv">2</span>]</span>
<span id="cb72-35"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-35" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb72-36"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(resul)</span>
<span id="cb72-37"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-37" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb72-38"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-39"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-39" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb72-40"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-40" aria-hidden="true" tabindex="-1"></a>mc2 <span class="ot">&lt;-</span> <span class="fu">met.hast</span>(datos, <span class="at">a =</span> <span class="dv">2</span>, <span class="at">b =</span> <span class="dv">5</span>, </span>
<span id="cb72-41"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-41" aria-hidden="true" tabindex="-1"></a>                <span class="at">iter =</span> <span class="dv">1000</span>, <span class="at">ini =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb72-42"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb72-42" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(mc2)</span></code></pre></div>
<pre><code>## [1] 4.900618 4.486181</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb74-2"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(mc2[, <span class="dv">1</span>], <span class="dv">100</span>)</span>
<span id="cb74-3"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pacf</span>(mc2[, <span class="dv">2</span>], <span class="dv">100</span>)</span>
<span id="cb74-4"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(mc2[, <span class="dv">1</span>], <span class="dv">100</span>)</span>
<span id="cb74-5"><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(mc2[, <span class="dv">2</span>], <span class="dv">100</span>)</span></code></pre></div>
<div class="figure"><span id="fig:unnamed-chunk-22"></span>
<img src="A3Simulacion_files/figure-html/unnamed-chunk-22-1.png" alt="Autocorrelación y autocorrelación parcial para las cadenas simuladas del algoritmo MH." width="672" />
<p class="caption">
Figura C.11: Autocorrelación y autocorrelación parcial para las cadenas simuladas del algoritmo MH.
</p>
</div>
</div>
<div id="buenas-prácticas-en-la-aplicación-de-métodos-mcmc" class="section level3" number="6.2.3">
<h3><span class="header-section-number">C.2.3</span> Buenas prácticas en la aplicación de métodos MCMC</h3>
<p>Dado que una gran parte de la inferencia bayesiana está ligada a la programación e implementación de los métodos MCMC para realizar inferencias posteriores de los parámetros de interés, se sugiere seguir el razonamiento y recomendaciones de <span class="citation"><a href="#ref-GelShir2010" role="doc-biblioref">A. Gelman y Shirley</a> (<a href="#ref-GelShir2010" role="doc-biblioref">2010</a>)</span>, que puede ser resumido en los siguientes ítemes para cada parámetro de interés:</p>
<ol style="list-style-type: decimal">
<li>Simulación de tres o más cadenas de forma paralela. Los valores iniciales de cada cadena deben estar dispersos entre sí.</li>
<li>Comprobación de la convergencia de las cadenas mediante el descarte de la primera mitad de los valores generados en las cadenas. Esta etapa se conoce como <em>burning stage</em>.</li>
<li>Una vez que las cadenas converjan, mezclar los tres conjuntos de valores generados por las cadenas. Esto garantiza, en primera instancia, que las cadenas no estén auto-correlacionadas.</li>
<li>Además de realizar esta mezcla, descartar valores intermedios mediante un muestreo sistemático. Esta etapa se conoce como <em>thining stage</em>. Al final se recomienda almacenar una cantidad elevada de valores simulados.</li>
<li>Calibrar el algoritmo si la convergencia de las cadenas no se presenta rápidamente.
<ul>
<li>Para los algoritmos de Metropolis-Hastings, escoger una distribución de salto acorde con la distribución de la cual se desea simular. Por ejemplo, <span class="citation"><a href="#ref-Cepe1" role="doc-biblioref">Cepeda y Gamerman</a> (<a href="#ref-Cepe1" role="doc-biblioref">2001</a>)</span> presentan dos distribuciones de salto para el problema de la modelación de la varianza (cada una de las propuestas presenta tasas de aceptación diferentes).</li>
</ul></li>
<li>Comparación y contraste de los resultados con modelos simples que permitan examinar posibles discrepancias y corregir errores de programación.</li>
</ol>
<p>En términos de inferencia bayesiana, se tienen dos tipos de procesos: el primero y más común, que trata de realizar inferencias acerca de un vector de parámetros de interés <span class="math inline">\(\boldsymbol \theta\)</span>; el segundo trata con los momentos del parámetro, por ejemplo su esperanza. Nótese que el primer proceso se presenta con seguridad en ejercicios empíricos simulados; sin embargo, el segundo se presenta en los ejercicios prácticos con datos reales, en donde se quiere contrastar alguna hipótesis.</p>
<p>Las anteriores dos opciones tienen tratamientos muy diferentes en términos de la cantidad de simulaciones requeridas. Por ejemplo, si el objetivo es inferir acerca de <span class="math inline">\(\boldsymbol \theta\)</span>, para conocer su comportamiento estructural, basta con realizar una simulación que genere una cantidad mediana de valores y que se resumen en un promedio y una desviación estándar. Por otro lado, si el objetivo es inferir acerca de <span class="math inline">\(E(\boldsymbol \theta)\)</span>, se requieren muchas más simulaciones para obtener una buena precisión. Siguiendo a <span class="citation"><a href="#ref-GelShir2010" role="doc-biblioref">A. Gelman y Shirley</a> (<a href="#ref-GelShir2010" role="doc-biblioref">2010</a>)</span>, una vez terminado el proceso de <em>burning</em> y <em>thining</em>, se sugiere que se dividan los valores simulados en las cadenas paralelas y se formen <span class="math inline">\(k\)</span> grupos; de esta forma, una estimación de <span class="math inline">\(E(\boldsymbol \theta)\)</span> será la gran media de las medias muestrales de cada grupo y el error estándar será su desviación estándar dividida por <span class="math inline">\(\sqrt{k}\)</span>.</p>

</div>
</div>
<!-- </div> -->
<h3>Referencias</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Cepe1" class="csl-entry">
Cepeda, E., y D. Gamerman. 2001. <span>«Bayesian Modeling of Variance Heterogeneity in Normal Regression Models»</span>. <em>Brazilian Journal of Probability and Statistics</em> 14: 207-21.
</div>
<div id="ref-GelShir2010" class="csl-entry">
Gelman, A., y K Shirley. 2010. <span>«Handbook of Markov Chain Monte Carlo»</span>. En. CRC.
</div>
<div id="ref-Pena2002" class="csl-entry">
Peña, D. 2002. <em><span>Análisis de datos multivariantes</span></em>. <span>McGraw-Hill</span>.
</div>
<div id="ref-Robert" class="csl-entry">
———. 2009. <em>Introducing Monte Carlo Methods with R</em>. Springer.
</div>
</div>
<p style="text-align: center;">
<a href="C-1-métodos-directos.html"><button class="btn btn-default">Previous</button></a>
<a href="referencias.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
