<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="2.2 Pruebas de hipótesis | Modelos Bayesianos con R y STAN" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
<meta name="github-repo" content="psirusteam/bookdownBayesiano" />

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />

<meta name="date" content="2021-06-04" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN.">

<title>2.2 Pruebas de hipótesis | Modelos Bayesianos con R y STAN</title>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#prefacio">Prefacio</a></li>
<li><a href="antes-de-comenzar.html#antes-de-comenzar">Antes de comenzar</a>
<ul>
<li><a href="cuestionamientos-sobre-el-enfoque-bayesiano.html#cuestionamientos-sobre-el-enfoque-bayesiano">Cuestionamientos sobre el enfoque bayesiano</a></li>
<li><a href="acerca-de-la-notación.html#acerca-de-la-notación">Acerca de la notación</a></li>
</ul></li>
<li><a href="1-tópicos-básicos.html#tópicos-básicos"><span class="toc-section-number">1</span> Tópicos básicos</a>
<ul>
<li><a href="1-1-teoría-de-la-decisión.html#teoría-de-la-decisión"><span class="toc-section-number">1.1</span> Teoría de la decisión</a></li>
<li><a href="1-2-algunos-resultados-de-probabilidad.html#algunos-resultados-de-probabilidad"><span class="toc-section-number">1.2</span> Algunos resultados de probabilidad</a></li>
<li><a href="1-3-teorema-de-bayes.html#teorema-de-bayes"><span class="toc-section-number">1.3</span> Teorema de Bayes</a></li>
</ul></li>
<li><a href="2-inferencia-bayesiana.html#inferencia-bayesiana"><span class="toc-section-number">2</span> Inferencia bayesiana</a>
<ul>
<li><a href="2-1-la-distribución-previa.html#la-distribución-previa"><span class="toc-section-number">2.1</span> La distribución previa</a>
<ul>
<li><a href="2-1-la-distribución-previa.html#distribuciones-conjugadas"><span class="toc-section-number">2.1.1</span> Distribuciones conjugadas</a></li>
<li><a href="2-1-la-distribución-previa.html#familia-exponencial"><span class="toc-section-number">2.1.2</span> Familia exponencial</a></li>
<li><a href="2-1-la-distribución-previa.html#distribuciones-previas-no-informativas"><span class="toc-section-number">2.1.3</span> Distribuciones previas no informativas</a></li>
</ul></li>
<li><a href="2-2-pruebas-de-hipótesis.html#pruebas-de-hipótesis"><span class="toc-section-number">2.2</span> Pruebas de hipótesis</a>
<ul>
<li><a href="2-2-pruebas-de-hipótesis.html#factor-de-bayes"><span class="toc-section-number">2.2.1</span> Factor de Bayes</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#valor-p-bayesiano"><span class="toc-section-number">2.2.2</span> Valor-<span class="math inline">\(p\)</span> Bayesiano</a></li>
</ul></li>
<li><a href="2-3-criterios-de-información.html#criterios-de-información"><span class="toc-section-number">2.3</span> Criterios de información</a>
<ul>
<li><a href="2-3-criterios-de-información.html#criterio-dic"><span class="toc-section-number">2.3.1</span> Criterio DIC</a></li>
<li><a href="2-3-criterios-de-información.html#criterios-aic-y-bic"><span class="toc-section-number">2.3.2</span> Criterios AIC y BIC</a></li>
</ul></li>
</ul></li>
<li><a href="3-modelos-uniparamétricos.html#modelos-uniparamétricos"><span class="toc-section-number">3</span> Modelos uniparamétricos</a>
<ul>
<li><a href="3-1-modelo-bernoulli.html#modelo-bernoulli"><span class="toc-section-number">3.1</span> Modelo Bernoulli</a></li>
<li><a href="3-2-modelo-binomial.html#modelo-binomial"><span class="toc-section-number">3.2</span> Modelo Binomial</a></li>
</ul></li>
<li class="appendix"><span><b>Apéndice</b></span></li>
<li><a href="A-elementos-de-probabilidad.html#elementos-de-probabilidad"><span class="toc-section-number">A</span> Elementos de probabilidad</a>
<ul>
<li><a href="A-1-distribuciones-discretas.html#distribuciones-discretas"><span class="toc-section-number">A.1</span> Distribuciones discretas</a>
<ul>
<li><a href="A-1-distribuciones-discretas.html#distribución-uniforme-discreta"><span class="toc-section-number">A.1.1</span> Distribución uniforme discreta</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-hipergeométrica"><span class="toc-section-number">A.1.2</span> Distribución hipergeométrica</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-bernoulli"><span class="toc-section-number">A.1.3</span> Distribución Bernoulli</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-binomial"><span class="toc-section-number">A.1.4</span> Distribución binomial</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-binomial-negativa"><span class="toc-section-number">A.1.5</span> Distribución Binomial negativa</a></li>
<li><a href="A-1-distribuciones-discretas.html#distribución-de-poisson"><span class="toc-section-number">A.1.6</span> Distribución de Poisson</a></li>
</ul></li>
<li><a href="A-2-distribuciones-continuas.html#distribuciones-continuas"><span class="toc-section-number">A.2</span> Distribuciones continuas</a>
<ul>
<li><a href="A-2-distribuciones-continuas.html#distribución-uniforme-continua"><span class="toc-section-number">A.2.1</span> Distribución Uniforme Continua</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-weibull"><span class="toc-section-number">A.2.2</span> Distribución Weibull</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-valor-extremo"><span class="toc-section-number">A.2.3</span> Distribución valor-extremo</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-gamma"><span class="toc-section-number">A.2.4</span> Distribución Gamma</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-gamma-inversa"><span class="toc-section-number">A.2.5</span> Distribución Gamma-inversa</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-exponencial"><span class="toc-section-number">A.2.6</span> Distribución exponencial</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-beta"><span class="toc-section-number">A.2.7</span> Distribución Beta</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-normal"><span class="toc-section-number">A.2.8</span> Distribución normal</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-log-normal"><span class="toc-section-number">A.2.9</span> Distribución log-normal</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-ji-cuadrado"><span class="toc-section-number">A.2.10</span> Distribución Ji-cuadrado</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-t-student"><span class="toc-section-number">A.2.11</span> Distribución t-student</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-t-student-generalizada"><span class="toc-section-number">A.2.12</span> Distribución t-student generalizada</a></li>
<li><a href="A-2-distribuciones-continuas.html#distribución-f"><span class="toc-section-number">A.2.13</span> Distribución F</a></li>
</ul></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribuciones-multivariadas"><span class="toc-section-number">A.3</span> Distribuciones multivariadas</a>
<ul>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-multinomial"><span class="toc-section-number">A.3.1</span> Distribución Multinomial</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-dirichelt"><span class="toc-section-number">A.3.2</span> Distribución Dirichelt</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-normal-multivariante"><span class="toc-section-number">A.3.3</span> Distribución Normal Multivariante</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-wishart"><span class="toc-section-number">A.3.4</span> Distribución Wishart</a></li>
<li><a href="A-3-distribuciones-multivariadas.html#distribución-inversa-wishart"><span class="toc-section-number">A.3.5</span> Distribución inversa-Wishart</a></li>
</ul></li>
</ul></li>
<li><a href="B-matriz-de-información.html#matriz-de-información"><span class="toc-section-number">B</span> Matriz de información</a></li>
<li><a href="C-elementos-de-simulación-estadística.html#elementos-de-simulación-estadística"><span class="toc-section-number">C</span> Elementos de simulación estadística</a>
<ul>
<li><a href="C-1-métodos-directos.html#métodos-directos"><span class="toc-section-number">C.1</span> Métodos directos</a>
<ul>
<li><a href="C-1-métodos-directos.html#método-de-la-transformación-uniforme"><span class="toc-section-number">C.1.1</span> Método de la transformación uniforme</a></li>
<li><a href="C-1-métodos-directos.html#método-de-la-grilla"><span class="toc-section-number">C.1.2</span> Método de la grilla</a></li>
</ul></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#métodos-de-monte-carlo-vía-cadenas-de-markov"><span class="toc-section-number">C.2</span> Métodos de Monte Carlo vía cadenas de Markov</a>
<ul>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-muestreador-de-gibbs"><span class="toc-section-number">C.2.1</span> El muestreador de Gibbs</a></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#el-algoritmo-de-metrópolis-hastings"><span class="toc-section-number">C.2.2</span> El algoritmo de Metrópolis-Hastings</a></li>
<li><a href="C-2-métodos-de-monte-carlo-vía-cadenas-de-markov.html#buenas-prácticas-en-la-aplicación-de-métodos-mcmc"><span class="toc-section-number">C.2.3</span> Buenas prácticas en la aplicación de métodos MCMC</a></li>
</ul></li>
</ul></li>
<li><a href="referencias.html#referencias">Referencias</a></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="pruebas-de-hipótesis" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Pruebas de hipótesis</h2>
<p>A excepción del juzgamiento de hipótesis, las inferencias que hacen los
estadísticos bayesianos, acerca de poblaciones normales, son muy
similares a las que los estadísticos de la tradición frecuentista, de
Neyman y Pearson, hacen. Consideremos la siguiente situación.</p>
<blockquote>
<p>Un instrumento mide la posición de un objeto con un determinado error. Éste
error está distribuido de manera uniforme en el intervalo (-1cm, 1cm).
Supongamos que el instrumento midió la posición de un objeto en
+0.9999cm del origen. Planteamos la siguiente hipótesis nula, <strong>H: La
posición real del objeto es exactamente el origen</strong>.</p>
</blockquote>
<p>Imagine que planteamos este problema de inferencia estadística a dos estadísticos, uno frecuentista clásico y el otro acérrimo bayesiano.</p>
<ul>
<li><em>Razonamiento del frecuentista</em>: si la hipótesis nula es verdadera, ha ocurrido un
evento con una probabilidad (a dos colas) de ocurrencia de 0.0001 o
menos. Mediante un criterio razonable (nivel de significación), este es
un evento muy raro y por lo tanto rechaza la hipótesis nula.</li>
<li><em>Razonamiento del bayesiano</em>: dada una
observación, la verosimilitud asociada con la posición del objeto en el
intervalo -0.0001 y +1.9999 es la misma, 0.5. Fuera de esos límites la
verosimilitud es nula. Ahora, el origen está dentro de la región en
donde la verosimilitud es máxima; por lo tanto sea cual sea la
distribución a previa asociada al parámetro de posición, la distribución
posterior tomara el valor cero en cualquier lugar fuera del intervalo
-0.0001 y +1.9999. Así, con la observación disponible, no hay evidencia
para el rechazo de la hipótesis nula.</li>
</ul>
<p>Bajo esta paradoja, <span class="citation"><a href="#ref-Brewer2002" role="doc-biblioref">Brewer</a> (<a href="#ref-Brewer2002" role="doc-biblioref">2002</a>)</span> sugiere que
ambos estadísticos tienen razón, pero a la vez están equivocados. El
frecuentista tiene razón en afirmar que, con la evidencia disponible, ha
ocurrido un evento extraordinariamente extraño o que la hipótesis nula
es falsa. El bayesiano tiene razón en argumentar que, en términos de la
situación, no hay evidencia en contra de la hipótesis nula. Esta
paradoja se presenta porque los bayesianos tienden a trabajar dentro de
la situación que ellos creen que existe y la lógica bayesiana se mueve en ese marco de
referencia. Los bayesianos hacen las inferencias en términos de la
verosimilitud de los eventos observados, mientras que los frecuentistas
hacen inferencias en términos de eventos que ni siquiera han ocurrido. .</p>
<div id="factor-de-bayes" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Factor de Bayes</h3>
<p>El juzgamiento de hipótesis del enfoque frecuentista se puede efectuar
en el ámbito Bayesiano por medio del contraste entre dos modelos. Suponiendo
que existen dos modelos <span class="math inline">\(M1\)</span> y <span class="math inline">\(M2\)</span> candidatos para <span class="math inline">\(\mathbf{Y}\)</span>, se
define el <em>Factor de Bayes</em> en favor del modelo <span class="math inline">\(M1\)</span> como la razón
de las densidades marginales de los datos para los dos modelos. Es
posible demostrar que este factor es equivalente a la siguiente expresión:</p>
<p><span class="math display" id="eq:FB">\[\begin{equation}
\tag{2.5}
FB=\frac{p(\mathbf{Y} \mid M1)}{p(\mathbf{Y} \mid M2)}=\frac{Pr(M1 \mid \mathbf{Y})/Pr(M2 \mid \mathbf{Y})}{Pr(M1)/Pr(M2)}
\end{equation}\]</span></p>
<p>Para evaluar esta última expresión es necesario recurrir a la densidad
previa y posterior del parámetro de interés, asumiendo que los modelos
están parametrizados por éstos. Se puede ver que cuando los modelos <span class="math inline">\(M1\)</span>
y <span class="math inline">\(M2\)</span> tienen la misma distribución previa, entonces el factor de Bayes
se reduce a la razón de densidad posterior de los dos modelos.
Adicionalmente este factor sólo está definido cuando la integral de la
densidad marginal de <span class="math inline">\(\mathbf{Y}\)</span> bajo cada modelo converge. En la
expresión <a href="2-2-pruebas-de-hipótesis.html#eq:FB">(2.5)</a> se claro que valores grandes del factor muestran
evidencia a favor del modelo <span class="math inline">\(M1\)</span>; valores menores de 1, a favor del
modelo <span class="math inline">\(M2\)</span>; mientras que valores cercanos a 1 no muestran evidencias
claras hacia ninguno de los dos modelos.</p>
<p>En <span class="citation"><a href="#ref-Gelman95" role="doc-biblioref">A. Gelman et al.</a> (<a href="#ref-Gelman95" role="doc-biblioref">1995</a>)</span> se presenta el siguiente ejemplo sencillo sobre la
presencia o ausencia de la enfermedad de la hemofilia, una enfermedad genética
especialmente grave en las mujeres. Para una mujer quien tiene un hermano
portador del gen, el parámetro <span class="math inline">\(\theta\)</span> describe la presencia o ausencia
del gen en ella, y toma valores de 1 (presencia del gen) y 0 (ausencia
del gen). La distribución previa del parámetro es
<span class="math inline">\(Pr(\theta=1)=Pr(\theta=0)=0.5\)</span>. El objetivo es evaluar el sistema
<span class="math inline">\(M_1:\ \theta=1\)</span> y <span class="math inline">\(M_2:\ \theta=0\)</span>, con base en el hecho de que ella
tiene dos hijos ambos no portadores del gen. De esta forma, el factor de Bayes se expresa como:</p>
<p><span class="math display">\[\begin{equation*}
FB=\frac{p(y_1=0,\ y_2=0|\theta=1)}{p(y_1=0,\ y_2=0|\theta=0)}=\frac{0.25}{1}=0.25
\end{equation*}\]</span> De donde se evidencia mayor apoyo a la hipótesis
<span class="math inline">\(\theta=0\)</span>.</p>
</div>
<div id="valor-p-bayesiano" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Valor-<span class="math inline">\(p\)</span> Bayesiano</h3>
<p>En la inferencia clásica, se define el valor-<span class="math inline">\(p\)</span> como la probabilidad de
que la estadística de prueba tome valores más extremos a los observados,
y se compara con el nivel de significancia, previamente establecido,
para tomar una decisión acerca de la hipótesis nula. En el ámbito
Bayesiano, el valor-<span class="math inline">\(p\)</span> se define como la probabilidad de que la
estadística de prueba <span class="math inline">\(T\)</span> calculada sobre los datos replicados <span class="math inline">\(y^{rep}\)</span>
sean más extremos al observado, y la probabilidad se toma sobre la
distribución posterior del parámetro <span class="math inline">\(\theta\)</span> y la distribución
predictiva posterior de <span class="math inline">\(y^{rep}\)</span>. Específicamente, queda determinado
por la siguiente expresión:</p>
<p><span class="math display">\[\begin{equation*}
p_B=\int\int_{T(y^{rep}) \geq T(y)}p(y^{rep}|\theta)p(\theta|y)dy^{rep}d\theta
\end{equation*}\]</span></p>
<p>A diferencia del valor-<span class="math inline">\(p\)</span> clásico, donde solo valores pequeños muestran
evidencia en contra de la hipótesis nula, un valor-<span class="math inline">\(p\)</span> Bayesiano extremo
(menor a 0.01 o mayor a 0.99) sugiere que los valores observados
difícilmente pueden ser replicados si el modelo fuera verdadero.</p>
</div>
</div>
<h3>Referencias</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Brewer2002" class="csl-entry">
Brewer, K. R. W. 2002. <em>Combined Survey Sampling Inference: Weighing Basu’s Elephants</em>. A Hodder Arnold Publication. Arnold.
</div>
<div id="ref-Gelman95" class="csl-entry">
Gelman, A., J. B. Carlin, H. S. Stern, y D. B. Rubin. 1995. <em>Bayesian Data Analysis</em>. 1.ª ed. Chapman; Hall/CRC.
</div>
</div>
<p style="text-align: center;">
<a href="2-1-la-distribución-previa.html"><button class="btn btn-default">Previous</button></a>
<a href="2-3-criterios-de-información.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
