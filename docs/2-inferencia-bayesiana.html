<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="Capítulo 2 Inferencia bayesiana | Modelos Bayesianos con R y STAN" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
<meta name="github-repo" content="psirusteam/bookdownBayesiano" />

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />

<meta name="date" content="2021-05-30" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN.">

<title>Capítulo 2 Inferencia bayesiana | Modelos Bayesianos con R y STAN</title>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<link href="libs/tufte-css-2015.12.29/tufte-fonts.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-background.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte-italics.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />





</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#prefacio">Prefacio</a></li>
<li><a href="1-tópicos-básicos.html#tópicos-básicos"><span class="toc-section-number">1</span> Tópicos básicos</a>
<ul>
<li><a href="1-1-teoría-de-la-decisión.html#teoría-de-la-decisión"><span class="toc-section-number">1.1</span> Teoría de la decisión</a></li>
<li><a href="1-2-algunos-resultados-de-probabilidad.html#algunos-resultados-de-probabilidad"><span class="toc-section-number">1.2</span> Algunos resultados de probabilidad</a></li>
<li><a href="1-3-teorema-de-bayes.html#teorema-de-bayes"><span class="toc-section-number">1.3</span> Teorema de Bayes</a></li>
</ul></li>
<li><a href="2-inferencia-bayesiana.html#inferencia-bayesiana"><span class="toc-section-number">2</span> Inferencia bayesiana</a>
<ul>
<li><a href="2-1-información-previa.html#información-previa"><span class="toc-section-number">2.1</span> Información previa</a>
<ul>
<li><a href="2-1-información-previa.html#distribuciones-conjugadas"><span class="toc-section-number">2.1.1</span> Distribuciones conjugadas</a></li>
<li><a href="2-1-información-previa.html#familia-exponencial"><span class="toc-section-number">2.1.2</span> Familia exponencial</a></li>
<li><a href="2-1-información-previa.html#distribuciones-previas-no-informativas"><span class="toc-section-number">2.1.3</span> Distribuciones previas no informativas</a></li>
</ul></li>
<li><a href="2-2-pruebas-de-hipótesis.html#pruebas-de-hipótesis"><span class="toc-section-number">2.2</span> Pruebas de hipótesis</a>
<ul>
<li><a href="2-2-pruebas-de-hipótesis.html#factor-de-bayes"><span class="toc-section-number">2.2.1</span> Factor de Bayes</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#valor-p-bayesiano"><span class="toc-section-number">2.2.2</span> Valor <span class="math inline">\(p\)</span> Bayesiano</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#criterio-dic"><span class="toc-section-number">2.2.3</span> Criterio DIC</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#criterio-aic-y-bic"><span class="toc-section-number">2.2.4</span> Criterio AIC y BIC</a></li>
<li><a href="2-2-pruebas-de-hipótesis.html#acerca-de-la-notación"><span class="toc-section-number">2.2.5</span> Acerca de la notación</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="inferencia-bayesiana" class="section level1" number="2">
<h1><span class="header-section-number">Capítulo 2</span> Inferencia bayesiana</h1>
<p>El enfoque bayesiano, además de especificar un modelo para los datos
observados <span class="math inline">\(\mathbf{Y}=(y_1,\ldots,y_n)\)</span> dado un vector de parámetros
desconocidos <span class="math inline">\(\boldsymbol \theta=(\theta_1,\ldots,\theta_K)\)</span>, usualmente en forma
de densidad condicional <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span>, supone que
<span class="math inline">\(\boldsymbol \theta\)</span> es aleatorio y que tiene un densidad <em>previa</em>
<span class="math inline">\(p(\boldsymbol \theta\mid \boldsymbol \eta)\)</span>, donde <span class="math inline">\(\boldsymbol \eta\)</span> es un vector de hiper-parámetros.
De esta forma, la inferencia concerniente a <span class="math inline">\(\boldsymbol \theta\)</span> se basa en una
densidad <em>posterior</em> <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span>.</p>
<p>En términos de estimación, inferencia y predicción, el enfoque Bayesiano
supone dos momentos o etapas:</p>
<ol style="list-style-type: decimal">
<li><p>Antes de la recolección de las datos, en donde el investigador propone,
basado en su conocimiento, experiencia o fuentes externas, una
distribución de probabilidad <em>previa</em> para el parámetro de interés.
Con esta distribución es posible calcular estimaciones puntuales y por
intervalo con el fin de confirmar que la distribución propuesta se
ajusta al problema de estudio. En esta etapa, basados en la distribución
<em>previa</em>, también es posible hacer predicciones de cantidades
observables.</p></li>
<li><p>Después de la recolección de los datos. Siguiendo el teorema de Bayes,
el investigador actualiza su conocimiento acerca del comportamiento
probabilístico del parámetro de interés mediante la distribución
<em>posterior</em> de este. Con esta distribución es posible calcular
estimaciones puntuales y por intervalo justo como en el enfoque
frecuentista. En esta etapa, basados en la distribución
<em>posterior</em>, también es posible hacer predicciones de cantidades
observables y pruebas de hipótesis acerca de la adecuación del mejor
modelo a los datos observados.</p></li>
</ol>
<div id="inferencia-previa" class="section level4 unnumbered">
<h4>Inferencia previa</h4>
<p>Con las anteriores expresiones es posible calcular la probabilidad
<em>previa</em> de que <span class="math inline">\(\boldsymbol \theta\)</span> esté en una determinada región <span class="math inline">\(G\)</span> como
<span class="math display">\[\begin{equation}
Pr(\boldsymbol \theta\in G)=\int_G p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>En esta primera etapa también es posible calcular, con fines
confirmatorios <span class="citation">(<label for="tufte-mn-2" class="margin-toggle">&#8853;</label><input type="checkbox" id="tufte-mn-2" class="margin-toggle">Carlin y Louis 1996<span class="marginnote">Carlin, B. P., y T. A. Louis. 1996. <em>Bayes and Empirical Bayes for Data Analysis</em>. 1.ª ed. Chapman; Hall/CRC.</span>)</span>, la estimación puntual para el vector
<span class="math inline">\(\boldsymbol \theta\)</span> dada por alguna medida de tendencia central para la
distribución <span class="math inline">\(p(\boldsymbol \theta\mid \boldsymbol \eta)\)</span>. En particular, si se escoge la
media, entonces <span class="math display">\[\begin{equation}\label{est.prio}
\hat{\boldsymbol \theta}=E(\boldsymbol \theta)=\int \boldsymbol \theta\ p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>También es posible calcular una región <span class="math inline">\(C\)</span> de <span class="math inline">\(100\times(1-\alpha)%\)</span> de
credibilidad<label for="tufte-sn-3" class="margin-toggle sidenote-number">3</label><input type="checkbox" id="tufte-sn-3" class="margin-toggle"><span class="sidenote"><span class="sidenote-number">3</span> La interpretación de las regiones de credibilidad
bayesianas difiere de la interpretación de las regiones de confianza
frecuentistas. La primera se refiere a la probabilidad de que el
verdadero valor de <span class="math inline">\(\boldsymbol \theta\)</span> esté en la región. La segunda se refiere a
la región de la distribución muestral para <span class="math inline">\(\boldsymbol \theta\)</span> tal que, dados los
datos observados, se podría esperar que el <span class="math inline">\(100\times\alpha%\)</span> de las
futuras estimaciones de <span class="math inline">\(\boldsymbol \theta\)</span> no pertenecieran a dicha región.</span> para
<span class="math inline">\(\boldsymbol \theta\)</span> que en esta primera etapa es tal que <span class="math display">\[\begin{equation}
1-\alpha \leq Pr(\boldsymbol \theta\in C)=\int_Cp(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
</div>
<div id="inferencia-posterior" class="section level4 unnumbered">
<h4>Inferencia posterior</h4>
<p>Una vez recolectados los datos, se actualizan las cálculos descritos en
la sección anterior. Podemos calcular la probabilidad <em>posterior</em>
de que <span class="math inline">\(\boldsymbol \theta\)</span> esté en la región <span class="math inline">\(G\)</span> dados los datos observados como
<span class="math display">\[\begin{equation}
Pr(\boldsymbol \theta\in G  \mid \mathbf{Y})=\int_G p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>También es posible calcular la estimación puntual para el vector
<span class="math inline">\(\boldsymbol \theta\)</span> dados los datos observados. Ésta está dada por alguna medida
de tendencia central para la distribución <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span>.
En particular, si se escoge la media, entonces <span class="math display">\[\begin{equation}
\hat{\boldsymbol \theta}=E(\boldsymbol \theta\mid \mathbf{Y})=\int \boldsymbol \theta\ p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>La región <span class="math inline">\(C\)</span> de <span class="math inline">\(100\times(1-\alpha)%\)</span> de credibilidad es tal que
<span class="math display">\[\begin{equation}
1-\alpha \leq Pr(\boldsymbol \theta\in C \mid \mathbf{Y})=\int_Cp(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>También la distribución posterior del parámetro <span class="math inline">\(\boldsymbol \theta\)</span> es útil para
el procedimiento de juzgamiento de hipótesis en el ámbito del análisis
bayesiano. Esto se lleva a cabo por medio del factor de Bayes que se
presentará más adelante.</p>
</div>
<div id="inferencia-predictiva" class="section level4 unnumbered">
<h4>Inferencia predictiva</h4>
<p>En términos de inferencia predictiva existen dos etapas que cubren las
&lt;<actuales>&gt; suposiciones acerca del vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span>.
En una primera etapa - antes de la observación de los datos - la
suposición &lt;<actual>&gt; de <span class="math inline">\(\boldsymbol \theta\)</span> está dada por la densidad
<em>previa</em> <span class="math inline">\(p(\boldsymbol \theta\mid \boldsymbol \eta)\)</span>. En estos términos, utilizando el
Resultado , la distribución predictiva <em>previa</em> de
<span class="math inline">\(\mathbf{Y}\)</span> está dada por <span class="math display">\[\begin{equation}
p(\mathbf{y})=\int p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>La segunda etapa - después de la recolección de los datos - actualiza
las suposiciones acerca de <span class="math inline">\(\boldsymbol \theta\)</span> puesto que ahora éste sigue una
distribución <em>posterior</em> dada por (). Por lo tanto, la
distribución predictiva <em>posterior</em> de <span class="math inline">\(\mathbf{Y}\)</span> está dada por
<span class="math display">\[\begin{align}\label{predictpos}
p(\tilde{\mathbf{y}} \mid \mathbf{Y})&amp;=\int p(\tilde{\mathbf{y}},\boldsymbol \theta\mid \mathbf{y})\ d\boldsymbol \theta\notag \\
&amp;=\int p(\tilde{\mathbf{y}} \mid \boldsymbol \theta,\mathbf{Y})p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta\notag \\
&amp;=\int p(\tilde{\mathbf{y}} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{align}\]</span> donde <span class="math inline">\(p(\tilde{\mathbf{y}} \mid \boldsymbol \theta)\)</span> es la
distribución de los datos evaluada en los nuevos valores
<span class="math inline">\(\tilde{\mathbf{y}}\)</span>. La segunda línea de la anterior igualdad se
obtiene utilizando el resultado  y la última línea se
obtiene del resultado  de la independencia condicional.</p>
</div>
</div>
<p style="text-align: center;">
<a href="1-3-teorema-de-bayes.html"><button class="btn btn-default">Previous</button></a>
<a href="2-1-información-previa.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>



</body>
</html>
