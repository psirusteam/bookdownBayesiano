<!DOCTYPE html>
<html lang="es-CO" xml:lang="es-CO">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 3 Algunos resultados de probabilidad | Modelos Bayesianos con R y STAN</title>
  <meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 3 Algunos resultados de probabilidad | Modelos Bayesianos con R y STAN" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="github-repo" content="psirusteam/bookdownBayesiano" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 3 Algunos resultados de probabilidad | Modelos Bayesianos con R y STAN" />
  
  <meta name="twitter:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />


<meta name="date" content="2021-05-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="tópicos-básicos.html"/>

<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Bayesianos con R y STAN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prefacio</a></li>
<li class="chapter" data-level="2" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html"><i class="fa fa-check"></i><b>2</b> Tópicos básicos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html#teoría-de-la-decisión"><i class="fa fa-check"></i><b>2.1</b> Teoría de la decisión</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html"><i class="fa fa-check"></i><b>3</b> Algunos resultados de probabilidad</a>
<ul>
<li class="chapter" data-level="3.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#teorema-de-bayes"><i class="fa fa-check"></i><b>3.1</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="3.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia-bayesiana"><i class="fa fa-check"></i><b>3.2</b> Inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia"><i class="fa fa-check"></i><b>3.2.1</b> Inferencia </a></li>
<li class="chapter" data-level="3.2.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia-1"><i class="fa fa-check"></i><b>3.2.2</b> Inferencia </a></li>
<li class="chapter" data-level="3.2.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia-predictiva"><i class="fa fa-check"></i><b>3.2.3</b> Inferencia predictiva</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#información"><i class="fa fa-check"></i><b>3.3</b> Información </a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>3.3.1</b> Distribuciones conjugadas</a></li>
<li class="chapter" data-level="3.3.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#familia-exponencial"><i class="fa fa-check"></i><b>3.3.2</b> Familia exponencial</a></li>
<li class="chapter" data-level="3.3.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#distribuciones-no-informativas"><i class="fa fa-check"></i><b>3.3.3</b> Distribuciones  no informativas</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#pruebas-de-hipótesis"><i class="fa fa-check"></i><b>3.4</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#factor-de-bayes"><i class="fa fa-check"></i><b>3.4.1</b> Factor de Bayes</a></li>
<li class="chapter" data-level="3.4.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#valor-p-bayesiano"><i class="fa fa-check"></i><b>3.4.2</b> Valor <span class="math inline">\(p\)</span> Bayesiano</a></li>
<li class="chapter" data-level="3.4.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#criterio-dic"><i class="fa fa-check"></i><b>3.4.3</b> Criterio DIC</a></li>
<li class="chapter" data-level="3.4.4" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#criterio-aic-y-bic"><i class="fa fa-check"></i><b>3.4.4</b> Criterio AIC y BIC</a></li>
<li class="chapter" data-level="3.4.5" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#acerca-de-la-notación"><i class="fa fa-check"></i><b>3.4.5</b> Acerca de la notación</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a Modelos Bayesianos con R y STAN</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Bayesianos con R y STAN</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="algunos-resultados-de-probabilidad" class="section level1" number="3">
<h1><span class="header-section-number">Capítulo 3</span> Algunos resultados de probabilidad</h1>
<p>A continuación se presentan definiciones y resultados de probabilidad en términos de notación se utilizará indistintamente la expresión de integral, <span class="math inline">\(\int\)</span>, que implicará la integral, en el caso de las variables aleatorias continuas, o la sumatoria, en el caso de las variables aleatorias discretas.</p>

<div class="definition">
<span id="def:unnamed-chunk-4" class="definition"><strong>Definition 3.1  </strong></span>Sean <span class="math inline">\(\mathbf{X}=(X_1,\ldots,X_p)&#39;\)</span>, <span class="math inline">\(\mathbf{Y}=(Y_1,\ldots,Y_q)&#39;\)</span> dos vectores aleatorios definidos sobre los espacios de muestreo <span class="math inline">\(\mathcal{X}\)</span>, <span class="math inline">\(\mathcal{Y}\)</span>, respectivamente. Suponga que la distribución conjunta de estos vectores aleatorios está dada por <span class="math inline">\(p(\mathbf{X},\mathbf{Y})\)</span>. La distribución marginal de <span class="math inline">\(\mathbf{X}\)</span> está dada por
<span class="math display">\[\begin{equation}
p(\mathbf{X})=\int p(\mathbf{X},\mathbf{Y})\ d\mathbf{Y}
\end{equation}\]</span>
y la distribución condicional de <span class="math inline">\(\mathbf{X}\)</span> dado <span class="math inline">\(\mathbf{Y}\)</span> como
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Y})
=\frac{p(\mathbf{X},\mathbf{Y})}{p(\mathbf{Y})}
\end{equation}\]</span>
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-5" class="proposition"><strong>Proposición 3.1  </strong></span>Suponga los vectores <span class="math inline">\(\mathbf{X}\)</span>, <span class="math inline">\(\mathbf{Y}\)</span> y un tercer vector <span class="math inline">\(\mathbf{Z}=(Z_1,\ldots,Z_r)&#39;\)</span> definido sobre el espacio de muestreo <span class="math inline">\(\mathcal{Z}\)</span>. Entonces se tiene que
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Z})=\int p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})\ d\mathbf{Y}
\end{equation}\]</span>
y
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}
\end{equation}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> En primer lugar, nótese que
<span class="math display">\[\begin{align*}
\int p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})\ d\mathbf{Y}&amp;=
\int \frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}\ d\mathbf{Y}\\
&amp;=\frac{1}{p(\mathbf{Z})} \int p(\mathbf{X},\mathbf{Y},\mathbf{Z}) \ d\mathbf{Y}\\
&amp;=\frac{1}{p(\mathbf{Z})} p(\mathbf{X},\mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})
\end{align*}\]</span></p>
<p>Por otro lado,</p>
<span class="math display">\[\begin{align*}
\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}=
\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})} \diagup
\frac{p(\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}
=\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}=p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})
\end{align*}\]</span>
</div>

<div class="definition">
<span id="def:unnamed-chunk-7" class="definition"><strong>Definition 3.2  </strong></span>Sean <span class="math inline">\(\mathbf{X}\)</span>, <span class="math inline">\(\mathbf{Y}\)</span>, <span class="math inline">\(\mathbf{Z}\)</span> vectores aleatorios, se dice que <span class="math inline">\(\mathbf{X}\)</span> es condicionalmente independiente de <span class="math inline">\(\mathbf{Y}\)</span> con respecto a <span class="math inline">\(\mathbf{Z}\)</span> si satisfacen la siguiente expresión
<span class="math display">\[\begin{equation}
p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})
\end{equation}\]</span>
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-8" class="proposition"><strong>Proposición 3.2  </strong></span>Si <span class="math inline">\(\mathbf{X}\)</span> es condicionalmente independiente de <span class="math inline">\(\mathbf{Y}\)</span> con respecto a <span class="math inline">\(\mathbf{Z}\)</span>, entonces se tiene que
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})
\end{equation}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Como <span class="math inline">\(p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})=\dfrac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}\)</span>, entonces</p>
<span class="math display">\[\begin{align*}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}
=\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})p(\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}
=\frac{p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}=p(\mathbf{X} \mid \mathbf{Z})
\end{align*}\]</span>
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-10" class="proposition"><strong>Proposición 3.3  </strong></span>Si <span class="math inline">\(\mathbf{X}\)</span> es independiente de <span class="math inline">\(\mathbf{Y}\)</span>, entonces <span class="math inline">\(\mathbf{X}\)</span> es condicionalmente independiente de <span class="math inline">\(\mathbf{Y}\)</span> dada cualquier otro vector, digamos <span class="math inline">\(\mathbf{Z}\)</span>.
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Nótese que
<span class="math display">\[\begin{equation*}
p(\mathbf{X},\mathbf{Y}\mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})
\end{equation*}\]</span></p>
puesto que, utilizando la hipótesis de independencia, se tiene que
<span class="math display">\[\begin{equation*}
p(\mathbf{X} \mid \mathbf{Y})=p(\mathbf{X})
\end{equation*}\]</span>
</div>
<div id="teorema-de-bayes" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Teorema de Bayes</h2>
<p>Desde la revolución estadística de Pearson y Fisher, la inferencia estadística busca encontrar los valores que parametrizan a la distribución desconocida de los datos. El primer enfoque, propuesto por Pearson, afirmaba que si era posible observar a la variable de interés en todos y cada uno de los individuos de una población, entonces era posible calcular los parámetros de la distribución de la variable de interés; por otro lado, si sólo se tenía acceso a una muestra representativa, entonces era posible calcular una estimación de tales parámetros. Sin embargo, Fisher discrepó de tales argumentos, asumiendo que las observaciones están sujetas a un error de medición y por lo tanto, así se tuviese acceso a toda la población, es imposible calcular los parámetros de la distribución de la variable de interés.</p>
<p>Del planteamiento de Fisher resultaron una multitud de métodos estadísticos para la estimación de los parámetros poblacionales. Es decir, si la distribución de <span class="math inline">\(\mathbf{Y}\)</span> está parametrizada por <span class="math inline">\(\boldsymbol \theta=(\theta_1,\ldots,\theta_K)\)</span>, <span class="math inline">\(\boldsymbol \theta\in \Theta\)</span> con <span class="math inline">\(\Theta\)</span> el espacio paramétrico inducido por el comportamiento de la variable de interés, el objetivo de la teoría estadística inferencial es calcular una estimación <span class="math inline">\(\hat{\boldsymbol \theta}\)</span> del parámetro <span class="math inline">\(\boldsymbol \theta\)</span> por medio de los datos observados. En este enfoque, los parámetros se consideran cantidades fijas y constantes. Sin embargo, en la última mitad del siglo XX, algunos investigadores estadísticos comenzaron a reflexionar acerca de la naturaleza de <span class="math inline">\(\boldsymbol \theta\)</span> y enfocaron la inferencia estadística de una manera distinta: asumiendo que la distribución de la variable de interés está condicionada a valores específicos de los parámetros. Es decir, en términos de notación, si la variable de interés es <span class="math inline">\(\mathbf{Y}\)</span>, su distribución condicionada a los parámetros toma la siguiente forma <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span>. Esto implica claramente que en este nuevo enfoque la naturaleza de los parámetros no es constante sino estocástica.</p>
<p>En términos de inferencia para <span class="math inline">\(\boldsymbol \theta\)</span>, es necesario encontrar la distribución de los parámetros condicionada a la observación de los datos. Para este fin, es necesario definir la distribución conjunta de la variable de interés con el vector de parámetros.
<span class="math display">\[\begin{equation*}
p(\boldsymbol \theta,\mathbf{Y})=p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)
\end{equation*}\]</span></p>
<p>A la distribución <span class="math inline">\(p(\boldsymbol \theta)\)</span> se le conoce con el nombre de distribución  y en ella se enmarcan todas y cada una de las creencias que se tienen acerca del comportamiento estocástico del vector de parámetros antes de que ocurra la recolección de los datos y <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span> es la distribución de muestreo o verosimilitud o distribución de los datos. Por otro lado, la distribución del vector de parámetros condicionada a los datos observados está dada por
<span class="math display">\[\begin{equation}\label{Bayes}
p(\boldsymbol \theta\mid \mathbf{Y})=\frac{p(\boldsymbol \theta,\mathbf{Y})}{p(\mathbf{Y})}=\frac{p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)}{p(\mathbf{Y})}
\end{equation}\]</span></p>
<p>A la distribución <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span> se le conoce con el nombre de distribución  y en ella se enmarcan las creencias actualizadas acerca del comportamiento estocástico del vector de parámetros teniendo en cuenta los datos observados <span class="math inline">\(\mathbf{Y}\)</span>. Nótese que la expresión () se compone de una fracción cuyo denominador no depende del vector de parámetros y considerando a los datos observados como fijos, corresponde a una constante y puede ser obviada. Por lo tanto, otra representación de la regla de Bayes está dada por
<span class="math display">\[\begin{align}\label{Bayes1}
p(\boldsymbol \theta\mid \mathbf{Y})\propto p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta)
\end{align}\]</span></p>
<p> menciona que esta expresión se conoce como la distribución  y encierra el núcleo técnico de la inferencia bayesiana. La constante <span class="math inline">\(p(\mathbf{Y})\)</span> faltante en la expresión {} se da a continuación:</p>

<div class="proposition">
<span id="prp:unnamed-chunk-12" class="proposition"><strong>Proposición 3.4  </strong></span>La expresión <span class="math inline">\(p(\mathbf{Y})\)</span> corresponde a una constante <span class="math inline">\(k\)</span> tal que
<span class="math display">\[\begin{equation*}
k=p(\mathbf{Y})=E_{\boldsymbol \theta}[p(Y \mid \boldsymbol \theta)]
\end{equation*}\]</span>
</div>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> Nótese que
<span class="math display">\[\begin{equation*}
k=p(\mathbf{Y})=\int p(\mathbf{Y},\boldsymbol \theta)\ d\boldsymbol \theta=\int p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)\ d\boldsymbol \theta.
\end{equation*}\]</span>
entonces
<span class="math display">\[\begin{align*}
k&amp;=\int p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta)\ d\boldsymbol \theta\\
&amp;=E_{\boldsymbol \theta}[p(Y \mid \boldsymbol \theta)]
\end{align*}\]</span>
</div>
<p>Curiosamente, el reverendo Thomas Bayes nunca publicó este resultado, sino que después de su fallecimiento, su amigo, el filósofo Richard Price, encontró los escritos dentro de sus pertenencias, y éstos fueron publicados en el 1764 en . Aunque el teorema de Bayes fue nombredo a honor de Thomas Bayes, estamos casi seguros que de que él mismo no sospechaba del gran impacto de este hermoso resultado. De hecho, aproximadamente una década más tarde el gran Pierre-Simon Laplace también descrubrió el mismo principio, y dedicó gran parte de su vida extendiéndolo y formalizándolo. Más aún, él analizó grandes volumenes de datos relacionados a los nacimientos en diferentes paises para confirmar esta teoría, y sentó las bases de ésta. A continuación se presenta un ejemplo simple de este sencillo pero poderoso teorema.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-14" class="example"><strong>Ejemplo 3.1  </strong></span>Uno de los primeros acercamientos de cualquier profesional a la estadística bayesiana se da en un curso básico de probabilidades en donde el docente presenta con cierta rigurosidad los conceptos básicos e introductorios de la teoría de probabilidad. En un sobrevuelo de tales conceptos es posible recordar términos como experimento, espacio muestral, función de probabilidad y sigma álgebra. Justo después del repaso de rigor acerca de los axiomas de probabilidades y sus teoremas más significativos, el curso da una curva cerrada y el alumno es introducido en conceptos más profundos como la probabilidad condicional.</p>
<p>En estos tópicos, tanto el maestro como el alumno asumen que los temas básicos ya están entendidos y que no existe necesidad de volver atrás. A manera de introducción, los autores desean hacer notar a los lectores que requieren de herramientas de modelamiento más sofisticadas, que es necesario volver atrás - al menos en esta primera página - para sentar las bases de la autopista de alta velocidad como lo es el análisis bayesiano. No tiene sentido que el investigador utilice las poderosas herramientas bayesianas si no entiende que sus bases probabilísticas están bien sustentadas.</p>
<p>Para entrar en detalle, vamos a utilizar un ejemplo en donde el lector se sentirá identificado con aquellas épocas universitarias de un curso de probabilidades: suponga que una fábrica del sector industrial produce bolígrafos y que la producción está a cargo de tres máquinas. La primera máquina produce el 50% del total de bolígrafos en el año, la segunda máquina produce el 30% y la última maquina produce el restante 20%. Por supuesto, esta producción esta sujeta al error y por tanto, basados en la experiencia, es posible reconocer que, de los artículos producidos por la primera máquina, el 5% resultan defectuosos; de los artículos producidos por la segunda máquina, el 2% resultan defectuosos y , de los artículos producidos por la última máquina, el 6% resultan defectuosos.</p>
<p>FIGURA - Fabrica1.pdf</p>
<p>Una pregunta natural que surge es acerca de la probabilidad de selección de un artículo defectuoso y para responder a esta pregunta con &lt;<rigurosidad de probabilísta>&gt; es necesario enfocar nuestra atención en los tópicos básicos que dejamos atrás. En primer lugar el experimento en cuestión es la selección de un bolígrafo. Para este experimento, una terna <span class="math inline">\((\Omega, \mathfrak{F}, P)\)</span> , llamada comúnmente espacio de medida o espacio de probabilidad, está dada por</p>
<ol style="list-style-type: decimal">
<li>El espacio muestral: <span class="math inline">\(\Omega=\{\text{defectuoso}, \text{No defectouso}\}\)</span></li>
<li>La <span class="math inline">\(\sigma\)</span>-álgebra: <span class="math inline">\(\mathfrak{F}=\{\Omega, \phi, \{\text{Defectuoso}\}, \{\text{No Defectuoso}\}\}\)</span></li>
<li>La función de probabilidad:
<span class="math display">\[\begin{align*}
  p: \mathfrak{F} &amp;\longrightarrow [0,1]\\
  \Omega &amp;\longrightarrow 1\\
  \phi &amp;\longrightarrow 0\\
  \{Defectuoso\}&amp;\longrightarrow P(D)\\
  \{Defectuoso\}&amp;\longrightarrow 1-P(D)
  \end{align*}\]</span>
en donde, acudiendo al teorema de probabilidad total, se define
<span class="math display">\[\begin{equation*}
  p(D)=p(D \mid M1)P(M1)+p(D \mid M2)P(M2)+p(D \mid M3)P(M3)
  \end{equation*}\]</span></li>
</ol>
<p>Sin embargo, también es posible plantearse otro tipo de preguntas que sirven para calibrar el proceso de producción de artículos defectuosos. Por ejemplo, cabe preguntarse acerca de la probabilidad de que habiendo seleccionado un artículo defectuoso, éste provenga de la primera máquina. En esta ocasión, el experimento ha cambiado y ahora se trata de seleccionar un artículo defectuoso y para responder a tal cuestionamiento, se debe establecer rigurosamente el espacio de probabilidad que puede estar dado por</p>
<ol style="list-style-type: decimal">
<li>El espacio muestral: <span class="math inline">\(\Omega=\{M1, M2, M3 \}\)</span></li>
<li>La <span class="math inline">\(\sigma\)</span>-álgebra: <span class="math inline">\(\mathfrak{F}^+=\{\Omega, \phi, \{M1\}, \{M2,M3\}\}\)</span></li>
<li>La función de probabilidad:
<span class="math display">\[\begin{align*}
  p: \mathfrak{F}^+ &amp;\longrightarrow [0,1]\\
  \Omega &amp;\longrightarrow 1\\
  \phi &amp;\longrightarrow 0\\
  \{M1\}&amp;\longrightarrow p(M1 \mid D)\\
  \{M2,M3\}&amp;\longrightarrow 1-p(M1 \mid D)
  \end{align*}\]</span>
en donde, acudiendo a la definición de probabilidad condicional, se define
<span class="math display">\[\begin{equation*}
  p(M1 \mid D)=\frac{p(D \mid M1)P(M1)}{p(D \mid M1)P(M1)+p(D \mid M2)P(M2)+p(D \mid M3)P(M3)}
  \end{equation*}\]</span></li>
</ol>
<p>La anterior función de probabilidad se conoce con el nombre de regla de probabilidad de Bayes y, aparte de ser el baluarte de la mayoría de investigaciones estadísticas que se plantean hoy en día, ha sido la piedra de tropiezo de muchos investigadores radicales que trataron de estigmatizar este enfoque tildando a sus seguidores de mediocres matemáticos y pobres probabilistas afirmando que la regla de probabilidad de Bayes es sólo un artilugio diseñado para divertirse en el tablero.</p>
Pues bien, la interpretación de la regla de bayes se puede realizar en el sentido de actualización de la estructura probabilística que gobierna el experimento. Y esta actualización tiene mucho sentido práctico cuando se cae en la cuenta de que la vida real está llena de calibradores y que las situaciones generadas son consecuencia de algún cambio estructural. De esta forma, el conocimiento de la probabilidad de que el artículo sea producido por la primera máquina se actualiza al conocer que este artículo particular es defectuoso y de esta manera calibra la estructura aleatoria que existe detrás del contexto de la fábrica de bolígrafos. Aparte de servir para resolver problemas como el anteriormente mencionado, la regla de bayes ha marcado el comienzo de un nuevo enfoque de análisis de datos, no solamente porque hace explícitas las relaciones causales entre los procesos aleatorios, sino también porque facilita la inferencia estadística y la interpretación de los resultados.
</div>
<p>En el campo de la medicina, también se ha visto un gran número de la aplicación del teorema de Bayes. A continuación se enuncia uno de ellos:</p>

<div class="example">
<p><span id="exm:unnamed-chunk-15" class="example"><strong>Ejemplo 3.2  </strong></span>El Grupo de Trabajo de Servicios Preventivos de los Estados Unidos (USPSTF por sus siglas en inglés) hizo unas nuevas y controversiales recomendaciones sobre la detección del cáncer de mama (ver página <span class="math inline">\(http://www.uspreventiveservicestaskforce.org/uspstf/uspsbrca.htm\)</span>), dentro de los cuales, no recomienda el examen de la mamografía en mujeres entre 40 y 49 años de edad, afirmando que la práctica bienal de este examen debe ser una decisión individual según el contexto particular de la paciente, mientras que por muchos años, se han dicho a las mujeres que se debe realizar la mamografía una vez cumplidos los 40 años. Por otro lado, USPSTF sí recomienda tal práctica de forma bienal en grupos de mujeres de entre 50 y 74 años de edad, puesto que USPSTF no encontró suficiente evidencia de beneficio o daño adicional en realizar este examen en mujeres mayores que los 74 años. Otra recomendación que hizo USPSTF es no realizar auto exámanes de senos, contrario a las recomendaciones y consejos que da la mayoría de los profesionales y organizaciones de la salud, incluyendo la  (ver <span class="math inline">\(http://www.cancer.org/acs/groups/cid/documents/webcontent/003164-pdf.pdf\)</span>).</p>
<p>El autor del blog, después de algunas averiguaciones, encontró que</p>
<ul>
<li>Los expertos estiman que un 12.3% de las mujeres desarrollan formas invasivas del cáncer de mama durante la vida.</li>
<li>La probabilidad de que una mujer desarrolle el cáncer de mama entre los 40 y los 49 años de edad es 1 en 69, y esta probabilidad aumenta a medida que envejezca, de tal forma que llega a ser de 1 en 38 en mujeres de entre 50 y 59 años.</li>
<li>El cáncer de mama es más difícil de detectar en mujeres jóvenes puesto que el tejido mamario es más denso y fibroso. Los expertos estiman que la tasa de un falso positivo es de 97.8 por cada 1000 mujeres de 40 y 49 años, y esta tasa disminuye a 86.6 por cada 1000 mujeres entre 50 y 59 años.</li>
<li>La tasa de un falso negativo es de 1 por cada 1000 mujeres de 40 y 49 años, y es de 1.1 por cada 1000 mujeres entre 50 y 59 años.</li>
</ul>
Resumiendo las anteriores afirmaciones, tenemos las siguientes probabilidades
<p>Utilizando la regla de Bayes, se puede calcular las siguientes probabilidades para mujeres de 40 y 49 años:
<span class="math display">\[\begin{align*}
P(\text{Cáncer}|\text{Positivo})&amp;=\frac{P(\text{Positivo}|\text{Cáncer})P(\text{Cáncer})}{P(\text{Positivo}|\text{Cáncer})P(\text{Cáncer})+P(\text{Positivo}|\text{No cáncer})P(\text{No cáncer})}\\
&amp;=\frac{0.999*0.01449}{0.999*0.01449+0.0978*0.9855}\\
&amp;=0.1305
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
P(\text{Cáncer}|\text{Negativo})&amp;=\frac{P(\text{Negativo}|\text{Cáncer})P(\text{Cáncer})}{P(\text{Negativo}|\text{Cáncer})P(\text{Cáncer})+P(\text{Negativo}|\text{No cáncer})P(\text{No cáncer})}\\
&amp;=\frac{0.001*0.01449}{0.001*0.01449+0.9022*0.9855}\\
&amp;=0.0000163
\end{align*}\]</span></p>
Similarmente, se puede calcular estas dos probabilidades para las mujeres de 50 y 59 años.
Los resultados de la anterior tabla muestran cómo se cambia la probabilidad de tener cancer condicionado en los resultados de la pruebe. Entre estos valores se puede ver que, con un resultado positivo en el examen, la probabilidad de tener efectivamente el cáncer es aproximadamente diez puntos porcentuales más bajo en mujeres de edad de 40 y 49 años, de donde se puede sustentar la recomendación de no efectuar este examen en mujeres de este rango de edad.
</div>
</div>
<div id="inferencia-bayesiana" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Inferencia bayesiana</h2>
<p>El enfoque bayesiano, además de especificar un modelo para los datos observados <span class="math inline">\(\mathbf{Y}=(y_1,\ldots,y_n)\)</span> dado un vector de parámetros desconocidos <span class="math inline">\(\boldsymbol \theta=(\theta_1,\ldots,\theta_K)\)</span>, usualmente en forma de densidad condicional <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span>, supone que <span class="math inline">\(\boldsymbol \theta\)</span> es aleatorio y que tiene un densidad  <span class="math inline">\(p(\boldsymbol \theta\mid \boldsymbol \eta)\)</span>, donde <span class="math inline">\(\boldsymbol \eta\)</span> es un vector de hiper-parámetros. De esta forma, la inferencia concerniente a <span class="math inline">\(\boldsymbol \theta\)</span> se basa en una densidad  <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span>.</p>
<p>En términos de estimación, inferencia y predicción, el enfoque Bayesiano supone dos momentos o etapas:</p>
Antes de la recolección de las datos, en donde el investigador propone, basado en su conocimiento, experiencia o fuentes externas, una distribución de probabilidad  para el parámetro de interés. Con esta distribución es posible calcular estimaciones puntuales y por intervalo con el fin de confirmar que la distribución propuesta se ajusta al problema de estudio. En esta etapa, basados en la distribución , también es posible hacer predicciones de cantidades observables.
<p>Después de la recolección de los datos. Siguiendo el teorema de Bayes, el investigador actualiza su conocimiento acerca del comportamiento probabilístico del parámetro de interés mediante la distribución  de este. Con esta distribución es posible calcular estimaciones puntuales y por intervalo justo como en el enfoque frecuentista. En esta etapa, basados en la distribución , también es posible hacer predicciones de cantidades observables y pruebas de hipótesis acerca de la adecuación del mejor modelo a los datos observados.</p>
<div id="inferencia" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Inferencia </h3>
<p>Con las anteriores expresiones es posible calcular la probabilidad  de que <span class="math inline">\(\boldsymbol \theta\)</span> esté en una determinada región <span class="math inline">\(G\)</span> como
<span class="math display">\[\begin{equation}
Pr(\boldsymbol \theta\in G)=\int_G p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>En esta primera etapa también es posible calcular, con fines confirmatorios , la estimación puntual para el vector <span class="math inline">\(\boldsymbol \theta\)</span> dada por alguna medida de tendencia central para la distribución <span class="math inline">\(p(\boldsymbol \theta\mid \boldsymbol \eta)\)</span>. En particular, si se escoge la media, entonces
<span class="math display">\[\begin{equation}\label{est.prio}
\hat{\boldsymbol \theta}=E(\boldsymbol \theta)=\int \boldsymbol \theta\ p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>También es posible calcular una región <span class="math inline">\(C\)</span> de <span class="math inline">\(100\times(1-\alpha)%\)</span> de credibilidad\footnote{La interpretación de las regiones de credibilidad bayesianas difiere de la interpretación de las regiones de confianza frecuentistas. La primera se refiere a la probabilidad de que el verdadero valor de <span class="math inline">\(\boldsymbol \theta\)</span> esté en la región. La segunda se refiere a la región de la distribución muestral para <span class="math inline">\(\boldsymbol \theta\)</span> tal que, dados los datos observados, se podría esperar que el <span class="math inline">\(100\times\alpha%\)</span> de las futuras estimaciones de <span class="math inline">\(\boldsymbol \theta\)</span> no pertenecieran a dicha región.} para <span class="math inline">\(\boldsymbol \theta\)</span> que en esta primera etapa es tal que
<span class="math display">\[\begin{equation}
1-\alpha \leq Pr(\boldsymbol \theta\in C)=\int_Cp(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
</div>
<div id="inferencia-1" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Inferencia </h3>
<p>Una vez recolectados los datos, se actualizan las cálculos descritos en la sección anterior. Podemos calcular la probabilidad  de que <span class="math inline">\(\boldsymbol \theta\)</span> esté en la región <span class="math inline">\(G\)</span> dados los datos observados como
<span class="math display">\[\begin{equation}
Pr(\boldsymbol \theta\in G  \mid \mathbf{Y})=\int_G p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>También es posible calcular la estimación puntual para el vector <span class="math inline">\(\boldsymbol \theta\)</span> dados los datos observados. Ésta está dada por alguna medida de tendencia central para la distribución <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span>. En particular, si se escoge la media, entonces
<span class="math display">\[\begin{equation}
\hat{\boldsymbol \theta}=E(\boldsymbol \theta\mid \mathbf{Y})=\int \boldsymbol \theta\ p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>La región <span class="math inline">\(C\)</span> de <span class="math inline">\(100\times(1-\alpha)%\)</span> de credibilidad es tal que
<span class="math display">\[\begin{equation}
1-\alpha \leq Pr(\boldsymbol \theta\in C \mid \mathbf{Y})=\int_Cp(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>También la distribución posterior del parámetro <span class="math inline">\(\boldsymbol \theta\)</span> es útil para el procedimiento de juzgamiento de hipótesis en el ámbito del análisis bayesiano. Esto se lleva a cabo por medio del factor de Bayes que se presentará más adelante.</p>
</div>
<div id="inferencia-predictiva" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Inferencia predictiva</h3>
<p>En términos de inferencia predictiva existen dos etapas que cubren las &lt;<actuales>&gt; suposiciones acerca del vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span>. En una primera etapa - antes de la observación de los datos - la suposición &lt;<actual>&gt; de <span class="math inline">\(\boldsymbol \theta\)</span> está dada por la densidad  <span class="math inline">\(p(\boldsymbol \theta\mid \boldsymbol \eta)\)</span>. En estos términos, utilizando el Resultado , la distribución predictiva  de <span class="math inline">\(\mathbf{Y}\)</span> está dada por
<span class="math display">\[\begin{equation}
p(\mathbf{y})=\int p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\ d\boldsymbol \theta
\end{equation}\]</span></p>
<p>La segunda etapa - después de la recolección de los datos - actualiza las suposiciones acerca de <span class="math inline">\(\boldsymbol \theta\)</span> puesto que ahora éste sigue una distribución  dada por (). Por lo tanto, la distribución predictiva  de <span class="math inline">\(\mathbf{Y}\)</span> está dada por
<span class="math display">\[\begin{align}\label{predictpos}
p(\tilde{\mathbf{y}} \mid \mathbf{Y})&amp;=\int p(\tilde{\mathbf{y}},\boldsymbol \theta\mid \mathbf{y})\ d\boldsymbol \theta\notag \\
&amp;=\int p(\tilde{\mathbf{y}} \mid \boldsymbol \theta,\mathbf{Y})p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta\notag \\
&amp;=\int p(\tilde{\mathbf{y}} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \mathbf{Y})\ d\boldsymbol \theta
\end{align}\]</span>
donde <span class="math inline">\(p(\tilde{\mathbf{y}} \mid \boldsymbol \theta)\)</span> es la distribución de los datos evaluada en los nuevos valores <span class="math inline">\(\tilde{\mathbf{y}}\)</span>. La segunda línea de la anterior igualdad se obtiene utilizando el resultado  y la última línea se obtiene del resultado  de la independencia condicional.</p>
</div>
</div>
<div id="información" class="section level2" number="3.3">
<h2><span class="header-section-number">3.3</span> Información </h2>
<p>La escogencia de una distribución previa es muy importante en el análisis bayesiano, puesto que ésta afecta directamente en la distribución posterior, tal como lo ilustra el teorema de Bayes. En primer lugar, la distribución previa debe describir adecuadamente los conocimientos previos sobre los parámetros objetivos de estimación. Por ejemplo, si se cree que un parámetro toma valores cercanos a 10, entonces la distribución escogida para representarla también debe tomar valores cercanos a 10, por ejemplo, una distribución normal centrada en ese valor. Por otro lado, dado que en la literatura existe un gran número de distribuciones, algunas muy similares entre ellas, a la hora de escoger una distribución previa también debe tener en cuenta las implicaciones a la hora de efectuar cálculos de la estimación puntual o de intervalo de crediblidad, procurando en la mayoría de casos, obtener una distribución posterior fácil de manejar. A continuación exponemos algunos aspectos generales relacionados con esta distribución previa.</p>
<div id="distribuciones-conjugadas" class="section level3" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Distribuciones conjugadas</h3>
<p>Como se verá en los capítulos siguientes, muchos problemas de inferencia bayesiana comparten la agradable cualidad de que la forma funcional de la distribución  para el parámetro de interés resulta ser la misma de la distribución . Por ejemplo:</p>
Cuando se tiene una muestra aleatoria de variables con distribución Bernoulli de parámetro <span class="math inline">\(\theta\)</span>, es factible pensar que una distribución  apropiada para este parámetro es la distribución Beta; bajo este escenario, la distribución  también resulta ser Beta.
<p>En el caso en que se quiera modelar el parámetro <span class="math inline">\(\theta\)</span> concerniente a una variable aleatoria con distribución Poisson, es posible asignar como candidata para distribución  a la distribución Gamma; en este caso la distribución  también resulta ser Gamma.</p>
<p>Las distribuciones conjugadas son deseadas en el análisis bayesiano pues en primer lugar, la distribución posterior del parámetro <span class="math inline">\(\theta\)</span> es considerada como la actualización del conocimiento acerca de este después de la recolección de los datos, entonces al tener la misma forma funcional que la distribución previa, puede ser comparada a ésta y así ver claramente cómo es la influencia de los datos observados sobre la creencia acerca de <span class="math inline">\(\theta\)</span>; en segundo lugar, el hecho de que la distribución posterior sea de la misma forma funcional que la previa permite que la actualización de información se pueda llevar a cabo sistemáticamente, pues cada vez que se observan nuevos datos, la anterior distribución posterior puede ser tomada como la distribución previa y así producir una nueva distribución posterior.</p>
<p>A continuación exponemos la definición rigurosa de las distribuciones conjungadas y algunos tópicos relacionados.</p>

<div class="definition">
<span id="def:unnamed-chunk-16" class="definition"><strong>Definition 3.3  </strong></span>Sea <span class="math inline">\(\mathcal{F}=\{p(\mathbf{Y} \mid \boldsymbol \theta)\}\)</span> una familia de distribuciones de probabilidad. Una familia de distribuciones <span class="math inline">\(\mathcal{P}\)</span> se dice conjugada con respecto a <span class="math inline">\(\mathcal{F}\)</span> si para toda distribución  <span class="math inline">\(p(\boldsymbol \theta) \in \mathcal{P}\)</span> y para toda distribución de muestreo o verosimilitud de las observaciones <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span>, <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span> también pertenece a la familia <span class="math inline">\(\mathcal{P}\)</span>.
</div>
<p>Esta definición es en la mayoría de los casos prácticos muy útil. Sin embargo,  describe los siguientes dos casos en donde esta definición es completamente inútil:</p>
(Caso amplio) Sea <span class="math inline">\(\mathcal{P}=\{\emph{Todas las distribuciones de probabilidad}\}\)</span> y <span class="math inline">\(\mathcal{F}\)</span> cualquier familia de distribuciones de probabilidad. Entonces <span class="math inline">\(\mathcal{P}\)</span> es conjugada con respecto a <span class="math inline">\(\mathcal{F}\)</span> puesto que toda posible distribución  será un miembro de <span class="math inline">\(\mathcal{P}\)</span>.
<p>(Caso restringido) Sea <span class="math inline">\(\mathcal{P}=\{p \mid p(\theta=\theta_0)=1\}\)</span>, esto es, <span class="math inline">\(\mathcal{P}\)</span> corresponde a todas las distribuciones concentradas en un punto. Sea <span class="math inline">\(\mathcal{F}\)</span> cualquier familia de distribuciones de probabilidad. De esta manera, la distribución  de <span class="math inline">\(\theta\)</span> estará dada por
<span class="math display">\[\begin{align*}
    p(\theta \mid Y)\propto
    p(Y \mid \theta)p(\theta)
    &amp;=
    \begin{cases}
    p(Y \mid \theta)\times 1 \ \ \ \ \text{si $\theta=\theta_0$}\\
    p(Y \mid \theta)\times 0 \ \ \ \ \text{si $\theta\neq\theta_0$}\\
    \end{cases}\\
    &amp;=
    \begin{cases}
    p(Y \mid \theta) \ \ \ \ \text{si $\theta=\theta_0$}\\
    0           \ \ \ \ \text{si $\theta\neq\theta_0$}\\
    \end{cases}
    \end{align*}\]</span></p>
<p>De lo anterior y dado que <span class="math inline">\(\int p(\theta \mid Y)\ d\theta=1\)</span>, entonces <span class="math inline">\(p(Y \mid \theta)=1\)</span> si y sólo si <span class="math inline">\(\theta=\theta_0\)</span>. Con el anterior razonamiento, se concluye que <span class="math inline">\(\mathcal{P}\)</span> es conjugada con respecto a <span class="math inline">\(\mathcal{F}\)</span>.</p>
<p>Por lo tanto, se deben buscar distribuciones  que sean conjugadas de una forma tan amplia que permita proponer una distribución  adecuada, pero al mismo tiempo tan restringida para que la definición de conjugada tenga sentido práctico. Ahora introducimos una familia de distribuciones muy importante para el desarrollo de la teoría estadística, tanto en el ámbito bayesiano como en el clásico.</p>
</div>
<div id="familia-exponencial" class="section level3" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Familia exponencial</h3>
<p>Dependiendo de la naturaleza del parámetro <span class="math inline">\(\theta\)</span>, la familia exponencial puede ser uniparamétrica o multiparamétrica. En el primer caso, una distribución de probabilidad pertenece a la familia exponencial uniparamétrica si se puede escribir de la forma
<span class="math display">\[\begin{equation}\label{uniexpo}
p(Y \mid \theta)=\exp\{d(\theta)T(y)-c(\theta)\}h(y)
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(T(y)\)</span> y <span class="math inline">\(h(y)\)</span> son funciones que dependen de <span class="math inline">\(y\)</span> únicamente, y <span class="math inline">\(d(\theta)\)</span> y <span class="math inline">\(c(\theta)\)</span> son funciones que depende de <span class="math inline">\(\theta\)</span> únicamente. Análogamente, una distribución de probabilidad pertenece a la familia exponencial multi-paramétrica si se puede escribir de la forma
<span class="math display">\[\begin{equation}\label{multiexpo}
p(Y \mid \boldsymbol \theta)=\exp\{\mathbf{d}(\boldsymbol \theta)&#39;\mathbf{T}(y)-c(\boldsymbol \theta)\}h(y)
\end{equation}\]</span>
donde <span class="math inline">\(\mathbf{T}(y)\)</span> y <span class="math inline">\(\mathbf{d}(\boldsymbol \theta)\)</span> son funciones vectoriales, <span class="math inline">\(h(y)\)</span> y <span class="math inline">\(c(\boldsymbol \theta)\)</span> son funciones reales.</p>
<p>La ventaja de la familia exponencial radica en que es una familia relativamente restringuida de distribuciones y a la vez conserva la propiedad de ser distribuciones conjugadas, tal como muestra el siguiente resultado:</p>

<div class="proposition">
<span id="prp:unnamed-chunk-17" class="proposition"><strong>Proposición 3.5  </strong></span>Sea <span class="math inline">\(Y\)</span> una variable aleatoria con función de densidad perteneciente a la familia exponencial uniparamétrica, entonces la familia exponencial uniparamétrica es conjugada con respecto a sí misma.
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Observando la expresión (1.5.1), se debe encontrar una distribución  en la familia exponencial uniparamétrica, tal que la distribución , resultante del producto de la distribución  con la verosimilitud, sea también miembro de la familia exponencial uniparamétrica. Con base en lo anterior, la distribución , parametrizada por el hiperparámetro <span class="math inline">\(\alpha\)</span>, debe ser una función exponencial de los términos <span class="math inline">\(d(\theta)\)</span> y <span class="math inline">\(c(\theta)\)</span> como lo afirma . Esto es,
<span class="math display">\[\begin{equation}
p(\theta \mid \alpha)\propto\exp\{w(\alpha) d(\theta)-\delta c(\theta)\},
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(\delta\)</span> es una constante real (posiblemente dependiente de <span class="math inline">\(\alpha\)</span>). Por otro lado, para garantizar que <span class="math inline">\(p(\theta \mid \alpha)\)</span> sea una auténtica función de densidad se normaliza de la siguiente manera
<span class="math display">\[\begin{equation}
p(\theta \mid \alpha)=\frac{1}{k(\alpha,\delta)}\exp\{w(\alpha) d(\theta)-\delta c(\theta)\},
\end{equation}\]</span></p>
<p>con
<span class="math display">\[\begin{equation*}
k(\alpha,\delta)=\int\exp\{w(\alpha) d(\theta)-\delta c(\theta)\} \ d\theta.
\end{equation*}\]</span></p>
<p>De esta manera, no es difícil comprobar que la definición de distribución , parametrizada por el hiper-parámetro <span class="math inline">\(\alpha\)</span>, pertenece a la familia exponencial, puesto que
<span class="math display">\[\begin{equation}
p(\theta \mid \alpha)=\exp\{\underbrace{w(\alpha)}_{d(\alpha)} \underbrace{d(\theta)}_{T(\theta)} - \underbrace{\ln k(\alpha,\delta)}_{c(\alpha)}\}\underbrace{\exp\{-\delta c(\theta)\}}_{h(\theta)}.
\end{equation}\]</span></p>
<p>Por otro lado, del teorema de Bayes se tiene que
<span class="math display">\[\begin{align*}
p(\theta \mid Y) &amp;\propto p(Y \mid \theta)p(\theta \mid \alpha)\\
&amp;=\exp\{w(\alpha) d(\theta) + d(\theta)T(y) - c(\theta) -\ln k(\alpha,\delta) \}\exp\{-\delta c(\theta)\}h(y)\\
&amp;=\exp\{\underbrace{[\alpha+T(y)]}_{d(y)} \underbrace{d(\theta)}_{T(\theta)} -\underbrace{[\ln k(\alpha,\delta)-\ln h(y)]}_{c(y)}\} \underbrace{\exp\{-(\delta+1) c(\theta)\}}_{h(\theta)}\\
&amp;\propto \exp\{[w(\alpha)+T(y)] d(\theta)\}\exp\{-(\delta+1) c(\theta)\}.
\end{align*}\]</span></p>
Por lo tanto, la distribución  resultante también pertenece a la familia exponencial uniparamétrica.
</div>
La extensión del anterior resultado para el caso cuando tenemos una muestra aleatoria de observaciones es sencilla, tal como se expone a continuación:

<div class="proposition">
<span id="prp:unnamed-chunk-19" class="proposition"><strong>Proposición 3.6  </strong></span>Sean <span class="math inline">\(\mathbf{Y}=\{Y_1, \ldots, Y_n\}\)</span> una muestra aleatoria de variables distribuidas con función de densidad común perteneciente a la familia exponencial uniparamétrica, cuya función de densidad conjunta <span class="math inline">\(p(\mathbf{Y} \mid \theta)\)</span> también pertenece a la familia exponencial uniparamétrica. Bajo las anteriores condiciones la familia exponencial uniparamétrica es conjugada con respecto a sí misma.
</div>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> La demostración es inmediata utilizando el resultado anterior y notando que la forma funcional de la densidad conjunta para <span class="math inline">\(\mathbf{Y}\)</span> es
<span class="math display">\[\begin{equation}
p(\mathbf{Y} \mid \theta)=\exp\left\{d(\theta)\sum_{i=1}^nT(y_i)-nc(\theta)\right\}\prod_{i=1}^nh(y_i)
\end{equation}\]</span>
la cual hace parte de la familia exponencial.
</div>
<p>Otra extensión del resultado  corresponde al caso cuando la distribución de la observación está reparametrizado por un vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span>. A continuación se expone el resultado y la prueba correspondiente.</p>

<div class="proposition">
<span id="prp:unnamed-chunk-21" class="proposition"><strong>Proposición 3.7  </strong></span>Sean <span class="math inline">\(Y\)</span> una variable aleatoria con función de densidad perteneciente a la familia exponencial multiparamétrica. Sea <span class="math inline">\(\boldsymbol \theta\)</span> el parámetro de interés con distribución  parametrizada por un vector de hiperparámetros <span class="math inline">\(\boldsymbol \eta\)</span> y perteneciente a la familia exponencial multiparamétrica. Entonces la familia exponencial multiparamétrica es conjugada con respecto a sí misma.
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> En primer lugar, la distribución de probabilidad de <span class="math inline">\(Y\)</span> perteneciente a la familia exponencial multiparamétrica está dada por (1.5.2). Siguiendo el mismo razonamiento de la demostración del Resultado 1.5.1, la distribución  del parámetro de interés debe estar definida de la siguiente manera
<span class="math display">\[\begin{equation}
p(\boldsymbol \theta\mid \boldsymbol \eta)=\exp\left\{\underbrace{w(\boldsymbol \eta)&#39;}_{\mathbf{d}(\boldsymbol \eta)}
\underbrace{\mathbf{d}(\boldsymbol \theta)}_{\mathbf{T}(\boldsymbol \theta)} - \underbrace{\ln k(\boldsymbol \eta,\delta)}_{c(\boldsymbol \eta)}\right\}\underbrace{\exp\{-\delta c(\boldsymbol \theta)\}}_{h(\boldsymbol \theta)},
\end{equation}\]</span></p>
<p>con
<span class="math display">\[\begin{equation*}
k(\boldsymbol \eta,\delta)=\int\exp\{w(\boldsymbol \eta)&#39;\mathbf{d}(\boldsymbol \theta)-\delta c(\boldsymbol \theta)\} \ d\boldsymbol \theta.
\end{equation*}\]</span></p>
<p>Utilizando el teorema de Bayes, se tiene que, la distribución  del parámetro <span class="math inline">\(\theta\)</span> es
<span class="math display">\[\begin{align*}
p(\boldsymbol \theta\mid Y) &amp;\propto p(Y \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\\
&amp;= \exp\{\mathbf{T}(y)&#39;\mathbf{d}(\boldsymbol \theta) - c(\boldsymbol \theta) + w(\boldsymbol \eta)&#39; \mathbf{d}(\boldsymbol \theta) - \delta c(\boldsymbol \theta) - \ln k(\boldsymbol \eta,\delta) +\ln h(y)\}\\
&amp; =
\exp\left\{\underbrace{(w(\boldsymbol \eta)+\mathbf{T}(y))&#39;}_{\mathbf{d}(y)}
\underbrace{\mathbf{d}(\boldsymbol \theta)}_{\mathbf{T}(\theta)} - \underbrace{\left[\ln k(\boldsymbol \eta,\delta)-\ln h(y)\right]}_{c(y)}\right\}\underbrace{\exp\{-(\delta+1)c(\boldsymbol \theta)\}}_{h(\boldsymbol \theta)}
\end{align*}\]</span></p>
La anterior expresión también hace parte de la familia exponencial biparamétrica y con esto se concluye la demostración
</div>
<p>Nótese que el anterior resultado también cobija situaciones donde la verosimilitud sea perteneciente a la familia exponencial uniparamétrica. Más aún, a cualquier familia exponencial multiparamétrica de orden menor o igual al orden de la distribución .</p>

<div class="proposition">
<span id="prp:unnamed-chunk-23" class="proposition"><strong>Proposición 3.8  </strong></span>Sean <span class="math inline">\(\mathbf{Y}=\{Y_1, \ldots, Y_n\}\)</span> una muestra aleatoria con función de densidad conjunta o verosimilitud dada (1.4.4). Bajo este escenario la familia exponencial multi-paramétrica es conjugada con respecto a sí misma.
</div>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> La demostración sigue los mismos lineamentos que la demostración del resultado anterior concluyendo que la distribución  de <span class="math inline">\(\boldsymbol \theta\)</span> está dada por
<span class="math display">\[\begin{align*}
&amp;p(\boldsymbol \theta\mid \mathbf{Y}) \propto p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta\mid \boldsymbol \eta)\\
&amp;= \exp\left\{\sum_{i=1}^n\mathbf{T}(y_i)&#39;\mathbf{d}(\boldsymbol \theta) - nc(\boldsymbol \theta) + \boldsymbol \eta&#39; \mathbf{d}(\boldsymbol \theta) - \delta c(\boldsymbol \theta) - \ln k(\boldsymbol \eta,\delta) +\sum_{i=1}^n\ln h(y_i)\right\}\\
&amp; =\exp\left\{\underbrace{\left(\boldsymbol \eta+\sum_{i=1}^n\mathbf{T}(y_i)\right)&#39;}_{\mathbf{d}(\mathbf{y})}
\underbrace{\mathbf{d}(\boldsymbol \theta)}_{\mathbf{T}(\theta)} - \underbrace{\left[\ln k(\boldsymbol \eta,\delta)-\sum_{i=1}^n\ln h(y_i)\right]}_{c(\mathbf{y})}\right\} \\
&amp;  \times \underbrace{\exp\left\{-(\delta+n)c(\boldsymbol \theta)\right\}}_{h(\boldsymbol \theta)}
\end{align*}\]</span>
La anterior expresión también hace parte de la familia exponencial.
</div>
Ahora, estudiamos las expresiones relacionadas con la distribución predictiva de nuevas observaciones dentro del contexto de la familia exponencial:

<div class="proposition">
<p><span id="prp:unnamed-chunk-25" class="proposition"><strong>Proposición 3.9  </strong></span>Sea <span class="math inline">\(Y\)</span> una variable aleatoria con función de densidad perteneciente a la familia exponencial, dada por (). Sea <span class="math inline">\(\theta\)</span> el parámetro de interés con distribución  en la familia exponencial biparamétrica. La distribución predictiva  de <span class="math inline">\(Y\)</span> está dada por
<span class="math display">\[\begin{equation}
p(Y)=\frac{k(\alpha+T(y),\delta+1)}{k(\alpha,\delta)}h(y)
\end{equation}\]</span></p>
donde
<span class="math display">\[\begin{equation*}
k(a,b)=\int \exp\{w(a) d(\theta)-b c(\theta)\}\ d\theta
\end{equation*}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> <span class="math display">\[\begin{align*}
p(Y)&amp;=\int p(\theta)p(Y \mid \theta)\ d\theta\\
&amp;=\int \exp\{w(\alpha) d(\theta)-\ln k(\alpha,\delta)-\delta c(\theta)\}\exp\{d(\theta)T(y)-c(\theta)\}h(y)d\theta\\
&amp;=\frac{h(y)}{k(\alpha,\delta)}\int \exp\{[w(\alpha)+T(y)]d(\theta)-(\delta+1)c(\theta)\}d\theta\\
&amp;=\frac{k(\alpha+T(y),\delta+1)h(y)}{k(\alpha,\delta)}
\end{align*}\]</span></p>
<p>donde
<span class="math display">\[\begin{equation*}
k(\alpha,\delta)=\int \exp\{w(\alpha) d(\theta)-\delta c(\theta)\}\ d\theta
\end{equation*}\]</span></p>
y
<span class="math display">\[\begin{equation*}
k(\alpha+T(y),\delta+1)=\int \exp\{[w(\alpha)+T(y)]d(\theta)-(\delta+1)c(\theta)\} \ d\theta.
\end{equation*}\]</span>
</div>
<p>La extensión al caso de contar con una muestra aleatoria de observaciones se encuentra a continuación:</p>

<div class="proposition">
<p><span id="prp:unnamed-chunk-27" class="proposition"><strong>Proposición 3.10  </strong></span>Sea <span class="math inline">\(\mathbf{Y}=\{Y_1\ldots,Y_n\}\)</span> una muestra aleatoria con función de densidad conjunta perteneciente a la familia exponencial, dada por (1.4.4). Sea <span class="math inline">\(\theta\)</span> el parámetro de interés con distribución  dada por (1.4.5). La distribución predictiva  de <span class="math inline">\(\mathbf{Y}\)</span> está dada por</p>
<span class="math display">\[\begin{equation}
p(\mathbf{Y})=\frac{k(\alpha+T(\mathbf{y}),\delta+n)}{k(\alpha,\beta)}h(\mathbf{y})
\end{equation}\]</span>
donde <span class="math inline">\(k\)</span> se define tal como en el resultado anterior.
</div>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> La prueba se tiene de inmediato siguiendo los lineamentos de la demostración del anterior resultado.
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-29" class="proposition"><strong>Proposición 3.11  </strong></span>En términos de la distribución predictiva , se tiene que para una sola observación <span class="math inline">\(\tilde{y}\)</span>, ésta está dada por
<span class="math display">\[\begin{equation}
p(\tilde{y} \mid Y)=\frac{k(\alpha+T(y)+T(\tilde{y}),\delta+2)}{k(\alpha+T(y),\delta+1)}h(\tilde{y})
\end{equation}\]</span>
y en el caso en donde se tiene una muestra aleatoria, entonces la distribución predictiva  para una nueva muestra <span class="math inline">\(\tilde{\mathbf{y}}=\{\tilde{y}_1,\ldots,\tilde{y}_{n^*}\}\)</span> de tamaño <span class="math inline">\(n^*\)</span> está dada por
<span class="math display">\[\begin{equation}
p(\tilde{\mathbf{y}} \mid \mathbf{Y})=
\frac{k(\alpha+T(\mathbf{y})+T(\tilde{\mathbf{y}}),\delta+n+n^*)}
{k(\alpha+T(\mathbf{y}),\delta+n)}h(\tilde{\mathbf{y}})
\end{equation}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> De la definición de distribución predictiva  dada por la expresión () se tiene que
<span class="math display">\[\begin{align*}
p(\tilde{y} \mid Y)&amp;=\int p(\tilde{y} \mid \theta)p(\theta \mid y)\ d\theta\\
&amp;=\int \exp\{d(\theta)T(\tilde{y})-c(\theta)\}h(\tilde{y})\dfrac{\exp\{[w(\alpha)+T(y)]d(\theta)-(\delta+1)c(\theta)\}}{k(\alpha+T(y),\delta+1)}\ d\theta\\
&amp;=\frac{h(\tilde{y})}{k(w(\alpha)+T(y),\delta+1)}\int \exp\{[\alpha+T(y)+T(\tilde{y})]d(\theta)-(\delta+2)c(\theta)\}\ d\theta\\
&amp;=\frac{k(\alpha+T(y)+T(\tilde{y}),\delta+2)}{k(\alpha+T(y),\delta+1)}h(\tilde{y}),
\end{align*}\]</span></p>
<p>con
<span class="math display">\[\begin{equation*}
k(\alpha+T(y)+T(\tilde{y}),\delta+2)=\int \exp\{[w(\alpha)+T(y)+T(\tilde{y})]d(\theta)-(\delta+2)c(\theta)\}\ d\theta.
\end{equation*}\]</span></p>
La demostración para la nueva muestra se lleva a cabo de manera análoga.
</div>
</div>
<div id="distribuciones-no-informativas" class="section level3" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Distribuciones  no informativas</h3>
<p>Cuando no existe una base poblacional sobre el parámetro de interés o cuando existe total ignorancia de parte del investigador acerca del comportamiento de probabilístico del parámetro, es necesario definir distribuciones  que sean no informativas. Es decir, definir distribuciones  que jueguen un papel mínimo en términos de influencia en la distribución . Una característica de estas distribuciones es que su forma es vaga, plana o difusa, cumpliendo así el objetivo de no influenciar a la distribución . Por tanto la pregunta de interés que surge en este instante es: ¿cómo seleccionar distribuciones  no informativas sobre el parámetro de interés?</p>
<p>En los anteriores términos, la distribución uniforme define una distribución  que cumple con las características de no información en la mayoría de escenarios. Específicamente en aquellos problemas en donde el parámetro de interés está limitado a un espacio de muestreo acotado. Por ejemplo, en la distribución Binomial, el parámetro de interés está limitado al espacio de muestreo <span class="math inline">\([0,1]\)</span>. Sin embargo, no en todos los problemas encaja la distribución uniforme. Nótese, por ejemplo, que en el caso en que la distribución exponencial se acomode a los datos como candidata a verosimilitud, entonces el espacio de muestreo del parámetro de interés estaría dado por <span class="math inline">\((0,\infty)\)</span> en cuyo caso la distribución uniforme no sería conveniente puesto que sería una distribución impropia en el espacio de muestreo del parámetro de interés. Es decir
<span class="math display">\[\begin{equation*}
\text{si } p(\theta)\propto kI_{\Theta}(\theta) \text{, entonces } \int_{\Theta}p(\theta) \ d(\theta)\longrightarrow \infty.
\end{equation*}\]</span></p>
<p>donde <span class="math inline">\(\Theta\)</span> denota espacio de muestreo del parámetro <span class="math inline">\(\theta\)</span> y <span class="math inline">\(I\)</span> denota la función indicadora. Por otro lado, una característica importante que debe tener una distribución  no informativa es que sea invariante en términos de transformaciones matemáticas. Es decir, si el parámetro de interés es <span class="math inline">\(\theta\)</span> con distribución  no informativa dada por <span class="math inline">\(p(\theta)\)</span>, y sea <span class="math inline">\(\phi=h(\theta)\)</span> una transformaición de <span class="math inline">\(\theta\)</span> por medio de la función <span class="math inline">\(h\)</span>, entonces la distribución  de <span class="math inline">\(\phi\)</span> también debería ser no informativa. Sin embargo, la teoría de probabilidad afirma que la distribución de probabilidad de una transformación está dada por
<span class="math display">\[\begin{equation}\label{teo_transf}
p(\phi)=p(\theta) \mid \frac{d\theta}{d\phi} \mid =p(\theta) \mid h&#39;(\theta) \mid ^{-1}
\end{equation}\]</span></p>
<p>y claramente si la función <span class="math inline">\(h\)</span> no es una función lineal, entonces los resultados encontrados por medio de este enfoque indicarían que la distribución  <span class="math inline">\(p(\phi)\)</span> sería informativa contradiciendo los supuestos de <span class="math inline">\(p(\theta)\)</span>. El siguiente ejemplo ilustra este planteamiento:</p>

<div class="example">
<p><span id="exm:unnamed-chunk-31" class="example"><strong>Ejemplo 3.3  </strong></span>Suponga que el parámetro de interés es <span class="math inline">\(\theta\)</span> y que está restringido a un espacio de muestreo dado por el intervalo <span class="math inline">\([0,1]\)</span>. Si se supone completa ignorancia acerca del comportamiento del parámetro, entonces una buena opción, con respecto a la distribución , sería la distribución uniforme en el intervalo <span class="math inline">\([0,1]\)</span>. Es decir, la distribución  no informativa estaría dada por
<span class="math display">\[\begin{equation*}
p(\theta) = I_{[0,1]}(\theta)
\end{equation*}\]</span></p>
<p>Suponga ahora que existe una transformación del parámetro de interés dada por <span class="math inline">\(\phi=h(\theta)=\ln(\theta)\)</span>. Por tanto, siguiendo () se tiene que la distribución de <span class="math inline">\(\phi\)</span> está dada por
<span class="math display">\[\begin{equation*}
p(\phi)=I_{(-\infty,0)}(\phi)e^{\phi}
\end{equation*}\]</span></p>
la cual es informativa con respecto al parámetro <span class="math inline">\(\phi\)</span>. Sin embargo, es el mismo problema y existe una contradicción en términos de que para <span class="math inline">\(\theta\)</span> se desconoce todo, pero para una función <span class="math inline">\(\phi\)</span> existe evidencia de que el parámetro se comporta de cierta manera.
</div>
<p>Para palear las anteriores diferencias, es necesario encontrar una distribución  no informativa que sea invariante a transformaciones matemáticas. La distribución  no informativa de Jeffreys, definida a continuación, cuenta con esta agradable propiedad.</p>

<div class="definition">
<p><span id="def:unnamed-chunk-32" class="definition"><strong>Definition 3.4  </strong></span>Si la verosimilitud de los datos está determinada por un único parámetro <span class="math inline">\(\theta\)</span>, la distribución  no informativa de Jeffreys tiene distribución de probabilidad dada por
<span class="math display">\[\begin{equation}
p(\theta)\propto (I(\theta))^{1/2}
\end{equation}\]</span></p>
<p>con <span class="math inline">\(I(\theta)\)</span> la información de Fisher definida como
<span class="math display">\[\begin{align*}
I(\theta)&amp;=E\left\{\left[\frac{\partial}{\partial\theta}\log{p(\mathbf{Y}\mid\theta)}\right]^2\right\}\\
&amp;=-E\left\{\dfrac{\partial^2}{\partial\theta^2}\log{p(\mathbf{Y}\mid\theta)}\right\}
\end{align*}\]</span></p>
<p>Si la verosimilitud de los datos está determinada por un vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span>, la distribución  no informativa de Jeffreys tiene distribución de probabilidad dada por
<span class="math display">\[\begin{equation}
p(\theta)\propto |\mathbf{I}(\boldsymbol \theta)|^{1/2}
\end{equation}\]</span></p>
donde <span class="math inline">\(\mathbf{I}\)</span> es la matriz de información de Fisher, cuyo elemento en la fila <span class="math inline">\(i\)</span> y columna <span class="math inline">\(j\)</span> está definida como
<span class="math display">\[\begin{align*}
\mathbf{I}_{[ij]}(\boldsymbol \theta)&amp;=E\left\{\left[\frac{\partial}{\partial\theta_i}\log{p(\mathbf{Y}\mid\theta)}\right]\left[\frac{\partial}{\partial\theta_j}\log{p(\mathbf{Y}\mid\boldsymbol \theta)}\right]\right\}\\
&amp;=-E\left\{\dfrac{\partial^2}{\partial\theta_i\partial\theta_j}\log{p(\mathbf{Y}\mid\boldsymbol \theta)}\right\}
\end{align*}\]</span>
donde <span class="math inline">\(\theta_i\)</span> y <span class="math inline">\(\theta_j\)</span> son los elementos <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span> del vector <span class="math inline">\(\boldsymbol \theta\)</span>.
</div>
<p>Nótese que si la verosimilitud de las observaciones pertenecen a la familia de distribuciones exponencial, entonces la distribución previa de Jeffreys no es difícil de calcular. Por otro lado nótese que la distribución previa no informativa de Jeffreys depende, de cierta manera, del mecanismo probabilístico que rige a los datos. Lo anterior hace que ciertos críticos de la estadística bayesiana critiquen este enfoque puesto que se supone que la formulación de la distribución a previa es independiente de los datos observados.</p>
A continuación se evidencia la propiedad de esta distribución previa de seguir siendo no informativa con diferentes parametrizaciones.

<div class="proposition">
<span id="prp:unnamed-chunk-33" class="proposition"><strong>Proposición 3.12  </strong></span>La distribución  no informativa de Jeffreys es invariante a transformaciones uno a uno. Es decir, si <span class="math inline">\(\phi=h(\theta)\)</span>, entonces <span class="math inline">\(p(\phi)\propto(I(\phi))^{1/2}\)</span>.
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> En primer lugar nótese que
<span class="math display">\[\begin{align*}
I(\theta)=\mathbf{J}(\phi) \mid \frac{\partial\phi}{\partial\theta} \mid ^{2}
\end{align*}\]</span></p>
<p>puesto que al utilizar la regla de la cadena del cálculo matemático se tiene que
<span class="math display">\[\begin{align*}
\mathbf{J}(\phi)= - E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \phi)}{\partial\phi^2}\right]
&amp;= - E\left[\frac{\partial}{\partial\phi}\left(\frac{\partial \log p(\mathbf{Y} \mid \phi)}{\partial\phi}\right)\right]\\
&amp;= - E\left[\frac{\partial}{\partial\theta}\left(\frac{\partial \log p(\mathbf{Y} \mid \phi)}{\partial\phi}\right) \mid \frac{\partial\theta}{\partial\phi} \mid \right]\\
&amp;= - E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \phi)}{d\theta^2} \mid \frac{\partial\theta}{\partial\phi} \mid ^{2}\right]\\
&amp;= - E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \theta =h^{-1}(\phi))}{d\theta^2} \mid \frac{\partial\theta}{\partial\phi} \mid ^{2}\right]\\
&amp;= I(\theta) \mid \frac{\partial\theta}{\partial\phi} \mid ^{2}
\end{align*}\]</span></p>
Ahora, de la definición de función de distribución para una función y utilizando (1.4.11), se tiene que
<span class="math display">\[\begin{align*}
p(\phi)&amp;=p(\theta) \mid \frac{\partial\theta}{\partial\phi} \mid
\propto (I(\theta))^{1/2} \mid \frac{\partial\theta}{\partial\phi} \mid
\propto I(\phi)^{1/2} \mid \frac{\partial\phi}{\partial\theta} \mid  \mid \frac{d\theta}{\partial\phi} \mid =I(\phi)^{1/2}
\end{align*}\]</span>
</div>
<p>En  citan una Tabla de resumen en donde se encuentran distribuciones a previa no informativas para las distribuciones probabilísticas más comunes. A continuación se exponen algunos ejemplos que utilizan este enfoque.</p>

<div class="example">
<span id="exm:unnamed-chunk-35" class="example"><strong>Ejemplo 3.4  </strong></span>Si <span class="math inline">\(Y\)</span> es una variable aleatoria con distribución Binomial, entonces el espacio de muestreo del parámetro de interés será el intervalo <span class="math inline">\([0,1]\)</span>; sería conveniente utilizar la función de distribución uniforme sobre este intervalo como distribución  no informativa. Con el enfoque de Jeffreys se llega a este mismo resultado puesto que: la información de Fisher para la distribución binomial es <span class="math inline">\(J(\theta)=n/\theta(1- \theta)\)</span> dado que
<span class="math display">\[\begin{equation*}
\log p(Y \mid \theta)=\log \binom{n}{y} + y\log(\theta)+(n-y)\log(1-\theta)
\end{equation*}\]</span>
y
<span class="math display">\[\begin{equation*}
\frac{\partial^2 \log p(Y \mid \theta)}{\partial\theta^2}=-\frac{y}{\theta^2}-\frac{n-y}{(1-\theta)^2}
\end{equation*}\]</span>
Por lo tanto al calcular la esperanza, y por consiguiente la información de Fisher, se tiene que
<span class="math display">\[\begin{equation*}
I(\theta)=- E\left[\frac{d^2 \log p(Y \mid \theta)}{d\theta^2}\right]
=\frac{n\theta}{\theta^2}+\frac{n-n\theta}{(1-\theta)^2}= \frac{n}{\theta(1-\theta)}
\end{equation*}\]</span>
Es decir, la distribución  no informativa para el parámetro de interés <span class="math inline">\(\theta\)</span> es proporcional a <span class="math inline">\(\theta^{-1/2}(1-\theta)^{-1/2}\)</span>, la cual comparte la misma forma estructural de una distribución <span class="math inline">\(Beta(1/2,1/2)\)</span> que a su vez es idéntica a la distribución uniforme. En términos de la distribución  para el parámetro de interés, se tiene que
<span class="math display">\[\begin{align*}
p(\theta \mid Y) &amp;\propto p(Y \mid \theta) p(\theta)\\
&amp;\propto \theta^{y}(1-\theta)^{n-y}\theta^{-1/2}(1-\theta)^{-1/2}\\
&amp;=\theta^{y+1/2-1}(1-\theta)^{n-y+1/2-1}
\end{align*}\]</span>
Por tanto, la distribución de <span class="math inline">\(\theta \mid Y\)</span> es <span class="math inline">\(Beta(y+1/2,n-y+1/2)\)</span>. Por construcción, esta distribución no está alterada ni influenciada por la distribución  pues la misma es no informativa.
</div>

<div class="example">
<span id="exm:unnamed-chunk-36" class="example"><strong>Ejemplo 3.5  </strong></span>
Si <span class="math inline">\(\mathbf{Y}=\{Y_1,\ldots,Y_n\}\)</span> es una muestra aleatoria de variables con distribución de Poisson, entonces el espacio de muestreo del parámetro de interés será el intervalo <span class="math inline">\((0,\infty)\)</span>; por tanto utilizar la distribución uniforme como distribución  no informativa no es conveniente. Ahora, la información de Fisher para la distribución conjunta es <span class="math inline">\(I(\theta)=n/\theta\)</span> puesto que
<span class="math display">\[\begin{equation*}
\log p(\mathbf{Y} \mid \theta)=-n\theta+\log(\theta)\sum_{i=1}^ny_i-\sum_{i=1}^n\log(y_i!)
\end{equation*}\]</span>
y
<span class="math display">\[\begin{equation*}
\frac{\partial^2 \log p(\mathbf{Y} \mid \theta)}{\partial\theta^2}=-\frac{\sum_{i=1}^ny_i}{\theta^2}
\end{equation*}\]</span>
Por lo tanto al calcular la esperanza, y por consiguiente la información de Fisher, se tiene que
<span class="math display">\[\begin{equation*}
I(\theta)=- E\left[\frac{\partial^2 \log p(\mathbf{Y} \mid \theta)}{\partial\theta^2}\right]
=\frac{\sum_{i=1}^nE(y_i)}{\theta^2}=\frac{n}{\theta}
\end{equation*}\]</span>
Es decir, la distribución  no informativa para el parámetro de interés es proporcional a <span class="math inline">\(\theta^{-1/2}\)</span>. En términos de la distribución  para el parámetro de interés, se tiene que
<span class="math display">\[\begin{align*}
p(\theta \mid Y) \propto p(Y \mid \theta) p(\theta) \propto e^{-n\theta} \theta^{\sum_{i=1}^ny_i}\theta^{-1/2}
=e^{-n\theta} \theta^{\sum_{i=1}^ny_i-1/2}
\end{align*}\]</span>
Por tanto, la distribución de <span class="math inline">\(\theta \mid \mathbf{Y}\)</span> es <span class="math inline">\(Gamma(\sum_{i=1}^ny_i+1/2,n)\)</span>. Por construcción, esta distribución no está alterada ni influenciada por la distribución  pues la misma es no informativa.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-37" class="example"><strong>Ejemplo 3.6  </strong></span>Suponga que <span class="math inline">\(\mathbf{Y}=\{Y_1\ldots, Y_n\}\)</span> es una muestra aleatoria con distribución normal de parámetros <span class="math inline">\((\theta, \sigma^2)&#39;\)</span>. Se puede verificar que la matriz de información de Fisher para el vector de parámetros está dada por
<span class="math display">\[\begin{equation}
\begin{pmatrix}
  \frac{n}{\sigma^2} &amp; 0 \\
  0 &amp; \frac{n}{2\sigma^4} \\
\end{pmatrix}
\end{equation}\]</span></p>
cuyo determinante está dado por <span class="math inline">\(\frac{n^2}{2\sigma^6}\)</span>. Por lo tanto, la distribución a previa no informativa de Jeffreys está dada por
<span class="math display">\[\begin{equation}
p(\theta,\sigma^2)\propto 1/\sigma^3
\end{equation}\]</span>
</div>
</div>
</div>
<div id="pruebas-de-hipótesis" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Pruebas de hipótesis</h2>
<p>A excepción del juzgamiento de hipótesis, las inferencias que hacen los estadísticos bayesianos, acerca de poblaciones normales, son muy similares a las que los estadísticos de la tradición frecuentista, de Neyman y Pearson, hacen.
Consideremos la siguiente situación. Un instrumento mide la posición de un objeto con un determinado error. Éste error está distribuido de manera uniforme en el intervalo (-1cm, 1cm). Supongamos que el instrumento midió la posición de un objeto en +0.9999cm del origen. Planteamos la siguiente hipótesis nula, H: La posición real del objeto es exactamente el origen. Imagine que planteamos este problema de inferencia estadística a los profesores López (frecuentista clásico) y Cepeda (acérrimo bayesiano).
Razonamiento del frecuentista: Si la hipótesis nula es verdadera, ha ocurrido un evento con una probabilidad (a dos colas) de ocurrencia de 0.0001 o menos. Mediante un criterio razonable (nivel de significación), este es un evento muy raro y por lo tanto rechaza H.
Razonamiento del bayesiano: El bayesiano ve las cosas desde un punto de vista diferente. Dada una observación, la verosimilitud asociada con la posición del objeto en el intervalo -0.0001 y +1.9999 es la misma, 0.5. Fuera de esos límites la verosimilitud es nula. Ahora, el origen está dentro de la región en donde la verosimilitud es máxima; por lo tanto sea cual sea la distribución a previa asociada al parámetro de posición, la distribución a posterior tomara el valor cero en cualquier lugar fuera del intervalo -0.0001 y +1.9999. Así, con la observación disponible, no hay evidencia para el rechazo de H.
Bajo esta paradoja, Brewer (2002) sugiere que ambos estadísticos tienen razón, pero a la vez están equivocados. El frecuentista tiene razón en afirmar que, con la evidencia disponible, ha ocurrido un evento extraordinariamente extraño o que la hipótesis nula es falsa. El bayesiano tiene razón en argumentar que, en términos de la situación, no hay evidencia en contra de la hipótesis nula.
Esta paradoja se presenta porque los bayesianos tienden a trabajar dentro de la situación que ellos creen que existe (o al menos creen que ellos creen que existe) y la lógica bayesiana se mueve en ese marco de referencia. Los bayesianos hacen las inferencias en términos de la verosimilitud de los eventos observados, mientras que los frecuentistas hacen inferencias en términos de eventos que ni siquiera han ocurrido. .</p>
<div id="factor-de-bayes" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> Factor de Bayes</h3>
<p>El juzgamiento de hipótesis del enfoque frecuentista se puede efectuar en el ámbito Bayesiano por medio del . Suponiendo que existen dos modelos <span class="math inline">\(M1\)</span> y <span class="math inline">\(M2\)</span> candidatos para <span class="math inline">\(\mathbf{Y}\)</span>, se define el  en favor del modelo <span class="math inline">\(M1\)</span> como la razón de las densidades marginales de los datos para los dos modelos y es posible demostrar que es equivale a la siguiente expresión
<span class="math display">\[\begin{equation}\label{FB}
FB=\frac{p(\mathbf{Y} \mid M1)}{p(\mathbf{Y} \mid M2)}=\frac{Pr(M1 \mid \mathbf{Y})/Pr(M2 \mid \mathbf{Y})}{Pr(M1)/Pr(M2)}
\end{equation}\]</span></p>
<p>Para evaluar esta última expresión es necesario recurrir a la densidad previa y posterior del parámetro de interés, asumiendo que los modelos están parametrizados por éstos. Se puede ver que cuando los modelos <span class="math inline">\(M1\)</span> y <span class="math inline">\(M2\)</span> tienen la misma distribución previa, entonces el factor de Bayes se reduce a la razón de densidad posterior de los dos modelos. Adicionalmente este factor sólo está definido cuando la integral de la densidad marginal de <span class="math inline">\(\mathbf{Y}\)</span> bajo cada modelo converge. En la expresión () se claro que valores grandes del factor muestra evidencias a favor del modelo <span class="math inline">\(M1\)</span>, valores menores de 1 a favor del modelo <span class="math inline">\(M2\)</span>, mientras que valores cercanos a 1 no muestra evidencias claras hacia ninguno de los dos modelos.</p>
<p>En  presenta el siguiente ejemplo sencillo sobre la presencia o ausencia de la enfermedad hemofilia, una enfermedad genética especialmente grave las mujeres. Para una mujer quien tiene un hermano portador del gen, el parámetro <span class="math inline">\(\theta\)</span> describe la presencia o ausencia del gen en ella, y toma valores de 1 (presencia del gen) y 0 (ausencia del gen). La distribución previa del parámetro es <span class="math inline">\(P(\theta=1)=P(\theta=0)=0.5\)</span>. El objetivo es evaluar el sistema <span class="math inline">\(M_1:\ \theta=1\)</span> y <span class="math inline">\(M_2:\ \theta=0\)</span> con base en el hecho de que ella tiene dos hijos ambos no portadores del gen. De esta forma
<span class="math display">\[\begin{equation*}
FB=\frac{p(y_1=0,\ y_2=0|\theta=1)}{p(y_1=0,\ y_2=0|\theta=0)}=\frac{0.25}{1}=0.25
\end{equation*}\]</span>
De donde se evidencia mayor apoyo a la hipótesis <span class="math inline">\(\theta=0\)</span>.</p>
</div>
<div id="valor-p-bayesiano" class="section level3" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Valor <span class="math inline">\(p\)</span> Bayesiano</h3>
<p>En la inferencia clásica, se define el valor <span class="math inline">\(p\)</span> como la probabilidad de que la estadística de prueba tome valores más extremos a los observados, y se compara con el nivel de significancia, previamente establecidad, para tomar decisión acerca de una hipótesis nula. En el ámbito Bayesiano, el valor <span class="math inline">\(p\)</span> se define como la probabilidad de que la estadística de prueba <span class="math inline">\(T\)</span> calculado sobre los datos replicados <span class="math inline">\(y^{rep}\)</span> sean más extremos al observado, y la probabilidad se toma sobre la distribución posterior del parámetro <span class="math inline">\(\theta\)</span> y la distribución predictiva posterior de <span class="math inline">\(y^{rep}\)</span>. Específicamente, queda determinado por
<span class="math display">\[\begin{equation*}
p_B=\int\int_{{T(y^{rep})\geq T(y)}}p(y^{rep}|\theta)p(\theta|y)dy^{rep}d\theta
\end{equation*}\]</span></p>
A diferencia del valor <span class="math inline">\(p\)</span> clásico donde solo valores pequeños muestran evidencia en contra de la hipótesis nula, un valor <span class="math inline">\(p\)</span> Bayesiano extremo (menor a 0.01 o mayor a 0.99) sugiere que los valores observados difícilmente pueden ser replicadso si el modelo fuera verdadero.
<p>Los criterios de información constituyen una herramienta muy importante en el modelamiento estadístico, pues contribuye a la selección de modelos de manera simple. Existen una variedad de estos criterios, a continuación se describen los dos criterios más comunes en el análisis bayesiano.</p>
</div>
<div id="criterio-dic" class="section level3" number="3.4.3">
<h3><span class="header-section-number">3.4.3</span> Criterio DIC</h3>
<p>El criterio de información de devianza (denotada por DIC por los iniciales en inglés) es una generalización del popular criterio AIC para los modelos jerárquicos, y se basa en el concepto de la devianza que se define como
<span class="math display">\[\begin{equation}
D(y, \boldsymbol \theta)=-2*\log(p(y|\boldsymbol \theta))
\end{equation}\]</span></p>
<p>cuya media posterior es una medida usual del ajuste del modelo.  sugirió graficar la distribución posteriori de la devianza para observar el ajuste del modelo a los datos. Una estimación de esta media posterior se basa en simulación de <span class="math inline">\(M\)</span> valores <span class="math inline">\(\boldsymbol \theta^1,\cdots,\boldsymbol \theta^M\)</span> de la distribución posterior de <span class="math inline">\(\boldsymbol \theta\)</span>, y está dada por
<span class="math display">\[\begin{equation*}
\hat{E}_D=\frac{1}{M}\sum_{m=1}^MD(y,\boldsymbol \theta^m)
\end{equation*}\]</span></p>
<p>El DIC se define como
<span class="math display">\[\begin{equation*}
DIC=\hat{E}_D+p_D
\end{equation*}\]</span></p>
<p>Donde <span class="math inline">\(p_D\)</span> es el número efectivo de parámetros. Nótese que en la anterior formulación, el DIC se puede descomponer en dos partes: la parte de la bondad de ajuste del modelo, medido a través de <span class="math inline">\(E_D\)</span>, y la parte que mide la complejidad del modelo <span class="math inline">\(p_D\)</span>. Otra formulación equivalente del DIC se obtiene teniendo en cuenta que
<span class="math display">\[\begin{equation*}
p_D=\hat{E}_D - \hat{D}
\end{equation*}\]</span></p>
<p>Donde <span class="math inline">\(\hat{D}=-2*\log(p(y|\hat{\boldsymbol \theta}))\)</span> con <span class="math inline">\(\hat{\boldsymbol \theta}\)</span> denotando la media posterior de <span class="math inline">\(\boldsymbol \theta\)</span>; es decir, <span class="math inline">\(\hat{D}\)</span> es la estimación de la devianza usando <span class="math inline">\(\hat{\boldsymbol \theta}\)</span>, y <span class="math inline">\(p_D\)</span> se puede ver como la media posterior de la devianza menos la devianza de las medias posterior . De esta forma, el DIC también se puede escribir como
<span class="math display">\[\begin{equation*}
DIC=\hat{D}+2p_D
\end{equation*}\]</span></p>
<p>Interpretación de DIC: El modelo con el menor DIC es considerado como el modelo que mejor predice un conjunto de datos con la misma estructura que los datos observados. Al respecto se deben tener en cuenta las siguientes consideraciones:</p>
El DIC puede ser negativo puesto que <span class="math inline">\(p(y|\theta)\)</span> puede tomar valores mayores a 1 asociado a una devianza pequeña.
<p><span class="math inline">\(p_D\)</span>, y por consiguiente DIC, no es invariante a parametrizaciones del modelo. Se sugiere en la práctica usar parametrizaciones que conducen a la normalidad en la distribución posterior.</p>
</div>
<div id="criterio-aic-y-bic" class="section level3" number="3.4.4">
<h3><span class="header-section-number">3.4.4</span> Criterio AIC y BIC</h3>
<p>El criterio de información de Akaike (AIC) fue formalmente presentado en . Este criterio mide la pérdida de información al ajustar un modelo a un conjunto de datos; por esto, se buscan modelos que arrojen valores pequeños de AIC. Posteriormente  introdujo el factor de corrección para evitar que el AIC escoja modelos con demasiados parámetros en situaciones de tamaño de muestra pequeño. Por otro lado, el criterio de información bayesiano BIC, también conocido como el criterio de Schwarz , también está formulado en términos de la función de verosimilitudel modelo y del número de parámetros. La expresión de estos criterios es como sigue:
<span class="math display">\[\begin{align*}
AIC&amp;=-2\log(p(y|\hat{\boldsymbol \theta}))+2p\\
AIC_c&amp;=AIC+\frac{2p^2+2p}{n-p-1}\\
BIC&amp;=-2\log(p(y|\hat{\boldsymbol \theta}))+p\log(n)
\end{align*}\]</span></p>
<p>Donde <span class="math inline">\(p\)</span> es el número de parámetros en el modelo y <span class="math inline">\(n\)</span> el número de datos observados. Cabe resaltar que en el criterio BIC hay una mayor penalización por el número excesivo de parámetros que en el criterio AIC, y en la práctica se prefieren los modelos con un BIC menor.</p>
<p> Se debe recalcar que los dos criterios tienen diferentes enfoques, el criterio BIC se enfoca en identificar el modelo verdadero, mientras que el criterio DIC enfoca en encontrar el modelo con mejor capacidad de predicción.</p>
</div>
<div id="acerca-de-la-notación" class="section level3" number="3.4.5">
<h3><span class="header-section-number">3.4.5</span> Acerca de la notación</h3>
<p>Antes de empezar las próximas secciones, es necesario revisar la notación que se seguirá de ahora en adelante. Del teorema de Bayes resultan tres grandes definiciones que constituyen la base de la estadística Bayesiana y que a lo largo de este texto se mencionarán diferenciándolas por medio de la notación. El símbolo más importante de la estadística matemática es <span class="math inline">\(p\)</span>, el cual indica que existe una distribución de probabilidad para los datos, para el vector de parámetros, condicional o no. De hecho todos las definiciones y resultados anteriores han estado supeditadas al uso de esta monótona notación. En el ámbito de la notación de investigación internacional es común diferenciar las distribuciones con el fin de hacer más ameno el estudio del enfoque Bayesiano. En este texto se seguirá esta distinción. Un ejemplo claro en donde <span class="math inline">\(p\)</span> representa cuatro funciones distintas en una sola ecuación es el siguiente:</p>
<p><span class="math display">\[p(\theta \mid y)=p(y \mid \theta)\frac{p(\theta)}{p(y)}\]</span></p>
<p> explica por qué la notación simple, con el uso (a veces abuso) de la letra <span class="math inline">\(p\)</span> es más rigurosa de lo que, a simple vista, pueda parecer y comenta que,</p>
<blockquote>
<p>En realidad no me gusta la notación que la mayoría de los estadísticos usan:<span class="math inline">\(f\)</span>, para distribuciones de muestreo; $ $, para distribuciones a previa y $ L$, para verosimilitudes. Este estilo de notación se desvía de lo que realmente es importante. La notación no debería depender del orden en que las distribuciones son especificadas. Todas ellas son distribuciones de probabilidad, eso es lo realmente importante.</p>
</blockquote>
<p>Esto tiene sentido, aún más cuando se estudian las propiedades estadísticas de los estimadores desde el punto de vista de la teoría de la medida. Siendo así, el símbolo <span class="math inline">\(p\)</span> se refiere a una notación para una medida de probabilidad, quizás inducida por un elemento aleatorio. De hecho, en la ecuación que determina la regla de Bayes, cada una de las <span class="math inline">\(p\)</span> son medidas de probabilidad que no comparten el mismo espacio de medida (ni la misma $ $-álgebra, ni el mimo espacio muestral ).</p>
<p>De hecho, todo queda claro al realizar un diagrama que permita ver el espacio de salida y el espacio de llegada de los elementos aleatorios que inducen (si es el caso), cada una de las distribuciones de probabilidad. Por otra parte, Bob Carpenter, concluye que</p>
<blockquote>
<p>Una vez resuelto el problema de identificación de los espacios] la notación estadística depende en gran manera del contexto y aunque la regla de Bayes no necesite de mucha explicación, es necesario conocerlo todo acerca del contexto para poder interpretar las funciones que la conforman… El problema se hace mucho más agudo para los estadísticos novatos, pero eso se resuelve con la práctica. Una vez que uno sabe lo que está haciendo, se vuelve obvia la referencia de la distribución <span class="math inline">\(p\)</span>.</p>
</blockquote>
<p>Por lo anterior, es natural que algunos de los textos clásicos de estadística matemática, parezcan olvidar el contexto de las diferentes medidas de probabilidad. En realidad no es que lo olviden, lo que pasa es que los autores no son novatos y asumen que el lector sigue la idea de la referencia de la $ p$ en cuestión. Sin embargo, y lo digo por mi y sólo por mí, sería mejor que no asumieran esa idea. De esta manera, el estudio de estos textos sería un poco menos denso.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="tópicos-básicos.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ModelosBayesianos.pdf", "ModelosBayesianos.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
