<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 1 Tópicos básicos | Modelos Bayesianos con R y STAN</title>
  <meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 1 Tópicos básicos | Modelos Bayesianos con R y STAN" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="github-repo" content="psirusteam/bookdownBayesiano" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 1 Tópicos básicos | Modelos Bayesianos con R y STAN" />
  
  <meta name="twitter:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />


<meta name="date" content="2021-05-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="inferencia-bayesiana.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Bayesianos con R y STAN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a></li>
<li class="chapter" data-level="1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html"><i class="fa fa-check"></i><b>1</b> Tópicos básicos</a>
<ul>
<li class="chapter" data-level="1.1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html#teoría-de-la-decisión"><i class="fa fa-check"></i><b>1.1</b> Teoría de la decisión</a></li>
<li class="chapter" data-level="1.2" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html#algunos-resultados-de-probabilidad"><i class="fa fa-check"></i><b>1.2</b> Algunos resultados de probabilidad</a></li>
<li class="chapter" data-level="1.3" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html#teorema-de-bayes"><i class="fa fa-check"></i><b>1.3</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html"><i class="fa fa-check"></i><b>2</b> Inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#información-previa"><i class="fa fa-check"></i><b>2.1</b> Información previa</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>2.1.1</b> Distribuciones conjugadas</a></li>
<li class="chapter" data-level="2.1.2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#familia-exponencial"><i class="fa fa-check"></i><b>2.1.2</b> Familia exponencial</a></li>
<li class="chapter" data-level="2.1.3" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#distribuciones-previas-no-informativas"><i class="fa fa-check"></i><b>2.1.3</b> Distribuciones previas no informativas</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#pruebas-de-hipótesis"><i class="fa fa-check"></i><b>2.2</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#factor-de-bayes"><i class="fa fa-check"></i><b>2.2.1</b> Factor de Bayes</a></li>
<li class="chapter" data-level="2.2.2" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#valor-p-bayesiano"><i class="fa fa-check"></i><b>2.2.2</b> Valor <span class="math inline">\(p\)</span> Bayesiano</a></li>
<li class="chapter" data-level="2.2.3" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#criterio-dic"><i class="fa fa-check"></i><b>2.2.3</b> Criterio DIC</a></li>
<li class="chapter" data-level="2.2.4" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#criterio-aic-y-bic"><i class="fa fa-check"></i><b>2.2.4</b> Criterio AIC y BIC</a></li>
<li class="chapter" data-level="2.2.5" data-path="inferencia-bayesiana.html"><a href="inferencia-bayesiana.html#acerca-de-la-notación"><i class="fa fa-check"></i><b>2.2.5</b> Acerca de la notación</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a Modelos Bayesianos con R y STAN</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Bayesianos con R y STAN</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tópicos-básicos" class="section level1" number="1">
<h1><span class="header-section-number">Capítulo 1</span> Tópicos básicos</h1>
<div id="teoría-de-la-decisión" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Teoría de la decisión</h2>
<p>El problema estadístico de estimar un parámetro se puede ver dentro del contexto de la teoría de decisión: la estimación que proveemos, sea en el ámbito de la estadística clásica o la estadística bayesiana, depende de los datos muestrales, <span class="math inline">\(\mathbf{X}\)</span>, de tal forma que si éstos cambian, la estimación también cambia. De esta manera, el proceso de estimación puede ser representado como una función que toma un conjunto de datos muestrales y los convierte en una estimación (<span class="math inline">\(A(\mathbf{X})\)</span> o simplemente <span class="math inline">\(A\)</span>) del parámetro de interés. En la teoría de decisión, la anterior función se conoce como una regla de decisión.</p>
<p>Así como en la vida cotidiana, por la incertidumbre del futuro (en el ámbito estadístico, por la incertidumbre acerca del parámetro), toda acción que se tome (toda estimación que se provea) puede traer consigo un grado de falla o riesgo. Y es necesario escoger la acción óptima que de alguna forma minimice ese riesgo. Formalizando esta idea intuitiva, se define la función de pérdida <span class="math inline">\(L\)</span> que asocia a cada dupla conformada por la acción tomada y el parámetro de interés <span class="math inline">\(\theta\)</span>, <span class="math inline">\((A, \ \theta)\)</span> con un número no negativo que cuantifica la pérdida que ocasiona la acción (o la estimación) <span class="math inline">\(A\)</span> con respecto al parámetro <span class="math inline">\(\theta\)</span>.</p>
<p>Es claro que se desea escoger aquella acción que minimice de alguna forma la pérdida que ésta ocasiona, pero la función <span class="math inline">\(L\)</span> no se puede minimizar directamente, puesto que:</p>
<ul>
<li><p>En el ámbito de la estadística clásica, el parámetro <span class="math inline">\(\theta\)</span> se considera fijo, y los datos muestrales <span class="math inline">\(\mathbf{X}\)</span> aleatorios. Como la función de pérdida <span class="math inline">\(L\)</span> depende de <span class="math inline">\(\mathbf{X}\)</span>, entonces ésta también será una variable aleatoria, y no se puede minimizar directamente. Por lo tanto se define el riesgo o la pérdida promedio como la esperanza matemática de <span class="math inline">\(L\)</span>; denotando el riesgo como <span class="math inline">\(R\)</span>, éste está definido como <span class="math inline">\(R=E(L)\)</span> (la esperanza se toma con respecto a la distribución probabilística de <span class="math inline">\(\mathbf{X}\)</span>).</p></li>
<li><p>En el ámbito de la estadística bayesiana, <span class="math inline">\(\theta\)</span> sigue siendo una cantidad fija, pero la incertidumbre que tiene el investigador sobre la localización del parámetro se puede modelar mediante funciones de probabilidad. La herramienta fundamental para conocer características de <span class="math inline">\(\theta\)</span> es su función de densidad posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>. En este caso, el riesgo <span class="math inline">\(R\)</span> se define como</p></li>
</ul>
<p><span class="math display">\[\begin{equation*}
R=E(L)=\int L(A, \theta)p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>En cualquiera de los dos casos anteriores, se busca la estimación que minimice el riesgo <span class="math inline">\(R\)</span>. Ilustramos los anteriores conceptos en los siguientes ejemplos tanto en la estadística clásica como en la estadística bayesiana.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-1" class="example"><strong>Ejemplo 1.1  </strong></span>Sea <span class="math inline">\(X_i\)</span> con <span class="math inline">\(i=1,\cdots, n\)</span> una muestra aleatoria con media <span class="math inline">\(\theta\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>, ambas fijas, y suponga que se desea encontrar el mejor estimador de <span class="math inline">\(\theta\)</span> bajo la función de pérdida cuadrática dada por</p>
<p><span class="math display">\[\begin{equation*}
L(A,\theta)=(A-\theta)^2
\end{equation*}\]</span></p>
<p>cuyo riesgo asociado está dado por <span class="math inline">\(R=E(A-\theta)^2\)</span>. En primer lugar, buscaremos dicho estimador dentro de todas las formas lineales de <span class="math inline">\(X_i\)</span>, es decir, los estimadores de la forma <span class="math inline">\(A=\sum_{i=1}^nc_iX_i\)</span>. Por tanto, el riesgo se puede expresar como
<span class="math display">\[\begin{align*}
R=E(A-\theta)^2&amp;=Var(A)+(E(A)-\theta)^2\\
&amp;=\sum_{i=1}^nc_i^2\sigma^2+\theta^2(\sum_{i=1}^nc_i-1)^2
\end{align*}\]</span></p>
<p>Y al buscar los coeficientes <span class="math inline">\(c_i\)</span> que minimizan la anterior expresión, encontramos que <span class="math inline">\(c_i=\theta^2/(\sigma^2+n\theta^2)\)</span> para todo <span class="math inline">\(i\)</span>. Como estos coeficientes conducen a un estimador que depende del parámetro desconocido, concluimos que no hay ningún estimador que minimiza el riesgo.</p>
Para encontrar una solución, es necesario restringir aún más el rango de estimadores; para eso, se impone la restricción de que <span class="math inline">\(\sum_{i=1}^nc_i=1\)</span>. De esta forma, el riesgo está dado por <span class="math inline">\(R=\sum c_i^2\sigma^2\)</span>. Dado que <span class="math inline">\(\sigma^2\)</span> es fijo, al minimizar <span class="math inline">\(\sum c_i^2\)</span> sujeto a la restricción, se tiene que la solución es <span class="math inline">\(c_i=1/n\)</span> para todo <span class="math inline">\(i\)</span>, y así encontramos que el mejor estimador (en el sentido de minimizar el riesgo de la función de pérdida cuadrática) dentro de todas las formas lineales con <span class="math inline">\(\sum c_i=1\)</span> es la media muestral <span class="math inline">\(\bar{X}\)</span>.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-2" class="example"><strong>Ejemplo 1.2  </strong></span>Suponga que se desea estimar un parámetro de interés <span class="math inline">\(\theta\)</span> en el contexto de la estadística bayesiana y denotamos la función de densidad posterior de <span class="math inline">\(\theta\)</span> como <span class="math inline">\(p(\theta|\mathbf{X})\)</span>, entonces si utilizamos la función de pérdida cuadrática, el riesgo asociado será</p>
<p><span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))=E (A-\theta)^2=Var(\theta)+(E(\theta)-A)^2
\end{align*}\]</span></p>
que es minimizado si <span class="math inline">\(A=E(\theta)\)</span>. Es decir, la mejor acción para estimar <span class="math inline">\(\theta\)</span> es utilizar la esperanza de <span class="math inline">\(\theta\)</span> tomada con respecto a la distribución posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Ejemplo 1.3  </strong></span>En el mismo contexto del ejemplo anterior, si cambiamos la función de pérdida a la siguiente
<span class="math display">\[\begin{equation*}
L(A,\theta)=|A-\theta|=(A-\theta)I_{(A\geq\theta)}+(\theta-A)I_{(\theta&gt;A)}
\end{equation*}\]</span></p>
<p>El riesgo estará dado por
<span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))\\
&amp;=\int L(A,\theta)p(\theta|\mathbf{X})d\theta\\
&amp;=\int_{(A\geq\theta)}(A-\theta)p(\theta|\mathbf{X})d\theta+\int_{(\theta&gt;A)}(\theta-A)p(\theta|\mathbf{X})d\theta
\end{align*}\]</span></p>
<p>Derivando el riesgo con respecto a la acción <span class="math inline">\(A\)</span>, se tiene que
<span class="math display">\[\begin{equation*}
\frac{\partial R}{\partial A}=\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta-\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>Igualando a cero, tenemos que
<span class="math display">\[\begin{equation*}
\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta=\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta=0.5
\end{equation*}\]</span></p>
Y concluimos que la acción <span class="math inline">\(A\)</span> que induce menor riesgo corresponde al percentil 50% o la mediana de la distribución posterior de <span class="math inline">\(\theta\)</span>.
</div>
<p><br></p>
<p>De los anteriores ejemplos se observa que, bajo un mismo contexto, cuando se utilizan diferentes funciones de pérdida, también se obtienen distintas estimaciones, y distintas acciones que optimizan el riesgo.</p>
</div>
<div id="algunos-resultados-de-probabilidad" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Algunos resultados de probabilidad</h2>
<p>Para entender los fundamentos de la modelación bayesiana, es necesario
recordar algunas definiciones y resultados de la teoría de probabilidad
que ayudarán a hacer más expedito este periplo por la estadística
bayesiana. En términos de notación, se utilizará indistintamente la
expresión de integral, <span class="math inline">\(\int\)</span>, indicando la sumatoria, en el caso de las
variables aleatorias discretas o la integral de Riemann-Stieltjes en el
caso de las variables aleatorias continuas.</p>

<div class="definition">
<span id="def:unnamed-chunk-4" class="definition"><strong>Definición 1.1  </strong></span>Sean <span class="math inline">\(\mathbf{X}=(X_1,\ldots,X_p)&#39;\)</span>, <span class="math inline">\(\mathbf{Y}=(Y_1,\ldots,Y_q)&#39;\)</span> dos vectores aleatorios definidos sobre los espacios de muestreo <span class="math inline">\(\mathcal{X}\)</span>, <span class="math inline">\(\mathcal{Y}\)</span>, respectivamente. Suponga que la distribución conjunta de estos vectores aleatorios está dada por <span class="math inline">\(p(\mathbf{X},\mathbf{Y})\)</span>. La distribución marginal de <span class="math inline">\(\mathbf{X}\)</span> está dada por
<span class="math display">\[\begin{equation}
p(\mathbf{X})=\int p(\mathbf{X},\mathbf{Y})\ d\mathbf{Y}
\end{equation}\]</span>
y la distribución condicional de <span class="math inline">\(\mathbf{X}\)</span> dado <span class="math inline">\(\mathbf{Y}\)</span> como
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Y})
=\frac{p(\mathbf{X},\mathbf{Y})}{p(\mathbf{Y})}
\end{equation}\]</span>
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-5" class="proposition"><strong>Resultado 1.1  </strong></span>Suponga los vectores <span class="math inline">\(\mathbf{X}\)</span>, <span class="math inline">\(\mathbf{Y}\)</span> y un tercer vector <span class="math inline">\(\mathbf{Z}=(Z_1,\ldots,Z_r)&#39;\)</span> definido sobre el espacio de muestreo <span class="math inline">\(\mathcal{Z}\)</span>. Entonces se tiene que
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Z})=\int p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})\ d\mathbf{Y}
\end{equation}\]</span>
y
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}
\end{equation}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> En primer lugar, nótese que
<span class="math display">\[\begin{align*}
\int p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})\ d\mathbf{Y}&amp;=
\int \frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}\ d\mathbf{Y}\\
&amp;=\frac{1}{p(\mathbf{Z})} \int p(\mathbf{X},\mathbf{Y},\mathbf{Z}) \ d\mathbf{Y}\\
&amp;=\frac{1}{p(\mathbf{Z})} p(\mathbf{X},\mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})
\end{align*}\]</span></p>
<p>Por otro lado,</p>
<span class="math display">\[\begin{align*}
\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}=
\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})} \diagup
\frac{p(\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}
=\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}=p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})
\end{align*}\]</span>
</div>

<div class="definition">
<span id="def:unnamed-chunk-7" class="definition"><strong>Definición 1.2  </strong></span>Sean <span class="math inline">\(\mathbf{X}\)</span>, <span class="math inline">\(\mathbf{Y}\)</span>, <span class="math inline">\(\mathbf{Z}\)</span> vectores aleatorios, se dice que <span class="math inline">\(\mathbf{X}\)</span> es condicionalmente independiente de <span class="math inline">\(\mathbf{Y}\)</span> con respecto a <span class="math inline">\(\mathbf{Z}\)</span> si satisfacen la siguiente expresión
<span class="math display">\[\begin{equation}
p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})
\end{equation}\]</span>
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-8" class="proposition"><strong>Resultado 1.2  </strong></span>Si <span class="math inline">\(\mathbf{X}\)</span> es condicionalmente independiente de <span class="math inline">\(\mathbf{Y}\)</span> con respecto a <span class="math inline">\(\mathbf{Z}\)</span>, entonces se tiene que
<span class="math display">\[\begin{equation}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})
\end{equation}\]</span>
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Como <span class="math inline">\(p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})=\dfrac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Z})}\)</span>, entonces</p>
<span class="math display">\[\begin{align*}
p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})=\frac{p(\mathbf{X},\mathbf{Y},\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}
=\frac{p(\mathbf{X},\mathbf{Y} \mid \mathbf{Z})p(\mathbf{Z})}{p(\mathbf{Y},\mathbf{Z})}
=\frac{p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})}{p(\mathbf{Y} \mid \mathbf{Z})}=p(\mathbf{X} \mid \mathbf{Z})
\end{align*}\]</span>
</div>

<div class="proposition">
<span id="prp:unnamed-chunk-10" class="proposition"><strong>Resultado 1.3  </strong></span>Si <span class="math inline">\(\mathbf{X}\)</span> es independiente de <span class="math inline">\(\mathbf{Y}\)</span>, entonces <span class="math inline">\(\mathbf{X}\)</span> es condicionalmente independiente de <span class="math inline">\(\mathbf{Y}\)</span> dado cualquier otro vector <span class="math inline">\(\mathbf{Z}\)</span>.
</div>

<div class="proof">
<p> <span class="proof"><em>Prueba. </em></span> Nótese que
<span class="math display">\[\begin{equation*}
p(\mathbf{X},\mathbf{Y}\mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Y},\mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})=p(\mathbf{X} \mid \mathbf{Z})p(\mathbf{Y} \mid \mathbf{Z})
\end{equation*}\]</span></p>
puesto que, utilizando la hipótesis de independencia, se tiene que
<span class="math display">\[\begin{equation*}
p(\mathbf{X} \mid \mathbf{Y})=p(\mathbf{X})
\end{equation*}\]</span>
</div>
</div>
<div id="teorema-de-bayes" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Teorema de Bayes</h2>
<p>Desde la revolución estadística de Pearson y Fisher, la inferencia
estadística busca encontrar los valores que parametrizan a la
distribución desconocida de los datos. El primer enfoque, propuesto por
Pearson, afirmaba que si era posible observar a la variable de interés
en todos y cada uno de los individuos de una población, entonces era
posible calcular los parámetros de la distribución de la variable de
interés; por otro lado, si solo se tenía acceso a una muestra
representativa, entonces era posible calcular una estimación de tales
parámetros. Sin embargo, Fisher discrepó de tales argumentos, asumiendo
que las observaciones están sujetas a un error de medición y por lo
tanto, así se tuviese acceso a toda la población, sería imposible calcular
los parámetros de la distribución de la variable de interés.</p>
<p>Del planteamiento de Fisher resultaron una multitud de métodos
estadísticos para la estimación de los parámetros poblacionales. Es
decir, si la distribución de <span class="math inline">\(\mathbf{Y}\)</span> está parametrizada por
<span class="math inline">\(\boldsymbol \theta=(\theta_1,\ldots,\theta_K)\)</span>, <span class="math inline">\(\boldsymbol \theta\in \Theta\)</span> con <span class="math inline">\(\Theta\)</span>
el espacio paramétrico inducido por el comportamiento de la variable de
interés, el objetivo de la teoría estadística inferencial es calcular
una estimación <span class="math inline">\(\hat{\boldsymbol \theta}\)</span> del parámetro <span class="math inline">\(\boldsymbol \theta\)</span>, por medio de los
datos observados. En este enfoque, los parámetros se consideran
cantidades fijas y constantes. Sin embargo, en la última mitad del siglo
XX, algunos investigadores estadísticos comenzaron a reflexionar acerca
de la naturaleza de <span class="math inline">\(\boldsymbol \theta\)</span> y enfocaron la inferencia estadística de
una manera distinta: <em>asumiendo que la distribución de la variable de
interés está condicionada a valores específicos de los parámetros</em>. Es
decir, en términos de notación, si la variable de interés es
<span class="math inline">\(\mathbf{Y}\)</span>, su distribución condicionada a los parámetros toma la
siguiente forma <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span>. Esto implica claramente
que en este nuevo enfoque la naturaleza de los parámetros no es
constante.</p>
<p>En términos de inferencia para <span class="math inline">\(\boldsymbol \theta\)</span>, es necesario encontrar la
distribución de los parámetros condicionada a la observación de los
datos. Para este fin, es necesario definir la distribución conjunta de
la variable de interés con el vector de parámetros.
<span class="math display">\[\begin{equation*}
p(\boldsymbol \theta,\mathbf{Y})=p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)
\end{equation*}\]</span></p>
<p>A la distribución <span class="math inline">\(p(\boldsymbol \theta)\)</span> se le conoce con el nombre de
distribución <em>previa</em> y en ella se enmarcan todas y cada una de las
creencias que se tienen acerca del comportamiento estocástico del vector
de parámetros antes de que ocurra la recolección de los datos; <span class="math inline">\(p(\mathbf{Y} \mid \boldsymbol \theta)\)</span> es la distribución de muestreo,
verosimilitud o distribución de los datos. Por otro lado, la
distribución del vector de parámetros condicionada a los datos
observados está dada por</p>
<p><span class="math display" id="eq:Bayes">\[\begin{equation}
\tag{1.1}
p(\boldsymbol \theta\mid \mathbf{Y})=\frac{p(\boldsymbol \theta,\mathbf{Y})}{p(\mathbf{Y})}=\frac{p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)}{p(\mathbf{Y})}
\end{equation}\]</span></p>
<p>A la distribución <span class="math inline">\(p(\boldsymbol \theta\mid \mathbf{Y})\)</span> se le conoce con el
nombre de distribución <em>posterior</em> y en ella se enmarcan las
creencias actualizadas acerca del comportamiento estocástico del vector
de parámetros teniendo en cuenta los datos observados <span class="math inline">\(\mathbf{Y}\)</span>.
Nótese que la expresión <a href="tópicos-básicos.html#eq:Bayes">(1.1)</a> se compone de una fracción cuyo
denominador no depende del vector de parámetros y considerando a los
datos observados como fijos, corresponde a una constante y puede ser
obviada. Por lo tanto, otra representación de la regla de Bayes está
dada por</p>
<p><span class="math display" id="eq:Bayes1">\[\begin{align}
\tag{1.2}
p(\boldsymbol \theta\mid \mathbf{Y})\propto p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta)
\end{align}\]</span></p>
<p><span class="citation"><a href="inferencia-bayesiana.html#ref-Gelman03" role="doc-biblioref">Gelman et al.</a> (<a href="inferencia-bayesiana.html#ref-Gelman03" role="doc-biblioref">2003</a>)</span> menciona que esta expresión se conoce como la
distribución <em>posterior no-normalizada</em> y encierra el núcleo
técnico de la inferencia bayesiana. La constante <span class="math inline">\(p(\mathbf{Y})\)</span>
faltante en la expresión <a href="tópicos-básicos.html#eq:Bayes1">(1.2)</a> se da a continuación.</p>

<div class="proposition">
<span id="prp:unnamed-chunk-12" class="proposition"><strong>Resultado 1.4  </strong></span>La expresión <span class="math inline">\(p(\mathbf{Y})\)</span> corresponde a una constante <span class="math inline">\(k\)</span> tal que
<span class="math display">\[\begin{equation*}
k=p(\mathbf{Y})=E_{\boldsymbol \theta}[p(Y \mid \boldsymbol \theta)]
\end{equation*}\]</span>
</div>

<div class="proof">
 <span class="proof"><em>Prueba. </em></span> Nótese que
<span class="math display">\[\begin{equation*}
k=p(\mathbf{Y})=\int p(\mathbf{Y},\boldsymbol \theta)\ d\boldsymbol \theta=\int p(\boldsymbol \theta)p(\mathbf{Y} \mid \boldsymbol \theta)\ d\boldsymbol \theta.
\end{equation*}\]</span>
entonces
<span class="math display">\[\begin{align*}
k&amp;=\int p(\mathbf{Y} \mid \boldsymbol \theta)p(\boldsymbol \theta)\ d\boldsymbol \theta\\
&amp;=E_{\boldsymbol \theta}[p(Y \mid \boldsymbol \theta)]
\end{align*}\]</span>
</div>
<p>Curiosamente, el reverendo Thomas Bayes nunca publicó este resultado,
sino que después de su fallecimiento, su amigo el filósofo Richard
Price, encontró los escritos dentro de sus pertenencias, y éstos fueron
publicados en el 1764 en
<em>Philosophical Transactions of the Royal Society of London</em>. Aunque
el teorema de Bayes fue nombrado en honor de Thomas Bayes, es casi
seguro que él mismo no sospechaba del gran impacto de su resultado. De hecho, aproximadamente una década más tarde, Pierre-Simon Laplace también descrubrió el mismo principio, y dedicó gran parte de su vida extendiéndolo y formalizándolo. Más aún, él analizó grandes volumenes de datos relacionados a los nacimientos en diferentes paises para confirmar esta teoría, y sentó las bases de la estadística bayesiana.</p>
<p>A continuación se presenta un ejemplo simple de este sencillo pero
poderoso teorema.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-14" class="example"><strong>Ejemplo 1.4  </strong></span>Suponga que una fábrica del sector industrial produce bolígrafos y que la producción está a cargo de tres máquinas. La primera máquina produce el 50% del total de bolígrafos en el año, la segunda máquina produce el 30% y la última maquina produce el restante 20%. Por supuesto, esta producción esta sujeta al error y por tanto, basados en la experiencia, es posible reconocer que, de los artículos producidos por la primera máquina, el 5% resultan defectuosos; de los artículos producidos por la segunda máquina, el 2% resultan defectuosos y, de los artículos producidos por la última máquina, el 6% resultan defectuosos.</p>
<p>FIGURA - Fabrica1.pdf</p>
<p>Una pregunta natural que surge es acerca de la probabilidad de selección de un artículo defectuoso y para responder a esta pregunta con rigurosidad de probabilística es necesario enfocar la atención en los tópicos básicos que dejamos atrás. En primer lugar, el experimento en cuestión es la selección de un bolígrafo. Para este experimento, una terna <span class="math inline">\((\Omega, \mathfrak{F}, P)\)</span>,<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> llamada comúnmente espacio de medida o espacio de probabilidad, está dada por</p>
<ol style="list-style-type: decimal">
<li>El espacio muestral: <span class="math inline">\(\Omega=\{\text{defectuoso}, \text{No defectouso}\}\)</span></li>
<li>La <span class="math inline">\(\sigma\)</span>-álgebra: <span class="math inline">\(\mathfrak{F}=\{\Omega, \phi, \{\text{Defectuoso}\}, \{\text{No Defectuoso}\}\}\)</span></li>
<li>La función de probabilidad:
<span class="math display">\[\begin{align*}
  p: \mathfrak{F} &amp;\longrightarrow [0,1]\\
  \Omega &amp;\longrightarrow 1\\
  \phi &amp;\longrightarrow 0\\
  \{Defectuoso\}&amp;\longrightarrow P(D)\\
  \{No Defectuoso\}&amp;\longrightarrow 1-P(D)
  \end{align*}\]</span>
en donde, acudiendo al teorema de probabilidad total, se define
<span class="math display">\[\begin{equation*}
  p(D)=p(D \mid M1)P(M1)+p(D \mid M2)P(M2)+p(D \mid M3)P(M3)
  \end{equation*}\]</span></li>
</ol>
<p>Sin embargo, también es posible plantearse otro tipo de preguntas que sirven para calibrar el proceso de producción de artículos defectuosos. Por ejemplo, cabe preguntarse acerca de la probabilidad de que, habiendo seleccionado un artículo defectuoso, éste provenga de la primera máquina<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a>. En esta ocasión, el experimento ha cambiado y ahora se trata de seleccionar un artículo defectuoso y para responder a tal cuestionamiento, se debe establecer rigurosamente el espacio de probabilidad que puede estar dado por</p>
<ol style="list-style-type: decimal">
<li>El espacio muestral: <span class="math inline">\(\Omega=\{M1, M2, M3 \}\)</span></li>
<li>La <span class="math inline">\(\sigma\)</span>-álgebra: <span class="math inline">\(\mathfrak{F}^+=\{\Omega, \phi, \{M1\}, \{M2,M3\}\}\)</span></li>
<li>La función de probabilidad:
<span class="math display">\[\begin{align*}
  p: \mathfrak{F}^+ &amp;\longrightarrow [0,1]\\
  \Omega &amp;\longrightarrow 1\\
  \phi &amp;\longrightarrow 0\\
  \{M1\}&amp;\longrightarrow p(M1 \mid D)\\
  \{M2,M3\}&amp;\longrightarrow 1-p(M1 \mid D)
  \end{align*}\]</span>
en donde, acudiendo a la probabilidad condicional, se define
<span class="math display">\[\begin{equation*}
  p(M1 \mid D)=\frac{p(D \mid M1)P(M1)}{p(D \mid M1)P(M1)+p(D \mid M2)P(M2)+p(D \mid M3)P(M3)}
  \end{equation*}\]</span></li>
</ol>
<p>La anterior función de probabilidad se conoce con el nombre de regla de probabilidad de Bayes y, aparte de ser el baluarte de la mayoría de investigaciones estadísticas que se plantean hoy en día, ha sido la piedra de tropiezo de muchos investigadores radicales que trataron de estigmatizar este enfoque tildando a sus seguidores de mediocres matemáticos y pobres probabilistas afirmando que la regla de probabilidad de Bayes es sólo un artilugio diseñado para divertirse en el tablero.</p>
Pues bien, la interpretación de la regla de bayes se puede realizar en el sentido de actualización de la estructura probabilística que gobierna el experimento. Y esta actualización tiene mucho sentido práctico cuando se cae en la cuenta de que la vida real está llena de calibradores y que las situaciones generadas son consecuencia de algún cambio estructural. De esta forma, el conocimiento de la probabilidad de que el artículo sea producido por la primera máquina se actualiza al conocer que este artículo particular es defectuoso y de esta manera calibra la estructura aleatoria que existe detrás del contexto de la fábrica de bolígrafos. Aparte de servir para resolver problemas como el anteriormente mencionado, la regla de bayes ha marcado el comienzo de un nuevo enfoque de análisis de datos, no solamente porque hace explícitas las relaciones causales entre los procesos aleatorios, sino también porque facilita la inferencia estadística y la interpretación de los resultados.
</div>
<p><br>
En el campo de la medicina, también se ha visto un gran número de la
aplicación del teorema de Bayes. A continuación se enuncia uno de ellos:</p>

<div class="example">
<p><span id="exm:unnamed-chunk-15" class="example"><strong>Ejemplo 1.5  </strong></span>El Grupo de Trabajo de Servicios Preventivos de los Estados Unidos (USPSTF) hizo unas nuevas y controversiales recomendaciones <a href="https://www.uspreventiveservicestaskforce.org/uspstf/recommendation/breast-cancer-screening">recomendaciones</a> sobre la detección del cáncer de mama dentro de los cuales no recomienda el examen de la mamografía en mujeres entre 40 y 49 años de edad, afirmando que la práctica bienal de este examen debe ser una decisión individual según el contexto particular de la paciente. Por otro lado, la USPSTF sí recomienda tal práctica de forma bienal en grupos de mujeres de entre 50 y 74 años de edad, puesto que no encontró suficiente evidencia de beneficio o daño adicional en realizar este examen en mujeres mayores a los 74 años. Además, también recomendó <em>no</em> realizar auto exámanes de senos, contrario a las recomendaciones y consejos que da la mayoría de los profesionales y organizaciones de la salud, incluyendo la <em>Amerian Cancer Society</em>. Como información adicional, se sabe que:</p>
<ul>
<li>Los expertos estiman que un 12.3% de las mujeres desarrollan formas invasivas del cáncer de mama durante la vida.</li>
<li>La probabilidad de que una mujer desarrolle el cáncer de mama entre los 40 y los 49 años de edad es 1 en 69, y esta probabilidad aumenta a medida que envejezca, de tal forma que llega a ser de 1 en 38 en mujeres de entre 50 y 59 años.</li>
<li>El cáncer de mama es más difícil de detectar en mujeres jóvenes puesto que el tejido mamario es más denso y fibroso. Los expertos estiman que la tasa de un falso positivo es de 97.8 por cada 1000 mujeres de 40 y 49 años, y esta tasa disminuye a 86.6 por cada 1000 mujeres entre 50 y 59 años.</li>
<li>La tasa de un falso negativo es de 1 por cada 1000 mujeres de 40 y 49 años, y es de 1.1 por cada 1000 mujeres entre 50 y 59 años.</li>
</ul>
<p>Resumiendo las anteriores afirmaciones, tenemos las siguientes probabilidades</p>
<table>
<thead>
<tr class="header">
<th>Probabilidad</th>
<th>40 - 49</th>
<th>50 - 59 años</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cáncer</td>
<td>1/69=0.01449</td>
<td>1/38=0.02632</td>
</tr>
<tr class="even">
<td>No cáncer</td>
<td>68/69=0.9855</td>
<td>37/38=0.97368</td>
</tr>
<tr class="odd">
<td>Positivo <span class="math inline">\(\mid\)</span> No cáncer</td>
<td>0.0978</td>
<td>0.0866</td>
</tr>
<tr class="even">
<td>Negativo <span class="math inline">\(\mid\)</span> No cáncer</td>
<td>0.9022</td>
<td>0.9134</td>
</tr>
<tr class="odd">
<td>Positivo <span class="math inline">\(\mid\)</span> Cáncer</td>
<td>0.999</td>
<td>0.9989</td>
</tr>
<tr class="even">
<td>Negativo <span class="math inline">\(\mid\)</span> Cáncer</td>
<td>0.001</td>
<td>0.0011</td>
</tr>
</tbody>
</table>
<p>Utilizando la regla de Bayes, se puede calcular las siguientes probabilidades para mujeres de 40 y 49 años:
<span class="math display">\[\begin{align*}
P(\text{Cáncer}|\text{Positivo})&amp;=\frac{P(\text{Positivo}|\text{Cáncer})P(\text{Cáncer})}{P(\text{Positivo}|\text{Cáncer})P(\text{Cáncer})+P(\text{Positivo}|\text{No cáncer})P(\text{No cáncer})}\\
&amp;=\frac{0.999*0.01449}{0.999*0.01449+0.0978*0.9855}\\
&amp;=0.1305
\end{align*}\]</span></p>
<p><span class="math display">\[\begin{align*}
P(\text{Cáncer}|\text{Negativo})&amp;=\frac{P(\text{Negativo}|\text{Cáncer})P(\text{Cáncer})}{P(\text{Negativo}|\text{Cáncer})P(\text{Cáncer})+P(\text{Negativo}|\text{No cáncer})P(\text{No cáncer})}\\
&amp;=\frac{0.001*0.01449}{0.001*0.01449+0.9022*0.9855}\\
&amp;=0.0000163
\end{align*}\]</span></p>
<p>Similarmente, se puede calcular estas dos probabilidades para las mujeres de 50 y 59 años.</p>
<table>
<thead>
<tr class="header">
<th>Probabilidad</th>
<th>40 - 49 años</th>
<th>50 - 59 años</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Cáncer <span class="math inline">\(\mid\)</span> Positivo</td>
<td>0.1305985</td>
<td>0.23769</td>
</tr>
<tr class="even">
<td>No cáncer <span class="math inline">\(\mid\)</span> Positivo</td>
<td>0.8694223</td>
<td>0.7623123</td>
</tr>
<tr class="odd">
<td>Cáncer <span class="math inline">\(\mid\)</span> Negativo</td>
<td>0.0000163</td>
<td>0.0000326</td>
</tr>
<tr class="even">
<td>No cáncer <span class="math inline">\(\mid\)</span> Negativo</td>
<td>0.9999837</td>
<td>0.9999674</td>
</tr>
</tbody>
</table>
Los anteriores resultados muestran cómo cambia la probabilidad de tener cáncer al condicionar en los resultados de la pruebe. Entre estos valores se puede ver que, con un resultado positivo en el examen, la probabilidad de tener efectivamente el cáncer es aproximadamente diez puntos porcentuales más bajo en mujeres de edad de 40 y 49 años, de donde se puede sustentar la recomendación de no efectuar este examen en mujeres de este rango de edad.
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p><span class="math inline">\(\Omega\)</span> denota el conjunto de todos lo posibles resultados del experimento, <span class="math inline">\(\mathfrak{F}\)</span> denota una <span class="math inline">\(\sigma\)</span>-álgebra y <span class="math inline">\(P\)</span> hace referencia ana medida de probabilidad propiamente definida.<a href="tópicos-básicos.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Por supuesto que la pregunta también es válida al indagar por la probabilidad de que habiendo seleccionado un artículo defectuoso, éste provenga de la segunda o tercera máquina.<a href="tópicos-básicos.html#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="inferencia-bayesiana.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ModelosBayesianos.pdf", "ModelosBayesianos.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
