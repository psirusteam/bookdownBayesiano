<!DOCTYPE html>
<html lang="es" xml:lang="es">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 2 Tópicos básicos | Modelos Bayesianos con R y STAN</title>
  <meta name="description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 2 Tópicos básicos | Modelos Bayesianos con R y STAN" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  <meta name="github-repo" content="psirusteam/bookdownBayesiano" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Tópicos básicos | Modelos Bayesianos con R y STAN" />
  
  <meta name="twitter:description" content="Este es el repositorio del libro Modelos Bayesianos con R y STAN." />
  

<meta name="author" content="Andrés Gutiérrez - Hanwen Zhang" />


<meta name="date" content="2021-05-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="algunos-resultados-de-probabilidad.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelos Bayesianos con R y STAN</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Prefacio</a></li>
<li class="chapter" data-level="2" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html"><i class="fa fa-check"></i><b>2</b> Tópicos básicos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tópicos-básicos.html"><a href="tópicos-básicos.html#teoría-de-la-decisión"><i class="fa fa-check"></i><b>2.1</b> Teoría de la decisión</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html"><i class="fa fa-check"></i><b>3</b> Algunos resultados de probabilidad</a>
<ul>
<li class="chapter" data-level="3.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#teorema-de-bayes"><i class="fa fa-check"></i><b>3.1</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="3.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia-bayesiana"><i class="fa fa-check"></i><b>3.2</b> Inferencia bayesiana</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia"><i class="fa fa-check"></i><b>3.2.1</b> Inferencia </a></li>
<li class="chapter" data-level="3.2.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia-1"><i class="fa fa-check"></i><b>3.2.2</b> Inferencia </a></li>
<li class="chapter" data-level="3.2.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#inferencia-predictiva"><i class="fa fa-check"></i><b>3.2.3</b> Inferencia predictiva</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#información"><i class="fa fa-check"></i><b>3.3</b> Información </a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#distribuciones-conjugadas"><i class="fa fa-check"></i><b>3.3.1</b> Distribuciones conjugadas</a></li>
<li class="chapter" data-level="3.3.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#familia-exponencial"><i class="fa fa-check"></i><b>3.3.2</b> Familia exponencial</a></li>
<li class="chapter" data-level="3.3.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#distribuciones-no-informativas"><i class="fa fa-check"></i><b>3.3.3</b> Distribuciones  no informativas</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#pruebas-de-hipótesis"><i class="fa fa-check"></i><b>3.4</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#factor-de-bayes"><i class="fa fa-check"></i><b>3.4.1</b> Factor de Bayes</a></li>
<li class="chapter" data-level="3.4.2" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#valor-p-bayesiano"><i class="fa fa-check"></i><b>3.4.2</b> Valor <span class="math inline">\(p\)</span> Bayesiano</a></li>
<li class="chapter" data-level="3.4.3" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#criterio-dic"><i class="fa fa-check"></i><b>3.4.3</b> Criterio DIC</a></li>
<li class="chapter" data-level="3.4.4" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#criterio-aic-y-bic"><i class="fa fa-check"></i><b>3.4.4</b> Criterio AIC y BIC</a></li>
<li class="chapter" data-level="3.4.5" data-path="algunos-resultados-de-probabilidad.html"><a href="algunos-resultados-de-probabilidad.html#acerca-de-la-notación"><i class="fa fa-check"></i><b>3.4.5</b> Acerca de la notación</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a Modelos Bayesianos con R y STAN</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelos Bayesianos con R y STAN</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="tópicos-básicos" class="section level1" number="2">
<h1><span class="header-section-number">Capítulo 2</span> Tópicos básicos</h1>
<div id="teoría-de-la-decisión" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Teoría de la decisión</h2>
<p>El problema estadístico de estimar un parámetro se puede ver dentro del contexto de la teoría de decisión: la estimación que proveemos, sea en el ámbito de la estadística clásica o la estadística bayesiana, depende de los datos muestrales, <span class="math inline">\(\mathbf{X}\)</span>, de tal forma que si éstos cambian, nuestra estimación también cambia. De esta manera, el proceso de estimación puede ser representado como una función que toma un conjunto de datos muestrales y los convierte en una estimación de nuestro parámetro de interés, <span class="math inline">\(A(\mathbf{X})\)</span> o simplemente <span class="math inline">\(A\)</span>. En la teoría de decisión, la anterior función se conoce como una regla de decisión.</p>
<p>Así como en la vida cotidiana, por la incertidumbre del futuro(en el ámbito estadístico, por la incertidumbre acerca del parámetro), toda acción que uno toma (toda estimación que uno provea) puede traer consigo un grado de falla o riesgo. Y es necesario tomar la acción óptima que de alguna forma minimice ese riesgo. Formalizando esta idea intuitiva, tenemos la función de pérdida <span class="math inline">\(L\)</span> que asocia cada dupla de la acción tomada y el parámetro de interés <span class="math inline">\(\theta\)</span>, <span class="math inline">\((A, \ \theta)\)</span> con un número no negativo que cuantifica la pérdida que ocasiona la acción (o la estimación) <span class="math inline">\(A\)</span> con respecto al parámetro <span class="math inline">\(\theta\)</span>.</p>
<p>Es claro que se desea escoger aquella acción que minimice de alguna forma la pérdida que ésta ocasiona, pero la función <span class="math inline">\(L\)</span> no se puede minimizar directamente, puesto que:</p>
<ul>
<li>En el ámbito de la estadística clásica, el parámetro <span class="math inline">\(\theta\)</span> se considera fijo, y los datos muestrales <span class="math inline">\(\mathbf{X}\)</span> aleatorios, así como la función de pérdida <span class="math inline">\(L\)</span> depende de <span class="math inline">\(\mathbf{X}\)</span>, entonces ésta también será una variable aleatoria, y no se puede minimizar directamente. Por lo tanto se define el riesgo o la pérdida promedio como la esperanza matemática de <span class="math inline">\(L\)</span>; denotando el riesgo como <span class="math inline">\(R\)</span>, éste está definido como <span class="math inline">\(R=E(L)\)</span> (la esperanza se toma con respecto a la distribución probabilística de <span class="math inline">\(\mathbf{X}\)</span>).</li>
<li>En el ámbito de la estadística bayesiana, <span class="math inline">\(\theta\)</span> es una cantidad aleatoria, y la herramienta fundamental para conocer características de <span class="math inline">\(\theta\)</span> es su función de densidad posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>. En este caso, el riesgo <span class="math inline">\(R\)</span> se define como</li>
</ul>
<p><span class="math display">\[\begin{equation*}
R=E(L)=\int L(A, \theta)p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>En cualquier de los dos casos anteriores, buscaremos la estimación que minimice el riesgo <span class="math inline">\(R\)</span>. Ilustramos los anteriores conceptos en los siguientes ejemplos tanto en la estadística clásica como en la estadística bayesiana.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-1" class="example"><strong>Example 2.1  </strong></span>Sea <span class="math inline">\(X_i\)</span> con <span class="math inline">\(i=1,\cdots, n\)</span> una muestra aleatoria con media <span class="math inline">\(\theta\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>, ambas fijas, y suponga que se desea encontrar el mejor estimador de <span class="math inline">\(\theta\)</span> bajo la función de pérdida cuadrática dada por
<span class="math display">\[\begin{equation*}
L(A,\theta)=(A-\theta)^2
\end{equation*}\]</span></p>
<p>cuyo riesgo asociado está dado por <span class="math inline">\(R=E(A-\theta)^2\)</span>. En primer lugar buscaremos dicho estimador dentro de todas las formas lineales de <span class="math inline">\(X_i\)</span>, es decir, los estimadores de la forma <span class="math inline">\(A=\sum_{i=1}^nc_iX_i\)</span>, de esta forma, el riesgo se puede expresar como
<span class="math display">\[\begin{align*}
R=E(A-\theta)^2&amp;=Var(A)+(E(A)-\theta)^2\\
&amp;=\sum_{i=1}^nc_i^2\sigma^2+\theta^2(\sum_{i=1}^nc_i-1)^2
\end{align*}\]</span></p>
<p>Y al buscar los coeficientes <span class="math inline">\(c_i\)</span> que minimizan la anterior expresión, encontramos que <span class="math inline">\(c_i=\theta^2/(\sigma^2+n\theta^2)\)</span> para todo <span class="math inline">\(i\)</span>. Como estos coeficientes conducen a un estimador que depende del parámetro desconocido, concluimos que no hay ningún estimador que minimiza el riesgo.</p>
Para encontrar una solución, es necesario restringir aún más el rango de estimadores, para eso, se restringe que <span class="math inline">\(\sum_{i=1}^nc_i=1\)</span>, de esta forma el riesgo está dado por <span class="math inline">\(R=\sum c_i^2\sigma^2\)</span>, y al minimizar <span class="math inline">\(\sum c_i^2\)</span> sujeto a la restricción de <span class="math inline">\(\sum c_i=1\)</span>. La solución está dada por <span class="math inline">\(c_i=1/n\)</span> para todo <span class="math inline">\(i\)</span>, y así encontramos que el mejor estimador (en el sentido de minimizar el riesgo de la función de pérdida cuadrática) dentro de todas formas lineales con <span class="math inline">\(\sum c_i=1\)</span> es la media muestral <span class="math inline">\(\bar{X}\)</span>.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-2" class="example"><strong>Example 2.2  </strong></span>Suponga que se desea estimar un parámetro de interés <span class="math inline">\(\theta\)</span> en el contexto de la estadística bayesiana y denotamos la función de densidad posterior de <span class="math inline">\(\theta\)</span> como <span class="math inline">\(p(\theta|\mathbf{X})\)</span>, entonces si utilizamos la función de pérdida cuadrática, entonces el riesgo asociado será
<span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))=E (A-\theta)^2=Var(\theta)+(E(\theta)-A)^2
\end{align*}\]</span></p>
que es minimizado si <span class="math inline">\(A=E(\theta)\)</span>. Es decir la mejor acción para estimar <span class="math inline">\(\theta\)</span> es utilizar la esperanza de <span class="math inline">\(\theta\)</span> tomada con respecto a la distribución posterior <span class="math inline">\(p(\theta|\mathbf{X})\)</span>.
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Example 2.3  </strong></span>En el mismo contexto del ejemplo anterior, si cambiamos la función de pérdida a la siguiente
<span class="math display">\[\begin{equation*}
L(A,\theta)=|A-\theta|=(A-\theta)I_{(A\geq\theta)}+(\theta-A)I_{(\theta&gt;A)}
\end{equation*}\]</span></p>
<p>Y el riesgo está dado por
<span class="math display">\[\begin{align*}
R&amp;=E(L(A,\theta))\\
&amp;=\int L(A,\theta)p(\theta|\mathbf{X})d\theta\\
&amp;=\int_{(A\geq\theta)}(A-\theta)p(\theta|\mathbf{X})d\theta+\int_{(\theta&gt;A)}(\theta-A)p(\theta|\mathbf{X})d\theta
\end{align*}\]</span></p>
<p>Derivando el riesgo con respecto a la acción <span class="math inline">\(A\)</span>, se tiene que
<span class="math display">\[\begin{equation*}
\frac{\partial R}{\partial A}=\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta-\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta
\end{equation*}\]</span></p>
<p>Igualando a cero, tenemos que
<span class="math display">\[\begin{equation*}
\int_{(A\geq\theta)}p(\theta|\mathbf{X})d\theta=\int_{(\theta&gt;A)}p(\theta|\mathbf{X})d\theta=0.5
\end{equation*}\]</span></p>
Y concluimos que la acción <span class="math inline">\(A\)</span> que induce menor riesgo corresponde al percentil 50% o la mediana de la distribución posterior de <span class="math inline">\(\theta\)</span>.
</div>
<p>De los anteriores ejemplos vemos que bajo un mismo contexto, cuando se utilizan diferentes funciones de pérdidas, también obtenemos distintas estimaciones.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="algunos-resultados-de-probabilidad.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["ModelosBayesianos.pdf", "ModelosBayesianos.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
